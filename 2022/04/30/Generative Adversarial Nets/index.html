<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="LAzy">
    <meta name="referrer" content="no-referrer" />
    
    <title>
        
            Generative Adversarial Nets |
        
        LAzy&#39;s Blog
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="https://user-images.githubusercontent.com/93063038/166112719-9e939286-9f8a-4f66-b019-9344ee5eec20.jpg">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/css/font-awesome.min.css">
    <script id="hexo-configurations">
    let KEEP = window.KEEP || {};
    KEEP.hexo_config = {"hostname":"lazy.github.io","root":"/","language":"en","path":"search.json"};
    KEEP.theme_config = {"toc":{"enable":true,"number":false,"expand_all":true,"init_open":true},"style":{"primary_color":"#0066CC","avatar":"https://user-images.githubusercontent.com/93063038/166112719-9e939286-9f8a-4f66-b019-9344ee5eec20.jpg","favicon":"https://user-images.githubusercontent.com/93063038/166112719-9e939286-9f8a-4f66-b019-9344ee5eec20.jpg","article_img_align":"left","left_side_width":"260px","content_max_width":"920px","hover":{"shadow":true,"scale":true},"first_screen":{"enable":true,"background_img":"https://user-images.githubusercontent.com/93063038/166112575-1e98e9cc-dfe3-456a-b1ca-790a17fca4d1.png","description":"Learning right now is always the best solution."},"scroll":{"progress_bar":{"enable":true},"percent":{"enable":true}}},"local_search":{"enable":true,"preload":true},"code_copy":{"enable":false,"style":"default"},"pjax":{"enable":true},"lazyload":{"enable":false},"version":"3.4.5"};
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
  </script>
<meta name="generator" content="Hexo 6.1.0"><link rel="alternate" href="/atom.xml" title="LAzy" type="application/atom+xml">
</head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
        <span class="pjax-progress-bar"></span>
        <span class="pjax-progress-icon">
            <i class="fas fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            <header class="header-wrapper">

    <div class="header-content">
        <div class="left">
            
                <a class="logo-image" href="/">
                    <img src="https://user-images.githubusercontent.com/93063038/166112719-9e939286-9f8a-4f66-b019-9344ee5eec20.jpg">
                </a>
            
            <a class="logo-title" href="/">
                LAzy&#39;s Blog
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class=""
                               href="/"
                            >
                                HOME
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/archives"
                            >
                                ARCHIVES
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/categories"
                            >
                                CATEGORIES
                            </a>
                        </li>
                    
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/">HOME</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/archives">ARCHIVES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/categories">CATEGORIES</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="article-content-container">

        <div class="article-title">
            <span class="title-hover-animation">Generative Adversarial Nets</span>
        </div>

        
            <div class="article-header">
                <div class="avatar">
                    <img src="https://user-images.githubusercontent.com/93063038/166112719-9e939286-9f8a-4f66-b019-9344ee5eec20.jpg">
                </div>
                <div class="info">
                    <div class="author">
                        <span class="name">LAzy</span>
                        
                            <span class="author-label">Lv2</span>
                        
                    </div>
                    <div class="meta-info">
                        <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fas fa-edit"></i>&nbsp;
        <span class="pc">2022-04-30 11:53:46</span>
        <span class="mobile">2022-04-30 11:53</span>
    </span>
    
    

    
    
    
    
        <span class="article-pv article-meta-item">
            <i class="fas fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                    </div>
                </div>
            </div>
        

        <div class="article-content markdown-body">
            <h2 id="浅学一些数学知识"><a href="#浅学一些数学知识" class="headerlink" title="浅学一些数学知识"></a><strong>浅学一些数学知识</strong></h2><h3 id="信息量"><a href="#信息量" class="headerlink" title="信息量"></a><strong>信息量</strong></h3><p>在信息论当中，我们用一件事情发生的概率的负对数表示信息量。</p>
<script type="math/tex; mode=display">
H=-\log{p}</script><p>如公式所示，也就是事情发生的概率越大，其包含的信息量就越小，反之亦然。</p>
<h3 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a><strong>信息熵</strong></h3><p>信息熵，也是平均自信息量，如公式所示，表示的是自信息量(也就是上面提到的信息量)的数学期望，表示为概率与其自信息量的乘积然后再求和。</p>
<script type="math/tex; mode=display">
H(X)=-\sum_{x\in{X}}p(x)\log{p(x)}</script><h3 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a><strong>交叉熵</strong></h3><blockquote>
<p>交叉熵刻画的是实际输出（概率）与期望输出（概率）的距离，也就是交叉熵的值越小，两个概率分布就越接近，即拟合的更好。</p>
</blockquote>
<p>交叉熵其实就是对于一个分布<em>p</em>来说，我们用分布<em>q</em>来对分布<em>p</em>中的信息进行编码，所需要的信息量。</p>
<p>如果交叉熵越小，说明用分布<em>q</em>来表示分布<em>p</em>所需要的信息量越小，这也就说明<em>q</em>分布越接近<em>p</em>分布。</p>
<script type="math/tex; mode=display">
H(p,q)=-\sum_xp(x)\log{q(x)}</script><h3 id="KL散度（相对熵）"><a href="#KL散度（相对熵）" class="headerlink" title="KL散度（相对熵）"></a><strong>KL散度（相对熵）</strong></h3><blockquote>
<p>描述两个概率分布之间差异的非对称量</p>
<p>其定义就是<strong>用理论分布去拟合真实分布时产生的信息损耗</strong></p>
</blockquote>
<p>若有两个随机变量p, q，且其概率分布分别为p(x)、q(x)，则p相对q的相对熵为：</p>
<script type="math/tex; mode=display">
D_{KL}(p||q)=\sum_{x}p(x)\log\frac{p(x)}{q(x)}</script><p>又由定义可知：<br><strong>KL散度 = 交叉熵 - 信息熵</strong></p>
<p>因此，KL散度可通过下式得出：</p>
<script type="math/tex; mode=display">
\begin{aligned}D_{KL}(p||q)&=H(p,q)-H(p)\\
&=-\sum_xp(x)(\log{q(x)}-\log{p(x)})\\
&=-\sum{p(x)\log{\frac{q(x)}{p(x)}}}\\\\
&\iff{E_{x\backsim{p}}(\log{p(x)}-\log{q(x)}})\end{aligned}</script><p><em>正定性</em></p>
<p><strong>相对熵的值是非负值，即D(P||Q)&gt;0。</strong></p>
<p><em>不对称性</em></p>
<p><strong>尽管KL散度从直观上是个度量或距离函数，但它并不是一个真正的度量或者距离，因为它不具有对称性，即D(P||Q)!=D(Q||P)。</strong></p>
<h3 id="JS散度"><a href="#JS散度" class="headerlink" title="JS散度"></a><strong>JS散度</strong></h3><blockquote>
<p>由于<em>KL</em>散度的不对称性，所以这里引入了一个<em>JS</em>散度，也就是<em>Jensen-Shannon</em>散度，<em>JS</em>散度度量了两个概率分布的相似度，基于<em>KL</em>散度的变体，解决了<em>KL</em>散度非对称的问题，一般地，<em>JS</em>散度是对称的</p>
</blockquote>
<p>公式如下</p>
<script type="math/tex; mode=display">
JS(p||q)=\frac{1}{2}KL(p(x)||\frac{p(x)+q(x)}{2}+\frac{1}{2}KL(q(x)||\frac{p(x)+q(x)}{2})</script><p><img src="https://user-images.githubusercontent.com/93063038/166672229-e98e47df-8ca3-45c6-aa90-5f031e230d29.png" alt="jskl"></p>
<h3 id="条件概率"><a href="#条件概率" class="headerlink" title="条件概率"></a>条件概率</h3><blockquote>
<p>条件概率是指事件A在另外一个事件B已经发生条件下的发生概率。 条件概率表示为：P（A|B），读作”在B的条件下A的概率”。 条件概率可以用决策树进行计算。</p>
</blockquote>
<script type="math/tex; mode=display">
P(B|A)=\frac{P(AB)}{P(A)}</script><h3 id="全概率公式"><a href="#全概率公式" class="headerlink" title="全概率公式"></a><strong>全概率公式</strong></h3><p>对于一个较为复杂的事件A，找到其完备事件组B1、B2、B3……则可得：</p>
<script type="math/tex; mode=display">
P(A)=P(AB_1)+P(AB_2)+...+P(AB_n)</script><p>又根据条件概率公式：</p>
<script type="math/tex; mode=display">
P(A)=P(A|B_1)P(B_1)+P(A|B_2)P(B_2)+...+P(A|B_n)P(B_n)</script><p>则可证得全概率公式如下：</p>
<script type="math/tex; mode=display">
P(A)=\sum^n_{i=1}P(B_i)P(A|B_i)</script><h3 id="贝叶斯公式"><a href="#贝叶斯公式" class="headerlink" title="贝叶斯公式"></a><strong>贝叶斯公式</strong></h3><blockquote>
<p>通常，事件 A 在事件 B 发生的条件下与事件 B 在事件 A 发生的条件下，它们两者的概率并不相同，但是它们两者之间存在一定的相关性，并具有以下公式（称之为“贝叶斯公式”）</p>
</blockquote>
<p><strong>后验概率</strong>就是事件A在另一个事件B已经发生的条件下发生概率，根据观察到的样本修正之后的概率值，公式表示为P(A|B)。</p>
<p><strong>联合概率</strong>表示两件事情共同发生的概率。A与B的联合概率表示为p(AB)。</p>
<p><strong>先验概率（边缘概率）</strong>这个概率是通过统计得到的，或者依据自身依据经验给出的一个概率值，这里P(A)就是先验概率</p>
<script type="math/tex; mode=display">
P (AB) = P (A)*P (B|A)=P (B)*P (A|B)</script><script type="math/tex; mode=display">
P(A|B)=\frac{P(B|A)P(A)}{P(B)}</script><p><img width="411" alt="image" src="https://user-images.githubusercontent.com/93063038/166134628-d1e505ad-dc0e-45bc-beec-e5f08b403596.png"></p>
<h3 id="似然函数"><a href="#似然函数" class="headerlink" title="似然函数"></a><strong>似然函数</strong></h3><blockquote>
<p>概率描述的是在一定条件下某个事件发生的可能性，概率越大说明这件事情越可能会发生；而似然描述的是结果已知的情况下，该事件在不同条件下发生的可能性，似然函数的值越大说明该事件在对应的条件下发生的可能性越大。</p>
</blockquote>
<p><strong>若x已知，$\theta$为变量，则该函数为似然函数$L(x|\theta)$     描述对于不同的模型参数，x样本点出现的概率</strong></p>
<p><strong>若x为变量，$\theta$未知，则该函数为概率函数$p(x|\theta)$     描述对于参数模型$\theta$,  不同的样本点x出现的概率为多少</strong></p>
<p>其中：x表示某一个具体的数据，θ 表示模型的参数。</p>
<p><strong>似然函数对数化</strong></p>
<p>实际问题往往要比抛一次硬币复杂得多，会涉及到多个独立事件，在似然函数的表达式中通常都会出现连乘</p>
<p>对多项乘积的求导往往非常复杂，但是对于多项求和的求导却要简单的多，对数函数不改变原函数的单调性和极值位置，而且根据对数函数的性质可以将乘积转换为加减式，这可以大大简化求导的过程</p>
<h3 id="最大似然估计"><a href="#最大似然估计" class="headerlink" title="最大似然估计"></a><strong>最大似然估计</strong></h3><blockquote>
<p><strong>利用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值</strong></p>
</blockquote>
<p>当已知样本服从某一分布时，我们根据这一分布求使似然函数最大的概率分布，则求得概率分布就是最大似然估计得结果</p>
<h2 id="Generative-Adversarial-Networks论文阅读"><a href="#Generative-Adversarial-Networks论文阅读" class="headerlink" title="Generative Adversarial Networks论文阅读"></a>Generative Adversarial Networks论文阅读</h2><blockquote>
<p>        $data$→真实数据$（groundtruth）$<br>        $p_{data}$→真实数据的分布<br>        $z$→噪音（输入数据）<br>        $p_{z}$→原始噪音的分布<br>        $p_g$→经过生成器后的数据分布<br>        $G()$→生成映射函数<br>        $D()$→判别映射函数</p>
</blockquote>
<h3 id="对GAN训练过程的理解"><a href="#对GAN训练过程的理解" class="headerlink" title="对GAN训练过程的理解"></a><strong>对GAN训练过程的理解</strong></h3><p>将符合正态分布的随机噪声z输入生成器生成G(z)，经处理后与真实数据x一起交予判别器处理，判别器将G(z)是否为真实数据并给出一个概率值D(G(z))。我们的训练目标是：训练判别器D使D(x)最大，而D(G(z))最小，训练生成器G使D(G(z))最大。我们的训练策略是先训练k次判别器D使之具备一定的判别能力（在论文中k取1），之后训练一次生成器G，如此<strong>迭代训练</strong>以接近<strong>全局最优</strong>。</p>
<p>在刚开始训练的时候，生成器G生成的数据显然与真实数据相差很大，此时判别器D将以高置信度拒绝生成器G生成的样本，这将导致$\log{(1-D(G(z)))}$饱和（很大），所以选择先对判别器进行训练。</p>
<p><img width="616" alt="image" src="https://user-images.githubusercontent.com/93063038/165891999-3ac9fffa-6cd1-44c9-a77d-0019128df5bb.png"></p>
<p>由于训练开始时，G性能较差，这将使得D(G(z))趋近于0，这将导致$\log{(1-G(D(z)))}$的梯度较小，而$\log{(G(D(x)))}$的梯度较大，因此，将G的训练目标改为最大化$\log{(G(D(x)))}$在训练初期提供了更大的梯度    </p>
<p>可以说生成对抗网络训练的过程就是生成器G与判别器D进行一个零和博弈的过程，G欲使目标函数最大化，D欲使目标函数最小化</p>
<script type="math/tex; mode=display">
\underset{G}{min}\underset{D}{max}V(D,G)=E_{x\backsim{p_{data}}}[\log{D(x)}]+E_{z\backsim{p_z(z)}}[\log{1-D(G(z)))}]</script><p> <u>A less formal, more pedagogical explanation of the approach.</u></p>
<p><img width="602" alt="image" src="https://user-images.githubusercontent.com/93063038/165944429-2fe05a8e-21e1-4708-9c4c-5fb86fdba24f.png"></p>
<ul>
<li>蓝线 判别分布 $D$</li>
<li>红线 生成分布 $p_{g}$</li>
<li>黑线 真实数据分布 $p_{x}$</li>
</ul>
<h3 id="为什么这样设计目标函数？"><a href="#为什么这样设计目标函数？" class="headerlink" title="为什么这样设计目标函数？"></a>为什么这样设计目标函数？</h3><p><strong>我们知道KL散度可以描述两个分布之间的差异程度，即用理论分布去拟合真实分布时产生的信息损耗。我们可以将生成器G的训练过程看作是令生成数据的分布不断接近、拟合真实数据分布的过程，因此，我们可以将它看作一个将二者KL散度最小化的过程。再结合GAN的训练过程是生成器G与判别器D进行零和博弈的过程，我们可以得到：</strong>                                                                                                                                                             </p>
<script type="math/tex; mode=display">
\begin{aligned}D_{KL}(p_{data}||p_{g})&=H(p_{data},p_g)-H(p_{data})\\\\
&=-\sum_xp_{data}(x)(\log{p_g(x)}-\log{p_{data}(x)})\\
&=-\sum_x{p_{data}(x)\log{\frac{p_g(x)}{p_{data}(x)}}}\\\\
&\iff{E_{x\backsim{p_{data}}}(\log{p_{data}(x)}-\log{p_g(x)}})\\\\
&=E_{x\backsim{p_{data}}}(\log{p_{data}(x)})-E_{x\backsim{p_{data}}}(\log{p_g}(x))\\
&结合GAN生成器和鉴别器零和博弈的思想。则我们将真实数据与生成数据\\&的概率分布替换为判别器D对数据分布是否为真实数据的概率分布。\\&={E_{x\backsim{p_{data}}}(\log{D(x)})-E_{x\backsim{p_{g}}}(\log{D(x)})}\\\\
&={E_{x\backsim{p_{data}}}(\log{D(x)})+E_{x\backsim{p_{g}}}(\log{\frac{1}{D(x)}})}\\\\
&\iff{E_{x\backsim{p_{data}}}(\log{D(x)})+E_{x\backsim{p_{g}}}(\log({1-D(x))})}\end{aligned}</script><p>可知，生成器G想要达到最优，与前一项无关，只需最小化后一项。判别器D想要达到最优，只需最大化判别真实数据为真的概率，最小化判别生成数据为真的概率，即最大化整个函数。因此我们可以得到目标函数：</p>
<script type="math/tex; mode=display">
\underset{G}{min}\underset{D}{max}V(D,G)=E_{x\backsim{p_{data}}}[\log{D(x)}]+E_{z\backsim{p_z(z)}}[\log{1-D(G(z)))}]</script><p>从最大似然估计的角度来看。</p>
<p>由于我们已知的数据是生成数据的分布与真实数据的分布，想要得到的是使生成器最优的模型概率参数$\theta$，因此我们可以设计一个似然函数：</p>
<script type="math/tex; mode=display">
p_g(X_{i}|\theta)</script><p>我们使用最大似然估计方法：</p>
<script type="math/tex; mode=display">
\theta_{bst}=arg\underset{\theta}max\prod_{i=1}^{n}p_g(x_i|\theta)</script><p>取对数可得</p>
<script type="math/tex; mode=display">
\begin{aligned}\theta_{bst}&=arg\underset{\theta}max\sum_{i=1}^{n}\log{p_g(x_i|\theta)}
\\&\iff{arg\underset{\theta}maxE_{x\backsim{p_{g}}}\log{p_g(x_i|\theta)}}
\end{aligned}</script><p>再考虑判别器，我们想要令判别器对于真实数据输出的值趋于1，对生成数据输出的值趋于0，因此，我们</p>
<p>!!!!!!!&gt;&gt;&gt;?????????杀了我吧</p>
<h3 id="何时达到全局最优？"><a href="#何时达到全局最优？" class="headerlink" title="何时达到全局最优？"></a><strong>何时达到全局最优？</strong></h3><script type="math/tex; mode=display">
\begin{aligned}V(G,D)&=\int_xp_{data}(x)\log{(D(x))}dx+\int_zp_z(z)\log{(1-D(g(z)))}dz\\\\&=\int_xp_{data(x)}\log{(D(x))}+p_g(x)\log{(1-D(x))dx}\end{aligned}</script><p>要证上式，只需证</p>
<script type="math/tex; mode=display">
E_{z\backsim{p_z(z)}}\log{(1-D(G(z)))}=E_{x\backsim{p_g(x)}}\log{(1-D(x))}</script><h4 id="寻找最优的判别器D"><a href="#寻找最优的判别器D" class="headerlink" title="寻找最优的判别器D"></a>寻找最优的判别器D</h4><p>我们假定生成器G固定，来考虑最优判别器, 可将$p_{data}$和$p_g$看作常数a, b。</p>
<p>由上式得：</p>
<script type="math/tex; mode=display">
V = a\log(D)+b\log(1-D)</script><p>求导求其极值：</p>
<script type="math/tex; mode=display">
\frac{dV}{dD}=a×\frac{1}{D}-b×\frac{1}{1-D}</script><p>令$\frac{dV}{dD}=0$，则易得<strong>最优判别器D</strong>为：</p>
<script type="math/tex; mode=display">
D^*_G(x)=\frac{p_{data}(x)}{p_{data}(x)+p_g(x)}</script><blockquote>
<p>Note that the training objective for <em>D</em> can be interpreted as maximizing the log-likelihood for estimating the conditional probability <em>P</em>(<em>Y</em> = <em>y<strong>|</strong></em>x<strong>), where <em>Y</em> indicates whether </strong>x comes from $p_{data}$(with <em>y</em> = 1) or from $p_g$(with <em>y</em> = 0). </p>
</blockquote>
<h4 id="寻找最优的生成器G"><a href="#寻找最优的生成器G" class="headerlink" title="寻找最优的生成器G"></a>寻找最优的生成器G</h4><p>于是，我们将$D^*$代入求$\underset{D}{max}V(G,D)$</p>
<p>联系KL散度与JS散度的定义，我们可以得到：</p>
<script type="math/tex; mode=display">
\begin{aligned}\underset{D}{max}V(G,D^*)
&=E_{x\backsim{p_{data}}}(\log{D^*(x)})+E_{x\backsim{p_{g}}}(\log({1-D^*(x))})\\
&=E_{x\backsim{p_{data}}}(\log{\frac{p_{data}(x)}{p_{data}(x)+p_g(x)}})+E_{x\backsim{p_{g}}}(\log(\frac{p_{g}(x)}{p_{data}(x)+p_g(x)})\\
&=\int_xp_{data}(x)\log{\frac{p_{data}(x)}{p_{data}(x)+p_g(x)}dx+\int_xp_g(x)\log{\frac{p_{g}(x)}{p_{data}(x)+p_g(x)}dx}}\\
&=\int_xp_{data}(x)\log{\frac{\frac{1}{2}p_{data}(x)}{\frac{p_{data}(x)+p_g(x)}{2}}dx+\int_xp_g(x)\log{\frac{\frac{1}{2}p_{g}(x)}{\frac{p_{data}(x)+p_g(x)}{2}}dx}}\\
&=\int_xp_{data}(x)\log{\frac{1}{2}}dx+\int_xp_{g}(x)\log{\frac{1}{2}}dx+\int_xp_{data}(x)\log{\frac{p_{data}(x)}{\frac{p_{data}(x)+p_g(x)}{2}}dx+\int_xp_g(x)\log{\frac{p_{g}(x)}{\frac{p_{data}(x)+p_g(x)}{2}}dx}}\\
&=2\log{\frac{1}{2}}+2×[\frac{1}{2}KL(p_{data}||\frac{p_g+p_{data}}{2})+\frac{1}{2}KL(p_g||\frac{p_g+p_{data}}{2})]\\\\
&=-\log{4}+2JSD(p_{data}||p_g)\end{aligned}</script><p>有JS散度的定义域可知，当且仅当$p_{data}=p_g$的时候JS散度取得最小值0。</p>
<p>所以我们可以知道仅当$p_{data}=p_g$时取得全局最小值$-\log{4}$。</p>
<p>即取得<strong>最优生成器G</strong>需要满足的条件是<strong>$p_{data}=p_g$</strong></p>
<hr>
<p><strong>在实际训练中，想要达到全局最优是不可能的，我们的训练目的是使GAN进入一个纳什平衡的状态。</strong></p>
<p>在纳什均衡点，两者的参数到达一种“制衡”状态。在给定G的参数情况下，D当前的参数便对应了D损失函数的最小值，同样在给定D的参数情况下，G当前的参数便对应了G损失函数的最小值，也就是说在交替更新过程中，D和G均不可能单独做出任何改变。</p>
<hr>
<h3 id="为什么不先将判别器训练得很好再训练生成器？"><a href="#为什么不先将判别器训练得很好再训练生成器？" class="headerlink" title="为什么不先将判别器训练得很好再训练生成器？"></a>为什么不先将判别器训练得很好再训练生成器？</h3><p>我们已经知道，当假设判别器为最优的极端情况下，目标函数为：</p>
<script type="math/tex; mode=display">
-\log{4}+2JSD(p_{data}||p_g)</script><p>此时生成器效果还很差，因此$p_{data}$与$p_g$两个分布的重叠区域几乎为0，此时易证$JSD(p_{data}||p_g)=\log{2}$，因此，目标函数为一常数0。此时，对于梯度下降方法，<strong>梯度为0</strong>，因此训练无法进行。</p>

        </div>

        

        

        
            <div class="article-nav">
                
                    <div class="article-prev">
                        <a class="prev"
                           rel="prev"
                           href="/2022/04/30/webcrawler/"
                        >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                            <span class="title flex-center">
                                <span class="post-nav-title-item">web crawler</span>
                                <span class="post-nav-item">Prev posts</span>
                            </span>
                        </a>
                    </div>
                
                
                    <div class="article-next">
                        <a class="next"
                           rel="next"
                           href="/2022/04/27/baseline/"
                        >
                            <span class="title flex-center">
                                <span class="post-nav-title-item">baseline</span>
                                <span class="post-nav-item">Next posts</span>
                            </span>
                            <span class="right arrow-icon flex-center">
                              <i class="fas fa-chevron-right"></i>
                            </span>
                        </a>
                    </div>
                
            </div>
        

        
            <div class="comment-container">
                <div class="comments-container">
    <div id="comment-anchor"></div>
    <div class="comment-area-title">
        <i class="fas fa-comments">&nbsp;Comments</i>
    </div>
    

        
            
    <div class="valine-container">
        <script data-pjax
                src="//cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js"></script>
        <div id="vcomments"></div>
        <script data-pjax>
            function loadValine() {
                new Valine({
                    el: '#vcomments',
                    appId: 'CcuyF9RKQi3JUBUojdmwYROs-gzGzoHsz',
                    appKey: 'c1x77tnTNwXqbXXHL8bx1XCd',
                    meta: ['nick', 'mail', 'link'],
                    avatar: 'wavatar',
                    enableQQ: true,
                    placeholder: '😜 尽情吐槽吧bro~',
                    lang: 'en'.toLowerCase()
                });

                function getAuthor(language) {
                    switch (language) {
                        case 'en':
                            return 'Author';
                        case 'zh-CN':
                            return '博主';
                        default:
                            return 'Master';
                    }
                }

                // Add "Author" identify
                const getValineDomTimer = setInterval(() => {
                    const vcards = document.querySelectorAll('#vcomments .vcards .vcard');
                    if (vcards.length > 0) {
                        let author = 'LAzy';

                        if (author) {
                            for (let vcard of vcards) {
                                const vnick_dom = vcard.querySelector('.vhead .vnick');
                                const vnick = vnick_dom.innerHTML;
                                if (vnick === author) {
                                    vnick_dom.innerHTML = `${vnick} <span class="author">${getAuthor(KEEP.hexo_config.language)}</span>`
                                }
                            }
                        }
                        clearInterval(getValineDomTimer);
                    } else {
                        clearInterval(getValineDomTimer);
                    }
                }, 2000);
            }

            if ('true') {
                const loadValineTimeout = setTimeout(() => {
                    loadValine();
                    clearTimeout(loadValineTimeout);
                }, 1000);
            } else {
                window.addEventListener('DOMContentLoaded', loadValine);
            }
        </script>
    </div>



        
    
</div>

            </div>
        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
              <span>2022</span>
              -
            
            2022&nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;<a href="/">LAzy</a>
        </div>
        
            <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv">
                        Visitor Count&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp;
                    </span>
                
                
                    <span id="busuanzi_container_site_pv">
                        Totalview&nbsp;<span id="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="theme-info info-item">
            Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.4.5</a>
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item page-aside-toggle">
                <i class="fas fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
            <li class="go-comment">
                <i class="fas fa-comment"></i>
            </li>
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-arrows-alt-h"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        
            <li class="tools-item rss flex-center">
                <a class="flex-center"
                   href="/atom.xml"
                   target="_blank"
                >
                    <i class="fas fa-rss"></i>
                </a>
            </li>
        

        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="arrow-up fas fa-arrow-up"></i>
                <span class="percent"></span>
            </li>
        
    </ul>
</div>

    </div>

    
        <aside class="page-aside">
            <div class="post-toc-wrap">
    <div class="post-toc">
        <ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B5%85%E5%AD%A6%E4%B8%80%E4%BA%9B%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86"><span class="nav-text">浅学一些数学知识</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BF%A1%E6%81%AF%E9%87%8F"><span class="nav-text">信息量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BF%A1%E6%81%AF%E7%86%B5"><span class="nav-text">信息熵</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%A4%E5%8F%89%E7%86%B5"><span class="nav-text">交叉熵</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#KL%E6%95%A3%E5%BA%A6%EF%BC%88%E7%9B%B8%E5%AF%B9%E7%86%B5%EF%BC%89"><span class="nav-text">KL散度（相对熵）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#JS%E6%95%A3%E5%BA%A6"><span class="nav-text">JS散度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87"><span class="nav-text">条件概率</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%A8%E6%A6%82%E7%8E%87%E5%85%AC%E5%BC%8F"><span class="nav-text">全概率公式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%85%AC%E5%BC%8F"><span class="nav-text">贝叶斯公式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BC%BC%E7%84%B6%E5%87%BD%E6%95%B0"><span class="nav-text">似然函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1"><span class="nav-text">最大似然估计</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Generative-Adversarial-Networks%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB"><span class="nav-text">Generative Adversarial Networks论文阅读</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%B9GAN%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B%E7%9A%84%E7%90%86%E8%A7%A3"><span class="nav-text">对GAN训练过程的理解</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E6%A0%B7%E8%AE%BE%E8%AE%A1%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0%EF%BC%9F"><span class="nav-text">为什么这样设计目标函数？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%95%E6%97%B6%E8%BE%BE%E5%88%B0%E5%85%A8%E5%B1%80%E6%9C%80%E4%BC%98%EF%BC%9F"><span class="nav-text">何时达到全局最优？</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AF%BB%E6%89%BE%E6%9C%80%E4%BC%98%E7%9A%84%E5%88%A4%E5%88%AB%E5%99%A8D"><span class="nav-text">寻找最优的判别器D</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AF%BB%E6%89%BE%E6%9C%80%E4%BC%98%E7%9A%84%E7%94%9F%E6%88%90%E5%99%A8G"><span class="nav-text">寻找最优的生成器G</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E5%85%88%E5%B0%86%E5%88%A4%E5%88%AB%E5%99%A8%E8%AE%AD%E7%BB%83%E5%BE%97%E5%BE%88%E5%A5%BD%E5%86%8D%E8%AE%AD%E7%BB%83%E7%94%9F%E6%88%90%E5%99%A8%EF%BC%9F"><span class="nav-text">为什么不先将判别器训练得很好再训练生成器？</span></a></li></ol></li></ol>
    </div>
</div>
        </aside>
    

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>



<script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/utils.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/main.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/header-shrink.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/back2top.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/dark-light-toggle.js"></script>


    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/local-search.js"></script>






<div class="post-scripts pjax">
    
        <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/left-side-toggle.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/libs/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/toc.js"></script>
    
</div>


    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/libs/pjax.min.js"></script>
<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax'
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            KEEP.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            KEEP.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            KEEP.refresh();
        });
    });
</script>



<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>

</body>
</html>
