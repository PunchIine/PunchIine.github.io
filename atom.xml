<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>LAzy</title>
  
  
  <link href="http://lazy.github.io/atom.xml" rel="self"/>
  
  <link href="http://lazy.github.io/"/>
  <updated>2022-04-30T13:51:11.237Z</updated>
  <id>http://lazy.github.io/</id>
  
  <author>
    <name>LAzy</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Yolo</title>
    <link href="http://lazy.github.io/2022/04/30/Yolo/"/>
    <id>http://lazy.github.io/2022/04/30/Yolo/</id>
    <published>2022-04-30T13:25:33.000Z</published>
    <updated>2022-04-30T13:51:11.237Z</updated>
    
    <content type="html"><![CDATA[<h2 id="IoU（Intersection-over-union）"><a href="#IoU（Intersection-over-union）" class="headerlink" title="IoU（Intersection over union）"></a>IoU（<strong>Intersection over union</strong>）</h2><blockquote><p>交并比，衡量两个区域的重叠程度，是二者重叠部分面积占二者总面积的比例</p></blockquote><p><img src="https://user-images.githubusercontent.com/93063038/163665429-095df1bd-6ac4-4023-a4e3-b58936722093.png" alt="img"></p><p>在目标检测任务中，如果我们模型输出的矩形框与我们人工标注的矩形框的IoU值大于某个阈值时（通常为0.5）即认为我们的模型输出了正确的</p><h2 id="Precision-amp-Recall"><a href="#Precision-amp-Recall" class="headerlink" title="Precision &amp; Recall"></a><strong>Precision &amp; Recall</strong></h2><p>假设我们有一组图片，里面有若干待检测的目标，</p><p>Precision就代表我们模型检测出来的目标有多大比例是真正的目标物体，</p><p>Recall就代表所有真实的目标有多大比例被我们的模型检测出来了。</p><p><img src="https://user-images.githubusercontent.com/93063038/163666250-5edb4b65-7d64-4cff-a5ed-83492325219d.png" alt="image"></p><p>TP ：模型预测为某类物品（检测出的矩形框大于置信度阈值）且与数据集标注中某个目标框IOU大于0.5</p><p>TN ：模型预测不为某类物品（检测出的矩形框小于置信度阈值）但与数据集标注中某个目标框IOU大于0.5</p><p>FP ：模型预测为某类物品，但与数据集标注中所有目标框IOU均大于0.5（重复检测）</p><p>FN ：模型预测不为某类物品，且与数据集中所有目标框IOU均大于0.5</p><p><img width="447" alt="image" src="https://user-images.githubusercontent.com/93063038/165037636-4aa10c6c-0368-4fad-9dcd-0c7b4d95578e.png"></p><p>准确率： 模型检测出的物品中正确的比例</p><p><img src="https://user-images.githubusercontent.com/93063038/163666288-f948f80e-77df-47ab-b850-09f8990e79c1.png" alt="image"></p><p>召回率： 所有正确的目标中被模型检测出来的比例</p><p><img src="https://user-images.githubusercontent.com/93063038/163666293-016cc94a-35c1-4fc0-9be5-dd7257e4e60a.png" alt="image"></p><h2 id="PR曲线"><a href="#PR曲线" class="headerlink" title="PR曲线"></a>PR曲线</h2><blockquote><p>我们当然希望检测的结果P越高越好，R也越高越好，但事实上这两者在<strong>某些情况下是矛盾的</strong>。比如极端情况下，我们只检测出了一个结果，且是准确的，那么Precision就是100%，但是Recall就很低；而如果我们把所有结果都返回，那么必然Recall必然很大，但是Precision很低。</p><p>因此在不同的场合中需要自己判断希望P比较高还是R比较高。如果是做实验研究，可以绘制Precision-Recall曲线来帮助分析。</p></blockquote><p><img src="https://user-images.githubusercontent.com/93063038/166089529-222bed42-72cb-432b-9c13-e8793d1dd308.png" alt="f133591e-4ed5-4cbb-829b-aa81a7dd19bb_"></p><h2 id="AP-Average-Precision"><a href="#AP-Average-Precision" class="headerlink" title="AP (Average Precision)"></a>AP (Average Precision)</h2><p>AP = $\int^1_0p(r)dr$</p><p>在实际应用中，我们并不直接对该PR曲线进行计算，而是对PR曲线进行平滑处理。即对PR曲线上的每个点，Precision的值取该点右侧最大的Precision的值。</p><p>？</p><h2 id="Yolov1"><a href="#Yolov1" class="headerlink" title="Yolov1"></a>Yolov1</h2><blockquote><p><strong>将目标检测问题转化为一个回归问题进行求解</strong>，也就是说将图像作为输入（像素数据），直接输出物体的位置和所属于的类别的置信度（是以一个向量的形式表示的，后续会介绍），属于端到端的模型形式。</p></blockquote><p>基本思想：将图片划分为S*S个区域（gridcell），假设都存在一个 true answer 也就是针对这个目标的最好的检测框 ， 则每一个目标的检测框的中心点一定是落在某一个小区域内的；如果此时的中心点落在 x 框内，则 x 小区域就负责搞定这个目标；注意此时可能多个目标落在同一个区域内。</p><p>每一个<strong>小区域设定 B （bounding box的数量）个可能的候选框，并计算每一个可能的候选框的得分</strong> = 置信度，是一个（该候选框和真实的目标检测框的重合程度）和（这个框里确实框住了某一个物体）的综合度量指标，计算方式如下：</p><p>$confidence = Pr（Object）* IOU^{truth}_{pred}$</p><p><strong>其中，若bounding box包含物体，则P(object) = 1；否则P(object) = 0</strong></p><p>每一个预测是一个长度为 5 的向量，记作 （x, y, w, h, conf）</p><ul><li>(x, y) 表示当前预测的检测框的中心相对于我的小区域的位置（共 $S^2$ 个小区域)，这里的 x 和 y 都是 0-1 之间的，也就是说是相对于当前小区域的左上角的偏移值</li><li>(w,h) 表示检测框的宽度和高度，一般是处理到 0-1 之间，标记当前的预测框和整个图片的宽度/高度的比例 - conf 为上述的置信度，可以看作是当前的框的可信度的综合指标，由（是否框准了 = 是否和真实的预测框有较好的重合）和（是否框里确实框住了物体）两个部分影响</li></ul><h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><blockquote><p>Our detection network has 24 convolutional layers followed by 2 fully connected layers. Alternating 1 <em>×</em> 1 convolutional layers reduce the features space from preceding layers. We pretrain the convolutional layers on the ImageNet classifification task at half the resolution (224 <em>×</em> 224 input image) and then double the resolution for detection.</p></blockquote><p>YOLO网络借鉴了GoogLeNet分类网络结构。 网络有24个卷积层，其后是2个完全连接的层，不同的是，YOLO未使用inception module，而是使用1x1卷积层（此处1x1卷积层的存在是为了跨通道信息整合）+3x3卷积层简单替代。最终输出的是7x7x30的张量的预测值</p><p><img width="665" alt="image" src="https://user-images.githubusercontent.com/93063038/165040258-989f9ec2-36c5-411a-9ef7-ec396115ab5a.png"></p><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>使用<strong>均方和误差</strong>作为loss函数来优化模型参数，即网络输出的SxSx(Bx5 + C)维向量与真实图像的对应SxSx(Bx5 + C)维向量的均方和误差。</p><p><img width="523" alt="image" src="https://user-images.githubusercontent.com/93063038/165040626-b6c30262-1151-4de8-92e7-413f53811f33.png"></p><h3 id="NMS-方法（Non-Maximal-Suppression-非极大值抑制）"><a href="#NMS-方法（Non-Maximal-Suppression-非极大值抑制）" class="headerlink" title="NMS 方法（Non-Maximal Suppression / 非极大值抑制）"></a>NMS 方法（Non-Maximal Suppression / 非极大值抑制）</h3><blockquote><p>将同一目标内的bboxes按照cls score + IoU阈值做筛选，剔除冗余地、低置信度的bbox</p></blockquote><p>具体实现思路如下：</p><ol><li>选取此类物品box中置信度最高的box</li><li>计算与其余此类box的IOU</li><li>IOU&gt;nms_threshold则去除置信度小的那个box</li><li>从剩余box中再选取置信度最高的box，如此循环</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;IoU（Intersection-over-union）&quot;&gt;&lt;a href=&quot;#IoU（Intersection-over-union）&quot; class=&quot;headerlink&quot; title=&quot;IoU（Intersection over union）&quot;&gt;&lt;/a&gt;Io</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>web crawler</title>
    <link href="http://lazy.github.io/2022/04/30/webcrawler/"/>
    <id>http://lazy.github.io/2022/04/30/webcrawler/</id>
    <published>2022-04-30T05:15:10.000Z</published>
    <updated>2022-04-30T05:16:28.861Z</updated>
    
    
    
    
    
  </entry>
  
  <entry>
    <title>Generative Adversarial Nets</title>
    <link href="http://lazy.github.io/2022/04/30/Generative%20Adversarial%20Nets/"/>
    <id>http://lazy.github.io/2022/04/30/Generative%20Adversarial%20Nets/</id>
    <published>2022-04-30T03:53:46.000Z</published>
    <updated>2022-05-04T04:57:38.733Z</updated>
    
    <content type="html"><![CDATA[<h2 id="浅学一些数学知识"><a href="#浅学一些数学知识" class="headerlink" title="浅学一些数学知识"></a><strong>浅学一些数学知识</strong></h2><h3 id="信息量"><a href="#信息量" class="headerlink" title="信息量"></a><strong>信息量</strong></h3><p>在信息论当中，我们用一件事情发生的概率的负对数表示信息量。</p><script type="math/tex; mode=display">H=-\log{p}</script><p>如公式所示，也就是事情发生的概率越大，其包含的信息量就越小，反之亦然。</p><h3 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a><strong>信息熵</strong></h3><p>信息熵，也是平均自信息量，如公式所示，表示的是自信息量(也就是上面提到的信息量)的数学期望，表示为概率与其自信息量的乘积然后再求和。</p><script type="math/tex; mode=display">H(X)=-\sum_{x\in{X}}p(x)\log{p(x)}</script><h3 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a><strong>交叉熵</strong></h3><blockquote><p>交叉熵刻画的是实际输出（概率）与期望输出（概率）的距离，也就是交叉熵的值越小，两个概率分布就越接近，即拟合的更好。</p></blockquote><p>交叉熵其实就是对于一个分布<em>p</em>来说，我们用分布<em>q</em>来对分布<em>p</em>中的信息进行编码，所需要的信息量。</p><p>如果交叉熵越小，说明用分布<em>q</em>来表示分布<em>p</em>所需要的信息量越小，这也就说明<em>q</em>分布越接近<em>p</em>分布。</p><script type="math/tex; mode=display">H(p,q)=-\sum_xp(x)\log{q(x)}</script><h3 id="KL散度（相对熵）"><a href="#KL散度（相对熵）" class="headerlink" title="KL散度（相对熵）"></a><strong>KL散度（相对熵）</strong></h3><blockquote><p>描述两个概率分布之间差异的非对称量</p><p>其定义就是<strong>用理论分布去拟合真实分布时产生的信息损耗</strong></p></blockquote><p>若有两个随机变量p, q，且其概率分布分别为p(x)、q(x)，则p相对q的相对熵为：</p><script type="math/tex; mode=display">D_{KL}(p||q)=\sum_{x}p(x)\log\frac{p(x)}{q(x)}</script><p>又由定义可知：<br><strong>KL散度 = 交叉熵 - 信息熵</strong></p><p>因此，KL散度可通过下式得出：</p><script type="math/tex; mode=display">\begin{aligned}D_{KL}(p||q)&=H(p,q)-H(p)\\&=-\sum_xp(x)(\log{q(x)}-\log{p(x)})\\&=-\sum{p(x)\log{\frac{q(x)}{p(x)}}}\\\\&\iff{E_{x\backsim{p}}(\log{p(x)}-\log{q(x)}})\end{aligned}</script><p><em>正定性</em></p><p><strong>相对熵的值是非负值，即D(P||Q)&gt;0。</strong></p><p><em>不对称性</em></p><p><strong>尽管KL散度从直观上是个度量或距离函数，但它并不是一个真正的度量或者距离，因为它不具有对称性，即D(P||Q)!=D(Q||P)。</strong></p><h3 id="JS散度"><a href="#JS散度" class="headerlink" title="JS散度"></a><strong>JS散度</strong></h3><blockquote><p>由于<em>KL</em>散度的不对称性，所以这里引入了一个<em>JS</em>散度，也就是<em>Jensen-Shannon</em>散度，<em>JS</em>散度度量了两个概率分布的相似度，基于<em>KL</em>散度的变体，解决了<em>KL</em>散度非对称的问题，一般地，<em>JS</em>散度是对称的</p></blockquote><p>公式如下</p><script type="math/tex; mode=display">JS(p||q)=\frac{1}{2}KL(p(x)||\frac{p(x)+q(x)}{2}+\frac{1}{2}KL(q(x)||\frac{p(x)+q(x)}{2})</script><h3 id="条件概率"><a href="#条件概率" class="headerlink" title="条件概率"></a>条件概率</h3><blockquote><p>条件概率是指事件A在另外一个事件B已经发生条件下的发生概率。 条件概率表示为：P（A|B），读作”在B的条件下A的概率”。 条件概率可以用决策树进行计算。</p></blockquote><script type="math/tex; mode=display">P(B|A)=\frac{P(AB)}{P(A)}</script><h3 id="全概率公式"><a href="#全概率公式" class="headerlink" title="全概率公式"></a><strong>全概率公式</strong></h3><p>对于一个较为复杂的事件A，找到其完备事件组B1、B2、B3……则可得：</p><script type="math/tex; mode=display">P(A)=P(AB_1)+P(AB_2)+...+P(AB_n)</script><p>又根据条件概率公式：</p><script type="math/tex; mode=display">P(A)=P(A|B_1)P(B_1)+P(A|B_2)P(B_2)+...+P(A|B_n)P(B_n)</script><p>则可证得全概率公式如下：</p><script type="math/tex; mode=display">P(A)=\sum^n_{i=1}P(B_i)P(A|B_i)</script><h3 id="贝叶斯公式"><a href="#贝叶斯公式" class="headerlink" title="贝叶斯公式"></a><strong>贝叶斯公式</strong></h3><blockquote><p>通常，事件 A 在事件 B 发生的条件下与事件 B 在事件 A 发生的条件下，它们两者的概率并不相同，但是它们两者之间存在一定的相关性，并具有以下公式（称之为“贝叶斯公式”）</p></blockquote><p><strong>后验概率</strong>就是事件A在另一个事件B已经发生的条件下发生概率，根据观察到的样本修正之后的概率值，公式表示为P(A|B)。</p><p><strong>联合概率</strong>表示两件事情共同发生的概率。A与B的联合概率表示为p(AB)。</p><p><strong>先验概率（边缘概率）</strong>这个概率是通过统计得到的，或者依据自身依据经验给出的一个概率值，这里P(A)就是先验概率</p><script type="math/tex; mode=display">P (AB) = P (A)*P (B|A)=P (B)*P (A|B)</script><script type="math/tex; mode=display">P(A|B)=\frac{P(B|A)P(A)}{P(B)}</script><p><img width="411" alt="image" src="https://user-images.githubusercontent.com/93063038/166134628-d1e505ad-dc0e-45bc-beec-e5f08b403596.png"></p><h3 id="似然函数"><a href="#似然函数" class="headerlink" title="似然函数"></a><strong>似然函数</strong></h3><blockquote><p>概率描述的是在一定条件下某个事件发生的可能性，概率越大说明这件事情越可能会发生；而似然描述的是结果已知的情况下，该事件在不同条件下发生的可能性，似然函数的值越大说明该事件在对应的条件下发生的可能性越大。</p></blockquote><p><strong>若x已知，$\theta$为变量，则该函数为似然函数$L(x|\theta)$     描述对于不同的模型参数，x样本点出现的概率</strong></p><p><strong>若x为变量，$\theta$未知，则该函数为概率函数$p(x|\theta)$     描述对于参数模型$\theta$,  不同的样本点x出现的概率为多少</strong></p><p>其中：x表示某一个具体的数据，θ 表示模型的参数。</p><p><strong>似然函数对数化</strong></p><p>实际问题往往要比抛一次硬币复杂得多，会涉及到多个独立事件，在似然函数的表达式中通常都会出现连乘</p><p>对多项乘积的求导往往非常复杂，但是对于多项求和的求导却要简单的多，对数函数不改变原函数的单调性和极值位置，而且根据对数函数的性质可以将乘积转换为加减式，这可以大大简化求导的过程</p><h3 id="最大似然估计"><a href="#最大似然估计" class="headerlink" title="最大似然估计"></a><strong>最大似然估计</strong></h3><blockquote><p><strong>利用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值</strong></p></blockquote><p>当已知样本服从某一分布时，我们根据这一分布求使似然函数最大的概率分布，则求得概率分布就是最大似然估计得结果</p><h2 id="Generative-Adversarial-Networks论文阅读"><a href="#Generative-Adversarial-Networks论文阅读" class="headerlink" title="Generative Adversarial Networks论文阅读"></a>Generative Adversarial Networks论文阅读</h2><blockquote><p>        $data$→真实数据$（groundtruth）$<br>        $p_{data}$→真实数据的分布<br>        $z$→噪音（输入数据）<br>        $p_{z}$→原始噪音的分布<br>        $p_g$→经过生成器后的数据分布<br>        $G()$→生成映射函数<br>        $D()$→判别映射函数</p></blockquote><h3 id="对GAN训练过程的理解"><a href="#对GAN训练过程的理解" class="headerlink" title="对GAN训练过程的理解"></a><strong>对GAN训练过程的理解</strong></h3><p>将符合正态分布的随机噪声z输入生成器生成G(z)，经处理后与真实数据x一起交予判别器处理，判别器将G(z)是否为真实数据并给出一个概率值D(G(z))。我们的训练目标是：训练判别器D使D(x)最大，而D(G(z))最小，训练生成器G使D(G(z))最大。我们的训练策略是先训练k次判别器D使之具备一定的判别能力（在论文中k取1），之后训练一次生成器G，如此<strong>迭代训练</strong>以接近<strong>全局最优</strong>。</p><p><img width="616" alt="image" src="https://user-images.githubusercontent.com/93063038/165891999-3ac9fffa-6cd1-44c9-a77d-0019128df5bb.png"></p><p>由于训练开始时，G性能较差，这将使得D(G(z))趋近于0，这将导致$\log{(1-G(D(z)))}$的梯度较小，而$\log{(G(D(x)))}$的梯度较大，因此，作者将G的训练目标改为最大化$\log{(G(D(x)))}$在训练初期提供了更大的梯度    </p><p>可以说生成对抗网络训练的过程就是生成器G与判别器D进行一个零和博弈的过程，G欲使目标函数最大化，D欲使目标函数最小化</p><script type="math/tex; mode=display">\underset{G}{min}\underset{D}{max}V(D,G)=E_{x\backsim{p_{data}}}[\log{D(x)}]+E_{z\backsim{p_z(z)}}[\log{1-D(G(z)))}]</script><p> <u>A less formal, more pedagogical explanation of the approach.</u></p><p><img width="602" alt="image" src="https://user-images.githubusercontent.com/93063038/165944429-2fe05a8e-21e1-4708-9c4c-5fb86fdba24f.png"></p><ul><li>蓝线 判别分布 $D$</li><li>红线 生成分布 $p_{g}$</li><li>黑线 真实数据分布 $p_{x}$</li></ul><h3 id="为什么这样设计目标函数？"><a href="#为什么这样设计目标函数？" class="headerlink" title="为什么这样设计目标函数？"></a>为什么这样设计目标函数？</h3><p><strong>我们知道KL散度可以描述两个分布之间的差异程度，即用理论分布去拟合真实分布时产生的信息损耗。我们可以将生成器G的训练过程看作是令生成数据的分布不断接近、拟合真实数据分布的过程，因此，我们可以将它看作一个将二者KL散度最小化的过程。再结合GAN的训练过程是生成器G与判别器D进行零和博弈的过程，我们可以得到：</strong>                                                                                                                                                             </p><script type="math/tex; mode=display">\begin{aligned}D_{KL}(p_{data}||p_{g})&=H(p_{data},p_g)-H(p_{data})\\\\&=-\sum_xp_{data}(x)(\log{p_g(x)}-\log{p_{data}(x)})\\&=-\sum_x{p_{data}(x)\log{\frac{p_g(x)}{p_{data}(x)}}}\\\\&\iff{E_{x\backsim{p_{data}}}(\log{p_{data}(x)}-\log{p_g(x)}})\\\\&=E_{x\backsim{p_{data}}}(\log{p_{data}(x)})-E_{x\backsim{p_{data}}}(\log{p_g}(x))\\&结合GAN生成器和鉴别器零和博弈的思想。则我们将真实数据与生成数据\\&的概率分布替换为判别器D对数据分布是否为真实数据的概率分布。\\&={E_{x\backsim{p_{data}}}(\log{D(x)})-E_{x\backsim{p_{g}}}(\log{D(x)})}\\\\&={E_{x\backsim{p_{data}}}(\log{D(x)})+E_{x\backsim{p_{g}}}(\log{\frac{1}{D(x)}})}\\\\&\iff{E_{x\backsim{p_{data}}}(\log{D(x)})+E_{x\backsim{p_{g}}}(\log({1-D(x))})}\end{aligned}</script><p>可知，生成器G想要达到最优，与前一项无关，只需最小化后一项。判别器D想要达到最优，只需最大化判别真实数据为真的概率，最小化判别生成数据为真的概率，即最大化整个函数。因此我们可以得到目标函数：</p><script type="math/tex; mode=display">\underset{G}{min}\underset{D}{max}V(D,G)=E_{x\backsim{p_{data}}}[\log{D(x)}]+E_{z\backsim{p_z(z)}}[\log{1-D(G(z)))}]</script><h3 id="何时达到全局最优？"><a href="#何时达到全局最优？" class="headerlink" title="何时达到全局最优？"></a><strong>何时达到全局最优？</strong></h3><script type="math/tex; mode=display">\begin{aligned}V(G,D)&=\int_xp_{data}(x)\log{(D(x))}dx+\int_zp_z(z)\log{(1-D(g(z)))}dz\\\\&=\int_xp_{data(x)}\log{(D(x))}+p_g(x)\log{(1-D(x))dx}\end{aligned}</script><p>要证上式，只需证</p><script type="math/tex; mode=display">E_{z\backsim{p_z(z)}}\log{(1-D(G(z)))}=E_{x\backsim{p_g(x)}}\log{(1-D(x))}</script><h4 id="寻找最优的判别器D"><a href="#寻找最优的判别器D" class="headerlink" title="寻找最优的判别器D"></a>寻找最优的判别器D</h4><p>我们假定生成器G固定，来考虑最优判别器, 可将$p_{data}$和$p_g$看作常数a, b。</p><p>由上式得：</p><script type="math/tex; mode=display">V = a\log(D)+b\log(1-D)</script><p>求导求其极值：</p><script type="math/tex; mode=display">\frac{dV}{dD}=a×\frac{1}{D}-b×\frac{1}{1-D}</script><p>令$\frac{dV}{dD}=0$，则易得<strong>最优判别器D</strong>为：</p><script type="math/tex; mode=display">D^*_G(x)=\frac{p_{data}(x)}{p_{data}(x)+p_g(x)}</script><h4 id="寻找最优的生成器G"><a href="#寻找最优的生成器G" class="headerlink" title="寻找最优的生成器G"></a>寻找最优的生成器G</h4><p>于是，我们将$D^*$代入求$\underset{D}{max}V(G,D)$</p><script type="math/tex; mode=display">\begin{aligned}\underset{D}{max}V(G,D^*)&=E_{x\backsim{p_{data}}}(\log{D^*(x)})+E_{x\backsim{p_{g}}}(\log({1-D^*(x))})\\&=E_{x\backsim{p_{data}}}(\log{\frac{p_{data}(x)}{p_{data}(x)+p_g(x)}})+E_{x\backsim{p_{g}}}(\log(\frac{p_{g}(x)}{p_{data}(x)+p_g(x)})\\&=\int_xp_{data}(x)\log{\frac{p_{data}(x)}{p_{data}(x)+p_g(x)}dx+\int_xp_g(x)\log{\frac{p_{g}(x)}{p_{data}(x)+p_g(x)}dx}}\\&=\int_xp_{data}(x)\log{\frac{\frac{1}{2}p_{data}(x)}{\frac{p_{data}(x)+p_g(x)}{2}}dx+\int_xp_g(x)\log{\frac{\frac{1}{2}p_{g}(x)}{\frac{p_{data}(x)+p_g(x)}{2}}dx}}\\&=\int_xp_{data}(x)\log{\frac{1}{2}}dx+\int_xp_{g}(x)\log{\frac{1}{2}}dx+\int_xp_{data}(x)\log{\frac{p_{data}(x)}{\frac{p_{data}(x)+p_g(x)}{2}}dx+\int_xp_g(x)\log{\frac{p_{g}(x)}{\frac{p_{data}(x)+p_g(x)}{2}}dx}}\\&=2\log{\frac{1}{2}}+2×[\frac{1}{2}KL(p_{data}||\frac{p_g+p_{data}}{2})+\frac{1}{2}KL(p_g||\frac{p_g+p_{data}}{2})]\\\\&=-\log{4}+2JSD(p_{data}||p_g)\end{aligned}</script><p>有JS散度的定义域可知，当且仅当$p_{data}=p_g$的时候JS散度取得最小值0。</p><p>所以我们可以知道仅当$p_{data}=p_g$时取得全局最小值$-\log{4}$。</p><p>即取得<strong>最优生成器G</strong>需要满足的条件是<strong>$p_{data}=p_g$</strong> </p><p>注意训练判别器D的过程能够看作是使条件估计概率$P(Y = y|x)$的似然函数最大化的过程，Y表示x可能来自原始数据分布，也可能来自生成数据分布。当来自原始数据分布的时候y=1，当来自生成数据分布的时候y=0</p><h3 id="为什么选择先训练判别器？"><a href="#为什么选择先训练判别器？" class="headerlink" title="为什么选择先训练判别器？"></a>为什么选择先训练判别器？</h3><p>在刚开始训练的时候，生成器G生成的数据显然与真实数据相差很大，此时判别器D将以高置信度拒绝生成器G生成的样本，这将导致$\log{(1-D(G(z)))}$饱和（很大）。</p><h3 id="为什么不先将判别器训练得很好再训练生成器？"><a href="#为什么不先将判别器训练得很好再训练生成器？" class="headerlink" title="为什么不先将判别器训练得很好再训练生成器？"></a>为什么不先将判别器训练得很好再训练生成器？</h3><hr><p>我们已知的是数据x，想要得到的是模型的参数$\theta$，因此，我们构造一个似然函数：</p><script type="math/tex; mode=display">p_g(X_{i}|\theta)</script><p>我们使用最大似然估计方法：</p><script type="math/tex; mode=display">\theta_{bst}=arg\underset{\theta}max\prod_{i=1}^{n}p_g(x_i|\theta)</script><p>取对数可得</p><script type="math/tex; mode=display">\begin{aligned}\theta_{bst}&=arg\underset{\theta}max\sum_{i=1}^{n}\log{p_g(x_i|\theta)}\\&\iff{arg\underset{\theta}maxE_{x\backsim{p_{data}}}\log{p_g(x_i|\theta)}}\\&=arg\underset{\theta}max\int_xp_{data}(x)\log{p_g(x_i|\theta)}\end{aligned}</script><script type="math/tex; mode=display">D_{KL}(P_{data}||P_{g})=E_{x\backsim{p_{data}}}(\log{p_{data}(x)}-\log{p_{g}(x)})</script><p>易看出前一项只与真实数据分布有关，与生成器模型无关。因此我们可以忽略它，当训练模型最小化的时候，我们只需要最大化后一项，即：</p><script type="math/tex; mode=display">E_{x\backsim{p_{data}}}\log{p_g(x)}</script><p>可转换为：</p><script type="math/tex; mode=display">\int_x{p_{data(x)}}\log{p_g(x)}dx</script><p>据最大似然估计方法，阿巴阿巴阿巴</p><hr>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;浅学一些数学知识&quot;&gt;&lt;a href=&quot;#浅学一些数学知识&quot; class=&quot;headerlink&quot; title=&quot;浅学一些数学知识&quot;&gt;&lt;/a&gt;&lt;strong&gt;浅学一些数学知识&lt;/strong&gt;&lt;/h2&gt;&lt;h3 id=&quot;信息量&quot;&gt;&lt;a href=&quot;#信息量&quot; clas</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>baseline</title>
    <link href="http://lazy.github.io/2022/04/27/baseline/"/>
    <id>http://lazy.github.io/2022/04/27/baseline/</id>
    <published>2022-04-27T08:35:09.000Z</published>
    <updated>2022-04-30T03:37:12.481Z</updated>
    
    <content type="html"><![CDATA[<h1 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h1><p><strong>VGG 网络结构</strong></p><p><img width="513" alt="image" src="https://user-images.githubusercontent.com/93063038/163182863-493b6f2f-7755-48bd-93e3-63285d68b3d1.png"></p><p>因为只使用了3x3卷积核， 尽管深度很大，网络中的权重数量相较具有更大卷积层宽度和感受野的网络并不大。</p><p><img width="933" alt="image" src="https://user-images.githubusercontent.com/93063038/163183370-5d7274ee-7dd9-432e-b8a9-884dbd8f20dc.png"></p><p><img src="https://user-images.githubusercontent.com/93063038/163183387-072af28e-a7d7-4f68-a4c5-7170e3a524f3.png" alt="image"></p><p><strong>3×3卷积的使用</strong></p><p><img src="https://user-images.githubusercontent.com/93063038/163291208-ddd9bef5-7734-42ce-978f-f3f98b2cd225.png" alt="image"></p><p>图为两个3×3卷积核的堆叠</p><p>1.可见两个3×3卷积核堆叠在原feature map中的感受野与一个5×5卷积核相同， 三个3x3的堆叠卷基层的感受野是7x7</p><p>2.可以把三个3x3的filter看成是一个7x7filter的分解中间层有非线性的分解, 并且起到<strong>隐式正则化</strong>的作用。</p><p>3.使用小卷积核减少了参数数量：</p><p>假设该卷积层的卷积核为3×3，为了清晰明了假设卷积层的输入和输出的特征图（featuremap）大小（其实是channel通道数）分别为C1，C2。说明：卷积核的应该是一个多维的矩阵K×K×channels，其中channels是由输入的featuremap的通道数决定的，而卷积层中卷积核的个数是由输出的featuremap的通道数决定的。<br>所以该卷积层的参数量是：<br>（3×3×C1）× C2<br>说明:（3×3×C1） —— 是每一个卷积核的参数量（输入）<br>          × C2 —— 是总共C2个卷积核（输出的通道数）</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;VGG&quot;&gt;&lt;a href=&quot;#VGG&quot; class=&quot;headerlink&quot; title=&quot;VGG&quot;&gt;&lt;/a&gt;VGG&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;VGG 网络结构&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img width=&quot;513&quot; alt=&quot;image&quot; src=</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>OpenMV实现靶点检测</title>
    <link href="http://lazy.github.io/2022/04/27/OpenMV%E5%AE%9E%E7%8E%B0%E9%9D%B6%E7%82%B9%E6%A3%80%E6%B5%8B/"/>
    <id>http://lazy.github.io/2022/04/27/OpenMV%E5%AE%9E%E7%8E%B0%E9%9D%B6%E7%82%B9%E6%A3%80%E6%B5%8B/</id>
    <published>2022-04-27T08:33:01.000Z</published>
    <updated>2022-04-27T08:34:20.859Z</updated>
    
    <content type="html"><![CDATA[<p>—— 未完</p><p>idea:</p><blockquote><p>初步想法是利用颜色信息对靶子进行检测</p><p>再对靶点进行定位。若效果不佳考虑部署TensorFlow Lite yolo进行目标检测</p><p>边缘检测</p><p>图像对比</p><p>先颜色识别后模块匹配</p><p>决定先色块识别定位靶子。舵机追踪靶子方位同时横向运动小车，令小车舵机与车身角度为90度时舵机对准靶子。转动小车使车身与舵机夹角为0度。使小车直行，并进行边缘检测，传回矩形靶子的长宽大小比例，分析数据并不断进行微调。戳中靶心后转动舵机寻找第二个靶子重复以上操做。</p></blockquote><p>1.设置窗口roi</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sensor.set_windowing(roi)</span><br></pre></td></tr></table></figure><blockquote><p>roi （回报率） （感兴趣的区域）（进行检测的区域）</p></blockquote><p>roi的格式是(x, y, w, h)的tupple</p><p>2.水平翻转图像，使小车视野与实际相同</p><p>水平方向翻转：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sensor.set_hmirror(True)</span><br></pre></td></tr></table></figure><p>3.获取区域内的平均颜色或者占面积最大的颜色信息</p><p>使用 Statistics</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">image.get_statistics(roi=Auto)</span><br></pre></td></tr></table></figure><p>4.寻找色块</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">image.find_blobs(thresholds, roi=Auto, x_stride=2, y_stride=1, invert=False, area_threshold=10, pixels_threshold=10, merge=False, margin=0, threshold_cb=None, merge_cb=None)</span><br></pre></td></tr></table></figure><ul><li>thresholds是<strong>颜色的阈值</strong>，注意：这个参数是一个<strong>列表</strong>，可以包含多个颜色。如果你只需要一个颜色，那么在这个列表中只需要有一个颜色值，如果你想要多个颜色阈值，那这个列表就需要多个颜色阈值。注意：在返回的<strong>色块对象blob可以调用code方法，来判断是什么颜色的色块</strong>。</li></ul><p><img width="583" alt="image" src="https://user-images.githubusercontent.com/93063038/164970009-1e6c157e-213c-4048-9d2c-45e6ed64a539.png"></p><p>阈值参数的结构</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">colour = (minL, maxL, minA, maxA, minB, maxB)</span><br></pre></td></tr></table></figure><p><strong>OpenMV 的IDE里加入了阈值选择工具</strong>      用他！</p><p>(50, 75, -60, -14, 12, 62)浅测一个绿色 感觉不是很准。。</p><p>靶点检测场地为200*200   调整x, y_stride    将merge设置为True</p><p><strong>blob.rect() 返回这个色块的外框——矩形元组(x, y, w, h)</strong></p><p><img width="493" alt="image" src="https://user-images.githubusercontent.com/93063038/164972113-651c1b87-43c5-4fd9-a565-0a2b59d7876f.png"></p><p>边缘检测</p><p>image.find_edges(edge_type[,threshold])</p><p>将图像变为黑白。边缘保留白色像素</p><p>edge_type 参数：image.EDGE_SIMPLE ——简单的阈值高通滤波算法</p><p>​                               image.EDGE_CANNY ——canny边缘检测</p><p>threshold —— 包含高低阈值的二元组 默认（100，200） 仅支持灰度图像</p><p>例程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Canny边缘检测:</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># 这个例子展示了Canny边缘检测。</span></span><br><span class="line"><span class="keyword">import</span> sensor, image, time</span><br><span class="line"></span><br><span class="line">sensor.reset() <span class="comment"># 初始化sensor.</span></span><br><span class="line"></span><br><span class="line">sensor.set_pixformat(sensor.GRAYSCALE) <span class="comment"># or sensor.RGB565</span></span><br><span class="line"><span class="comment">#设置图像色彩格式，有RGB565色彩图和GRAYSCALE灰度图两种</span></span><br><span class="line"></span><br><span class="line">sensor.set_framesize(sensor.QQVGA) <span class="comment"># or sensor.QVGA (or others)</span></span><br><span class="line"><span class="comment">#设置图像像素大小</span></span><br><span class="line"></span><br><span class="line">sensor.skip_frames(<span class="number">30</span>) <span class="comment"># 让新的设置生效</span></span><br><span class="line">sensor.set_gainceiling(<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">clock = time.clock() <span class="comment"># 跟踪FPS帧率</span></span><br><span class="line"><span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">    clock.tick() <span class="comment"># 追踪两个snapshots()之间经过的毫秒数.</span></span><br><span class="line">    img = sensor.snapshot() <span class="comment"># 拍一张照片并返回图像。</span></span><br><span class="line">    <span class="comment"># 使用Canny边缘检测器</span></span><br><span class="line">    img.find_edges(image.EDGE_CANNY, threshold=(<span class="number">50</span>, <span class="number">80</span>))</span><br><span class="line">    <span class="comment">#threshold设置阈值</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 更快更简单的边缘检测</span></span><br><span class="line">    <span class="comment">#img.find_edges(image.EDGE_SIMPLE, threshold=(100, 255))</span></span><br><span class="line">    <span class="built_in">print</span>(clock.fps()) <span class="comment"># 注意:你的OpenMV摄像头的运行速度只有它的一半</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import sensor, image, lcd</span><br><span class="line">#初始化摄像头</span><br><span class="line">sensor.reset() # 初始化摄像头模块.</span><br><span class="line">sensor.set_pixformat(sensor.GRAYSCALE) # 或者使用 sensor.RGB565 彩色</span><br><span class="line">sensor.set_framesize(sensor.QQVGA) # 或者使用 sensor.QVGA (or others)</span><br><span class="line">sensor.skip_frames(time = 2000) #延时让摄像头文稳定.</span><br><span class="line">sensor.set_gainceiling(8) #设置增益，这是官方推荐的参数</span><br><span class="line">lcd.init()                          # LCD初始化</span><br><span class="line">while(True):</span><br><span class="line">    img = sensor.snapshot() # 拍摄并返回图像.</span><br><span class="line">    #使用 Canny 边缘检测器</span><br><span class="line">    img.find_edges(image.EDGE_CANNY, threshold=(50, 80))</span><br><span class="line">    lcd.display(img)                # LCD显示img</span><br></pre></td></tr></table></figure><p><strong>舵机控制</strong></p><p>构造函数</p><blockquote><ul><li><p><em>class</em>pyb.Servo(<em>id</em>)</p><p>创建一个伺服对象。 <code>id</code> 为1-3，与引脚P7至P9相对应。</p></li></ul></blockquote><p>方法</p><ul><li><p>Servo.angle(<strong>[*</strong>angle<em>, </em>time=0<strong>*]</strong>)</p><p>若未给定参数，该函数返回当前角度。若给定函数，该函数设置servo的角度：<code>angle</code> 是度数计的移动的角度。<code>time</code> 是达到指定角度所用的毫秒数。若省略，则servo会尽快移动到新的位置。</p></li><li><p>Servo.speed(<strong>[*</strong>speed<em>, </em>time=0<strong>*]</strong>)</p><p>若未给定参数，该函数会返回当前速度。若给定参数，该函数设置servo的速度：<code>speed</code> 是改变的速度，取值100-100。<code>time</code> 是达到指定角度所用的毫秒数。若省略，则servo会尽快加速。</p></li><li><p>Servo.pulse_width(<strong>[*</strong>value<strong>*]</strong>)</p><p>若未给定参数，该函数会返回当前的原始脉宽值。若给定参数，该函数设置原始脉宽值。</p></li><li><p>Servo.calibration(<strong>[*</strong>pulse_min<em>, </em>pulse_max<em>, </em>pulse_centre<strong>*[</strong>, pulse_angle_90, <em>pulse_speed_100**</em>]<strong>**]</strong>)</p><p>若未给定参数，这个函数返回当前的5元组校准数据。若给定参数，该函数设定计时校准：<code>pulse_min</code> 是允许的最小脉宽。<code>pulse_max</code> 是允许的最大脉冲。<code>pulse_centre</code> 是中心/零位置对应的脉宽。<code>pulse_angle_90</code> 是90度对应的脉宽。<code>pulse_speed_100</code> 是速度100对应的脉宽。</p></li></ul><p>串口通信</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> pyb <span class="keyword">import</span> UART</span><br><span class="line"></span><br><span class="line">uart = UART(<span class="number">3</span>, <span class="number">19200</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">    uart.write(<span class="string">&quot;Hello World!\r&quot;</span>)</span><br><span class="line">    time.sleep_ms(<span class="number">1000</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>UART类</p><p>实例化一个串口， 波特率为19200的串口3</p><blockquote><p>注意：必须是串口3，因为OpenMV2只引出了这个串口，pyb的串口有好多个的。OpenMV3又增加了串口1。</p></blockquote><p>调用write方法传输数据   可传输Json数据</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;—— 未完&lt;/p&gt;
&lt;p&gt;idea:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;初步想法是利用颜色信息对靶子进行检测&lt;/p&gt;
&lt;p&gt;再对靶点进行定位。若效果不佳考虑部署TensorFlow Lite yolo进行目标检测&lt;/p&gt;
&lt;p&gt;边缘检测&lt;/p&gt;
&lt;p&gt;图像对比&lt;/p&gt;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>pytorch笔记</title>
    <link href="http://lazy.github.io/2022/04/24/pytorch%E7%AC%94%E8%AE%B0/"/>
    <id>http://lazy.github.io/2022/04/24/pytorch%E7%AC%94%E8%AE%B0/</id>
    <published>2022-04-24T07:01:09.000Z</published>
    <updated>2022-04-30T03:39:49.045Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一-张量"><a href="#一-张量" class="headerlink" title="一.张量"></a>一.张量</h3><h4 id="1-张量的数据类型"><a href="#1-张量的数据类型" class="headerlink" title="1.张量的数据类型"></a>1.张量的数据类型</h4><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202201311115752.png" alt="image-20220131111457646"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202201311137743.png" alt="image-20220131113706683"></p><p>默认数据类型为32位浮点型</p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202201311137323.png" alt="image-20220131113746252"></p><p><strong>torch.set_default_tensor_type()</strong>函数可设置默认的张量数据类型</p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202201311141394.png" alt="image-20220131114156317"></p><p><strong>a.long()  a.int()  a.float()方法</strong></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202201311143047.png" alt="image-20220131114336959"></p><h4 id="2-张量的生成"><a href="#2-张量的生成" class="headerlink" title="2.张量的生成"></a>2.张量的生成</h4><p>(1)列表或序列可通过<strong>torch.tensor()</strong>函数构造张量</p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202011519786.png" alt="image-20220201151919676"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202201311204496.png" alt="image-20220131120443462"></p><p><strong>.shape .size .numel()</strong>方法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a  = torch.randn((<span class="number">2</span>,<span class="number">3</span>,<span class="number">5</span>),dtype = torch.float32)</span><br><span class="line"><span class="built_in">print</span>(a.shape)<span class="comment">#打印“torch.Size([2,3,5])”不需要加括号，直接访问成员属性，返回的是torch.Size类对象，</span></span><br><span class="line"><span class="built_in">print</span>(a.shape[<span class="number">1</span>])<span class="comment">#可以使用[]索引访问,所以size属性是一个迭代器</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(a.size())<span class="comment">#打印“torch.Size([2,3,5])”,与shape属性一致</span></span><br><span class="line"><span class="built_in">print</span>(a.size(<span class="number">1</span>))<span class="comment">#可传入参数，返回3，即第i维的个数</span></span><br><span class="line"><span class="built_in">print</span>(a.numel)<span class="comment">#返回30，计算张量中包含元素数量</span></span><br></pre></td></tr></table></figure><p>通过<strong>torch.tensor()</strong>函数构造张量可使用<strong>dtype</strong>参数指定数据类型，使用requires_grad来指定是否需要计算梯度</p><p>(2)<strong>torch.Tensor()</strong>——————一个类</p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202011523056.png" alt="image-20220201152349906"></p><p>可以生成指定形状的张量</p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202011543977.png" alt="image-20220201154329908"></p><p>(3)<strong>torch.from_numpy(ndarray)</strong>  <strong>torch.as_tensor()</strong></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202011545516.png" alt="image-20220201154511394"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202011603578.png" alt="image-20220201160311505"></p><p>(4)依据数值创建</p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202011548415.png" alt="image-20220201154817290"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202011549781.png" alt="image-20220201154949675"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202011552566.png" alt="image-20220201155232420"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202011553085.png" alt="image-20220201155307992"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202011554567.png" alt="image-20220201155410450"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202011554715.png" alt="image-20220201155438613"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202011555299.png" alt="image-20220201155534168"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202011555716.png" alt="image-20220201155557606"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202020945847.png" alt="image-20220202094539781"></p><p><strong>torch.empty()</strong>————返回填充有未初始化数据的张量，张量的形状由可变的参数大小定义</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.empty(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">tensor(<span class="number">1.00000e-08</span> *</span><br><span class="line">       [[ <span class="number">6.3984</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>],</span><br><span class="line">        [ <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>]])</span><br></pre></td></tr></table></figure><p>(5)依据概率分布创建张量</p><p><strong>torch.manual_seed()</strong>——————指定生成随机数种子</p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202011604558.png" alt="image-20220201160448443"></p><p> <img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202011614983.png" alt="image-20220201161451904"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202011615034.png" alt="image-20220201161514884"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202011616898.png" alt="image-20220201161608761"></p><h4 id="3-张量的操作"><a href="#3-张量的操作" class="headerlink" title="3.张量的操作"></a>3.张量的操作</h4><h5 id="（1）张量的拼接与切分"><a href="#（1）张量的拼接与切分" class="headerlink" title="（1）张量的拼接与切分"></a>（1）张量的拼接与切分</h5><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202021015601.png" alt="image-20220202101504497"></p><p><strong>torch.stack()</strong>会拓展张量维度</p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202021018613.png" alt="image-20220202101844509"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202021020023.png" alt="image-20220202102018924"></p><h5 id="（2）张量索引"><a href="#（2）张量索引" class="headerlink" title="（2）张量索引"></a>（2）张量索引</h5><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202021023763.png" alt="image-20220202102350596"></p><p>==注意index参数的数据类型必须是torch.long==</p><p>例</p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202021030467.png" alt="image-20220202103022392"></p><p>(对第0维度进行索引（相当于索引第一维度）)</p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202021032248.png" alt="image-20220202103238169"></p><h5 id="（3）张量变换"><a href="#（3）张量变换" class="headerlink" title="（3）张量变换"></a>（3）张量变换</h5><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202021034687.png" alt="image-20220202103425616"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202041220593.png" alt="image-20220204122005493"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202041236220.png" alt="image-20220204123625169"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202041234792.png" alt="image-20220204123440698"></p><p>==注意reshape共享数据内存==</p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202021037649.png" alt="image-20220202103706542"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202021038823.png" alt="image-20220202103810700"></p><p>如图：</p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202021039152.png" alt="image-20220202103951071"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202041702785.png" alt="image-20220204170210714"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202041707930.png" alt="image-20220204170737883"></p><p>沿着指定的维度重复tensor。不同与expand()，本函数复制的是tensor中的数据。扩展（expand）张量不会分配新的内存，只是在存在的张量上创建一个新的视图（view），一个大小（size）等于1的维度扩展到更大的尺寸。repeat沿着特定的维度重复这个张量，和expand()不同的是，这个函数拷贝张量的数据。</p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202041716152.png" alt="image-20220204171657106"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202041717585.png" alt="image-20220204171731493"></p><h5 id="（4）张量数学运算"><a href="#（4）张量数学运算" class="headerlink" title="（4）张量数学运算"></a>（4）张量数学运算</h5><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202021045502.png" alt="image-20220202104524351"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202021044623.png" alt="image-20220202104455497"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202041733245.png" alt="image-20220204173330127"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202041913380.png" alt="image-20220204191336309"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202041914954.png" alt="image-20220204191459872"></p><p>真多啊。。。用到再查叭。</p><h3 id="二-pytorch中的自动求导"><a href="#二-pytorch中的自动求导" class="headerlink" title="二.pytorch中的自动求导"></a>二.pytorch中的自动求导</h3><p>将张量的<strong>requires_grad参数</strong>设为Ture可自动求导得到其梯度</p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202042022817.png" alt="image-20220204202233657"></p><p><strong>Tensor()类的重要属性：</strong></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202042036027.png" alt="image-20220204203646918"></p><p>在Pytorch中，默认情况下，非叶节点的梯度值在反向传播过程中使用完后就会被清除，不会被保留。<strong>只有叶子节点的梯度值能够被保留下来</strong></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202042032787.png" alt="image-20220204203208599"></p><h4 id="retain-grad"><a href="#retain-grad" class="headerlink" title="retain_grad()"></a>retain_grad()</h4><p>可保存非叶子节点梯度</p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202042033410.png" alt="image-20220204203319272"></p><p>grad_fn：记录创建该张量时所用的方法（函数）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;grad_fn:&quot;</span>, w.grad_fn, x.grad_fn, a.grad_fn, b.grad_fn, y.grad_fn)</span><br><span class="line"><span class="comment"># Out：grad_fn: None None &lt;AddBackward0 object at 0x000001C04BB24788&gt; &lt;AddBackward0 object at 0x000001C04605D188&gt; &lt;MulBackward0 object at 0x000001C04605D1C8&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="autograd"><a href="#autograd" class="headerlink" title="autograd"></a>autograd</h4><h5 id="torch-autograd-backward"><a href="#torch-autograd-backward" class="headerlink" title="torch.autograd.backward"></a>torch.autograd.backward</h5><p>张量中的backward()方法直接调用了torch.autograd.backward()</p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202042048465.png" alt="image-20220204204833276"></p><p><strong>retain_graph</strong>参数设置为True，得以进行两次反向传播</p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202051129435.png" alt="image-20220205112941344"></p><p><strong>grad_tensors</strong>参数用于多梯度权重的设置</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">w = torch.tensor([<span class="number">1.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">    x = torch.tensor([<span class="number">2.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    a = torch.add(w, x)     <span class="comment"># retain_grad()</span></span><br><span class="line">    b = torch.add(w, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    y0 = torch.mul(a, b)    <span class="comment"># y0 = (x+w) * (w+1)</span></span><br><span class="line">    y1 = torch.add(a, b)    <span class="comment"># y1 = (x+w) + (w+1)    dy1/dw = 2</span></span><br><span class="line"></span><br><span class="line">    loss = torch.cat([y0, y1], dim=<span class="number">0</span>)       <span class="comment"># [y0, y1]</span></span><br><span class="line">    grad_tensors = torch.tensor([<span class="number">1.</span>, <span class="number">1.</span>])</span><br><span class="line">    <span class="comment"># grad_tensors = torch.tensor([1., 2.])</span></span><br><span class="line"></span><br><span class="line">    loss.backward(gradient=grad_tensors)    <span class="comment"># gradient 传入 torch.autograd.backward()中的grad_tensors</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(w.grad)</span><br><span class="line">    </span><br><span class="line">    out：<span class="number">7</span> <span class="comment"># 9</span></span><br></pre></td></tr></table></figure><h5 id="torch-autograd-grad"><a href="#torch-autograd-grad" class="headerlink" title="torch.autograd.grad"></a>torch.autograd.grad</h5><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202042059611.png" alt="image-20220204205947396"></p><p><strong>create_graph</strong>   创建导数计算图，用于高阶求导</p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202051145014.png" alt="image-20220205114554928"></p><h5 id="autograd小贴士："><a href="#autograd小贴士：" class="headerlink" title="autograd小贴士："></a>autograd小贴士：</h5><p>1.梯度不自动清零</p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202051150324.png" alt="image-20220205115044251"></p><p>使用<strong>grad.zero_()</strong>  对梯度清零</p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202051151087.png" alt="image-20220205115154019"></p><p>2.依赖于叶子节点的节点， requires_grad默认为True</p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202051155322.png" alt="image-20220205115547253"></p><p>3.叶子节点不可执行in-place操作</p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202051200092.png" alt="image-20220205120026028"></p><p>可知+=操作时不改变内存地址，为in-place操作，不可对叶子节点执行</p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202051202037.png" alt="image-20220205120213991"></p><h3 id="三-torch-nn模块"><a href="#三-torch-nn模块" class="headerlink" title="三.torch.nn模块"></a>三.torch.nn模块</h3><h4 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h4><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202190444179.png" alt="image-20220219044440063"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202190444944.png" alt="image-20220219044452816"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202190448651.png" alt="image-20220219044809497"></p><h4 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h4><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202051346913.png" alt="image-20220205134635851"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 以torch.nn.Conv2d()为例， 介绍卷积再图像上的使用方法，其调用方式为：</span></span><br><span class="line">torch.nn.Conv2d(in_channels,</span><br><span class="line">               out_channels,</span><br><span class="line">               kernel_size,</span><br><span class="line">               stride=<span class="number">1</span>,</span><br><span class="line">               padding=<span class="number">0</span>,</span><br><span class="line">               dilation=<span class="number">1</span>,</span><br><span class="line">               groups=<span class="number">1</span>,</span><br><span class="line">               bias=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202051349651.png" alt="image-20220205134953580"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line">myim = Image.<span class="built_in">open</span>(<span class="string">&quot;lenna.jpg&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">myimgray = np.array(myim.convert(<span class="string">&quot;L&quot;</span>), dtype=np.float32)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">imh, imw = myimgray.shape</span><br><span class="line">myimgray_t = torch.from_numpy(myimgray.reshape((<span class="number">1</span>, <span class="number">1</span>, imh, imw)))</span><br><span class="line"></span><br><span class="line">kersize = <span class="number">5</span></span><br><span class="line">ker = torch.ones(kersize, kersize, dtype=torch.float32)*-<span class="number">1</span></span><br><span class="line">ker[<span class="number">2</span>, <span class="number">2</span>] = <span class="number">24</span></span><br><span class="line">ker = ker.reshape((<span class="number">1</span>, <span class="number">1</span>, kersize, kersize))</span><br><span class="line"></span><br><span class="line">conv2d = nn.Conv2d(<span class="number">1</span>, <span class="number">2</span>, (kersize, kersize), bias = <span class="literal">False</span>)</span><br><span class="line">conv2d.weight.data[<span class="number">0</span>] = ker</span><br><span class="line">imconv2dout = conv2d(myimgray_t)</span><br><span class="line">imconv2dout_im = imconv2dout.data.squeeze()</span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">plt.imshow(imconv2dout_im[<span class="number">0</span>], cmap=plt.cm.gray)</span><br><span class="line">plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202070301469.png" alt="image-20220207030119312"></p><p><strong>可见使用边缘特征提取卷积核很好的提取出了图像的边缘信息</strong></p><h4 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h4><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202070317522.png" alt="image-20220207031712430"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202070317316.png" alt="image-20220207031744256"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202130929419.png" alt="image-20220213092921319"></p><h4 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h4><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202130930276.png" alt="image-20220213093044229"></p><h4 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h4><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202130950880.png" alt="image-20220213095021812"></p><h3 id="四-pytorch中的数据操作与预处理"><a href="#四-pytorch中的数据操作与预处理" class="headerlink" title="四.pytorch中的数据操作与预处理"></a>四.pytorch中的数据操作与预处理</h3><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202130951963.png" alt="image-20220213095134915"></p><h4 id="Dataloader"><a href="#Dataloader" class="headerlink" title="Dataloader"></a>Dataloader</h4><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202190325547.png" alt="image-20220219032522337"></p><h4 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h4><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202190326166.png" alt="image-20220219032624056"></p><h4 id="transforms"><a href="#transforms" class="headerlink" title="transforms"></a>transforms</h4><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202190354368.png" alt="image-20220219035439267"></p><h4 id="crop"><a href="#crop" class="headerlink" title="crop"></a>crop</h4><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202190357254.png" alt="image-20220219035758981"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202190402535.png" alt="image-20220219040238390"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202190407217.png" alt="image-20220219040747063"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202190407901.png" alt="image-20220219040715776"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202190409623.png" alt="image-20220219040934500"></p><h4 id="flip"><a href="#flip" class="headerlink" title="flip"></a>flip</h4><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202190413544.png" alt="image-20220219041354431"></p><h4 id="rotation"><a href="#rotation" class="headerlink" title="rotation"></a>rotation</h4><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202190417363.png" alt="image-20220219041707239"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202190425111.png" alt="image-20220219042546974"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202190426940.png" alt="image-20220219042619787"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202190427628.png" alt="image-20220219042739525"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202190428019.png" alt="image-20220219042807856"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202190428461.png" alt="image-20220219042851339"></p><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202190430602.png" alt="image-20220219043053494"></p><h4 id="transforms的操作"><a href="#transforms的操作" class="headerlink" title="transforms的操作"></a>transforms的操作</h4><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202190431831.png" alt="image-20220219043148686"></p><h4 id="自定义transforms"><a href="#自定义transforms" class="headerlink" title="自定义transforms"></a>自定义transforms</h4><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202190434716.png" alt="image-20220219043402594"></p><h3 id="正态分布与平方损失"><a href="#正态分布与平方损失" class="headerlink" title="正态分布与平方损失"></a>正态分布与平方损失</h3><p>接下来，我们通过对噪声分布的假设来解读平方损失目标函数。</p><p>正态分布和线性回归之间的关系很密切。 正态分布（normal distribution），也称为<em>高斯分布</em>（Gaussian distribution）， 最早由德国数学家高斯（Gauss）应用于天文学研究。 简单的说，若随机变量xx具有均值μμ和方差σ2σ2（标准差σσ），其正态分布概率密度函数如下：</p><p>(3.1.11)</p><p>p(x)=12πσ2−−−−√exp(−12σ2(x−μ)2).p(x)=12πσ2exp⁡(−12σ2(x−μ)2).</p><p>下面我们定义一个Python函数来计算正态分布。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def normal(x, mu, sigma):</span><br><span class="line">    p = 1 / math.sqrt(2 * math.pi * sigma**2)</span><br><span class="line">    return p * np.exp(-0.5 / sigma**2 * (x - mu)**2)</span><br></pre></td></tr></table></figure><p>我们现在可视化正态分布。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 再次使用numpy进行可视化</span><br><span class="line">x = np.arange(-7, 7, 0.01)</span><br><span class="line"></span><br><span class="line"># 均值和标准差对</span><br><span class="line">params = [(0, 1), (0, 2), (3, 1)]</span><br><span class="line">d2l.plot(x, [normal(x, mu, sigma) for mu, sigma in params], xlabel=&#x27;x&#x27;,</span><br><span class="line">         ylabel=&#x27;p(x)&#x27;, figsize=(4.5, 2.5),</span><br><span class="line">         legend=[f&#x27;mean &#123;mu&#125;, std &#123;sigma&#125;&#x27; for mu, sigma in params])</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/chen-zeyu0/wohaoxiangshuijiao/raw/master/img/202202231627780.png" alt="image-20220223162721741"></p><p>就像我们所看到的，改变均值会产生沿xx轴的偏移，增加方差将会分散分布、降低其峰值。</p><p>均方误差损失函数（简称均方损失）可以用于线性回归的一个原因是： 我们假设了观测中包含噪声，其中噪声服从正态分布。 噪声正态分布如下式:</p><p>(3.1.12)</p><p>y=w⊤x+b+ϵ,y=w⊤x+b+ϵ,</p><p>其中，ϵ∼N(0,σ2)ϵ∼N(0,σ2)。</p><p>因此，我们现在可以写出通过给定的xx观测到特定yy的<em>似然</em>（likelihood）：</p><p>(3.1.13)</p><p>P(y∣x)=12πσ2−−−−√exp(−12σ2(y−w⊤x−b)2).P(y∣x)=12πσ2exp⁡(−12σ2(y−w⊤x−b)2).</p><p>现在，根据极大似然估计法，参数ww和bb的最优值是使整个数据集的<em>似然</em>最大的值：</p><p>(3.1.14)</p><p>P(y∣X)=∏i=1np(y(i)|x(i)).P(y∣X)=∏i=1np(y(i)|x(i)).</p><p>根据极大似然估计法选择的估计量称为<em>极大似然估计量</em>。 虽然使许多指数函数的乘积最大化看起来很困难， 但是我们可以在不改变目标的前提下，通过最大化似然对数来简化。 由于历史原因，优化通常是说最小化而不是最大化。 我们可以改为<em>最小化负对数似然</em>−logP(y∣X)−log⁡P(y∣X)。 由此可以得到的数学公式是：</p><p>(3.1.15)</p><p>−logP(y∣X)=∑i=1n12log(2πσ2)+12σ2(y(i)−w⊤x(i)−b)2.−log⁡P(y∣X)=∑i=1n12log⁡(2πσ2)+12σ2(y(i)−w⊤x(i)−b)2.</p><p>现在我们只需要假设σσ是某个固定常数就可以忽略第一项， 因为第一项不依赖于ww和bb。 现在第二项除了常数1σ21σ2外，其余部分和前面介绍的均方误差是一样的。 幸运的是，上面式子的解并不依赖于σσ。 因此，在高斯噪声的假设下，最小化均方误差等价于对线性模型的极大似然估计。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;一-张量&quot;&gt;&lt;a href=&quot;#一-张量&quot; class=&quot;headerlink&quot; title=&quot;一.张量&quot;&gt;&lt;/a&gt;一.张量&lt;/h3&gt;&lt;h4 id=&quot;1-张量的数据类型&quot;&gt;&lt;a href=&quot;#1-张量的数据类型&quot; class=&quot;headerlink&quot; title=</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>jetson配置日志</title>
    <link href="http://lazy.github.io/2022/04/16/jetson%E9%85%8D%E7%BD%AE%E6%97%A5%E5%BF%97/"/>
    <id>http://lazy.github.io/2022/04/16/jetson%E9%85%8D%E7%BD%AE%E6%97%A5%E5%BF%97/</id>
    <published>2022-04-16T11:16:25.000Z</published>
    <updated>2022-04-16T11:18:27.775Z</updated>
    
    <content type="html"><![CDATA[<h4 id="jetson-nano-apt更换国内源"><a href="#jetson-nano-apt更换国内源" class="headerlink" title="jetson nano apt更换国内源"></a>jetson nano apt更换国内源</h4><p>备份source.list文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak  </span><br></pre></td></tr></table></figure><p>修改source.list文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/apt/sources.list</span><br></pre></td></tr></table></figure><p>删除所有内容，并复制：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic main multiverse restricted universe</span><br><span class="line">deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-security main multiverse restricted universe</span><br><span class="line">deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-updates main multiverse restricted universe</span><br><span class="line">deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-backports main multiverse restricted universe</span><br><span class="line">deb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic main multiverse restricted universe</span><br><span class="line">deb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-security main multiverse restricted universe</span><br><span class="line">deb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-updates main multiverse restricted universe</span><br><span class="line">deb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-backports main multiverse restricted universe</span><br></pre></td></tr></table></figure><p><strong>注意arm架构下的apt源与普通的ubuntu不相同</strong></p><p>then</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get upgrade</span><br></pre></td></tr></table></figure><h4 id="jtop安装"><a href="#jtop安装" class="headerlink" title="jtop安装"></a>jtop安装</h4><p>先安装pip</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install python3-pip</span><br></pre></td></tr></table></figure><p>then</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pip3 install jetson-stats -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo jtop # 打开jtop</span><br></pre></td></tr></table></figure><h4 id="zerotier安装使用（内网穿透）"><a href="#zerotier安装使用（内网穿透）" class="headerlink" title="zerotier安装使用（内网穿透）"></a>zerotier安装使用（内网穿透）</h4><p>安装命令</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -s  https://install.zerotier.com  | sudo bash</span><br></pre></td></tr></table></figure><p>加入网络</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo zerotier-cli join xxxxxxxxxxxxxxxx</span><br></pre></td></tr></table></figure><p>离开网络</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo zerotier-cli leave xxxxxxxxxxxxxxxx</span><br></pre></td></tr></table></figure><p>启动</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl start zerotier-one.service</span><br></pre></td></tr></table></figure><p>设置开机自启</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl enable zerotier-one.service</span><br></pre></td></tr></table></figure><h4 id="minifoege-安装"><a href="#minifoege-安装" class="headerlink" title="minifoege 安装"></a>minifoege 安装</h4><p><a class="link" href="https://github.com/conda-forge/miniforge">https://github.com/conda-forge/miniforge<i class="fas fa-external-link-alt"></i></a></p><p>在jetson nano中选择Mambaforge时 出现了pip 无法使用 illegal instruction(core dumped) 的问题</p><p>安装miniforge后在虚拟环境中出现同样问题， 但能在base环境下正常使用pip</p><p>所以选择使用它</p><p><img src="https://user-images.githubusercontent.com/93063038/162883166-e1713007-a6da-4fab-8f04-23caa255487c.png" alt="image"></p><p>在Miniforge-Linux-aarch64.sh所在文件夹打开终端</p><p>执行</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash Miniforge-Linux-aarch64.sh</span><br></pre></td></tr></table></figure><p>全yes即可</p><h4 id="conda更换国内镜像源"><a href="#conda更换国内镜像源" class="headerlink" title="conda更换国内镜像源"></a>conda更换国内镜像源</h4><p>配置清华源：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/</span><br><span class="line">#设置搜索时显示通道地址</span><br><span class="line">conda config --set show_channel_urls yes</span><br></pre></td></tr></table></figure><p>可执行conda config —show channels显示已添加的源</p><h4 id="pip更换国内镜像源"><a href="#pip更换国内镜像源" class="headerlink" title="pip更换国内镜像源"></a>pip更换国内镜像源</h4><p>编辑pip配置文件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir ~/.pip</span><br><span class="line">vim ~/.pip/pip.conf</span><br></pre></td></tr></table></figure><p>添加内容为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[global]</span><br><span class="line">index-url = https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">[install]</span><br><span class="line">trusted-host = https://pypi.tuna.tsinghua.edu.cn</span><br></pre></td></tr></table></figure><h4 id="conda更改base环境下python版本"><a href="#conda更改base环境下python版本" class="headerlink" title="conda更改base环境下python版本"></a>conda更改base环境下python版本</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install python=&lt;版本号&gt;</span><br></pre></td></tr></table></figure><p>（看网上都是这么干的， 但由于我们想换版本时已经无意中在base环境下下载了很多包， 所以由于依赖问题这样会报错）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda clean -a # 删除所有包</span><br></pre></td></tr></table></figure><h4 id="jetson-nano-和-jetson-nx-配置-cuda"><a href="#jetson-nano-和-jetson-nx-配置-cuda" class="headerlink" title="jetson nano 和 jetson nx 配置 cuda"></a>jetson nano 和 jetson nx 配置 cuda</h4><p>jetson nano 与 nx 已经内置好了cuda， 但需要配置环境变量才能使用</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bashrc</span><br></pre></td></tr></table></figure><p>在.bashrc文件中添加：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export PATH=/usr/local/cuda-10.2/bin:$PATH</span><br><span class="line">export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH</span><br><span class="line">export CUDA_HOME=/usr/local/cuda-10.2</span><br><span class="line">export OPENBLAS_CORETYPE=ARMV8# 据说不加的话，运行相关的项目会内核崩掉（but在我配置nano环境时即使加上也无济于事）</span><br></pre></td></tr></table></figure><p>再次执行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure><p>最后输入nvcc -V 测试环境变量是否设置正确</p><h4 id="cv2-torch等由于numpy问题报错illegal-instruction-core-dumped"><a href="#cv2-torch等由于numpy问题报错illegal-instruction-core-dumped" class="headerlink" title="cv2, torch等由于numpy问题报错illegal instruction(core dumped)"></a>cv2, torch等由于numpy问题报错illegal instruction(core dumped)</h4><p>我们下载的numpy版本是1.19.5</p><p>在base环境中测试了几个版本发现都没有问题</p><p>于是换了个numpy版本就解决了（大概是1.19.5版本的numpy在arm架构下出了点问题）</p><h4 id="在linux下使用opencv无法打开摄像头问题-WARN-0-global-io-opencv-modules-videoio-src-cap-v4l-cpp-893-open-VIDEOIO-V4L2-dev-video0-can’t-open-camera-by-index"><a href="#在linux下使用opencv无法打开摄像头问题-WARN-0-global-io-opencv-modules-videoio-src-cap-v4l-cpp-893-open-VIDEOIO-V4L2-dev-video0-can’t-open-camera-by-index" class="headerlink" title="在linux下使用opencv无法打开摄像头问题[ WARN:0] global /io/opencv/modules/videoio/src/cap_v4l.cpp (893) open VIDEOIO(V4L2:/dev/video0): can’t open camera by index"></a>在linux下使用opencv无法打开摄像头问题[ WARN:0] global /io/opencv/modules/videoio/src/cap_v4l.cpp (893) open VIDEOIO(V4L2:/dev/video0): can’t open camera by index</h4><p>发现是重复调用摄像头导致的：</p><p>两次使用了<strong>cv2.VideoCapture(0)</strong></p><p>删去一个就可以了</p><p>除此之外还遇到了另一个报错令代码无法运行（忘记记录了），原因是opencv版本太高， 降了几个版本就解决了</p><h4 id="报错This-plugin-does-not-support-propagateSizeHints-，-图形界面控件消失"><a href="#报错This-plugin-does-not-support-propagateSizeHints-，-图形界面控件消失" class="headerlink" title="报错This plugin does not support propagateSizeHints()， 图形界面控件消失"></a>报错This plugin does not support propagateSizeHints()， 图形界面控件消失</h4><p>网上的解决方案都奇奇怪怪的（我看不明白）</p><p>在使用管理员权限运行代码后神奇的成功了</p><p>sudo python main.py</p><h4 id="pyside2的安装"><a href="#pyside2的安装" class="headerlink" title="pyside2的安装"></a>pyside2的安装</h4><p>在网上没有找到支持arm架构的pyside2 whl安装包</p><p>所以我们自己编译了pyside2</p><h4 id="dlib安装"><a href="#dlib安装" class="headerlink" title="dlib安装"></a>dlib安装</h4><h4 id="torch和torchvision的安装"><a href="#torch和torchvision的安装" class="headerlink" title="torch和torchvision的安装"></a>torch和torchvision的安装</h4>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;jetson-nano-apt更换国内源&quot;&gt;&lt;a href=&quot;#jetson-nano-apt更换国内源&quot; class=&quot;headerlink&quot; title=&quot;jetson nano apt更换国内源&quot;&gt;&lt;/a&gt;jetson nano apt更换国内源&lt;/h4&gt;&lt;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Json学习笔记</title>
    <link href="http://lazy.github.io/2022/04/10/Json%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://lazy.github.io/2022/04/10/Json%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</id>
    <published>2022-04-10T13:50:24.000Z</published>
    <updated>2022-04-13T11:44:18.018Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#json">JSON</a><ul><li><a href="#json-语法规则">JSON 语法规则</a></li><li><a href="#json-名称值对">JSON 名称/值对</a></li><li><a href="#json-值">JSON 值</a></li><li><a href="#json-文件">JSON 文件</a></li><li><a href="#json对象">JSON对象</a><ul><li><a href="#使用点号访问对象值">使用点号访问对象值</a></li><li><a href="#使用点号-或者中括号-来访问嵌套的json对象">使用点号. 或者中括号 [] 来访问嵌套的JSON对象。</a></li><li><a href="#修改json值">修改JSON值</a></li><li><a href="#修改对象属性">修改对象属性</a></li></ul></li><li><a href="#json数组">JSON数组</a><ul><li><a href="#数组可以作为json对象">数组可以作为JSON对象</a></li><li><a href="#json对象中的数组">JSON对象中的数组</a></li><li><a href="#嵌套-json-对象中的数组">嵌套 JSON 对象中的数组</a></li></ul></li></ul></li><li><a href="#python-json">Python json</a><ul><li><a href="#jsondumps">json.dumps</a></li><li><a href="#jsonloads">json.loads</a></li></ul></li></ul><!-- tocstop --><h3 id="JSON"><a href="#JSON" class="headerlink" title="JSON"></a>JSON</h3><p>JSON: <strong>J</strong>ava<strong>S</strong>cript <strong>O</strong>bject <strong>N</strong>otation(JavaScript 对象表示法)</p><h4 id="JSON-语法规则"><a href="#JSON-语法规则" class="headerlink" title="JSON 语法规则"></a>JSON 语法规则</h4><p>JSON 语法是 JavaScript 对象表示语法的子集。</p><ul><li>数据在名称/值对中</li><li>数据由逗号分隔</li><li>大括号 <strong>{}</strong> 保存对象</li><li>中括号 <strong>[]</strong> 保存数组，数组可以包含多个对象</li></ul><h4 id="JSON-名称-值对"><a href="#JSON-名称-值对" class="headerlink" title="JSON 名称/值对"></a>JSON 名称/值对</h4><p>JSON 数据的书写格式是：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">key <span class="punctuation">:</span> value</span><br></pre></td></tr></table></figure><p>名称/值对包括字段名称（在双引号中），后面写一个冒号，然后是值：</p><p>“name” : “菜鸟教程”</p><h4 id="JSON-值"><a href="#JSON-值" class="headerlink" title="JSON 值"></a>JSON 值</h4><p>JSON 值可以是：</p><ul><li>数字（整数或浮点数）</li><li>字符串（在双引号中）</li><li>逻辑值（true 或 false）</li><li>数组（在中括号中）</li><li>对象（在大括号中）</li><li>null</li></ul><h4 id="JSON-文件"><a href="#JSON-文件" class="headerlink" title="JSON 文件"></a>JSON 文件</h4><ul><li>JSON 文件的文件类型是 <strong>.json</strong></li><li>JSON 文本的 MIME 类型是 <strong>application/json</strong></li></ul><p>MINE类型：媒体类型（通常称为 Multipurpose Internet Mail Extensions 或 MIME 类型 ）是一种标准，用来表示文档、文件或字节流的性质和格式。 它在IETF RFC 6838中进行了定义和标准化。</p><h4 id="JSON对象"><a href="#JSON对象" class="headerlink" title="JSON对象"></a>JSON对象</h4><p>必须在大括号{}中书写，</p><p>key必须是字符串，value可以是合法的JSON数据类型（见JSON值）</p><h5 id="使用点号访问对象值"><a href="#使用点号访问对象值" class="headerlink" title="使用点号访问对象值"></a>使用点号访问对象值</h5><p>例：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">var myobj<span class="punctuation">,</span> x;</span><br><span class="line">myobj = <span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;runoob&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;alexa&quot;</span><span class="punctuation">:</span><span class="number">10000</span><span class="punctuation">,</span> <span class="attr">&quot;site&quot;</span><span class="punctuation">:</span><span class="keyword">null</span><span class="punctuation">&#125;</span>;</span><br><span class="line">x = myobj<span class="punctuation">[</span><span class="string">&quot;name&quot;</span><span class="punctuation">]</span>;</span><br></pre></td></tr></table></figure><h5 id="使用点号-或者中括号-来访问嵌套的JSON对象。"><a href="#使用点号-或者中括号-来访问嵌套的JSON对象。" class="headerlink" title="使用点号. 或者中括号 [] 来访问嵌套的JSON对象。"></a>使用点号. 或者中括号 [] 来访问嵌套的JSON对象。</h5><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = myobj.sites.site1;</span><br><span class="line">x = myobj.sites<span class="punctuation">[</span><span class="string">&quot;site1&quot;</span><span class="punctuation">]</span>;</span><br></pre></td></tr></table></figure><h5 id="修改JSON值"><a href="#修改JSON值" class="headerlink" title="修改JSON值"></a>修改JSON值</h5><p>使用点号访问并修改</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">myobj.sites.site1 = <span class="string">&quot;sxasxaxa&quot;</span></span><br></pre></td></tr></table></figure><p>使用中括号访问并修改</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">myobj.sites.<span class="punctuation">[</span><span class="string">&quot;site1&quot;</span><span class="punctuation">]</span> = <span class="string">&quot;sadadsad&quot;</span></span><br></pre></td></tr></table></figure><h5 id="修改对象属性"><a href="#修改对象属性" class="headerlink" title="修改对象属性"></a>修改对象属性</h5><p>使用delete关键字来删除JSON对象的属性：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">delete myobj.sites.site1</span><br></pre></td></tr></table></figure><h4 id="JSON数组"><a href="#JSON数组" class="headerlink" title="JSON数组"></a>JSON数组</h4><h5 id="数组可以作为JSON对象"><a href="#数组可以作为JSON对象" class="headerlink" title="数组可以作为JSON对象"></a>数组可以作为JSON对象</h5><p>例：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">[</span> <span class="string">&quot;Google&quot;</span><span class="punctuation">,</span> <span class="string">&quot;Runoob&quot;</span><span class="punctuation">,</span> <span class="string">&quot;Taobao&quot;</span> <span class="punctuation">]</span></span><br></pre></td></tr></table></figure><h5 id="JSON对象中的数组"><a href="#JSON对象中的数组" class="headerlink" title="JSON对象中的数组"></a>JSON对象中的数组</h5><p>例：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line"><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;网站&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;num&quot;</span><span class="punctuation">:</span><span class="number">3</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;sites&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span> <span class="string">&quot;Google&quot;</span><span class="punctuation">,</span> <span class="string">&quot;Runoob&quot;</span><span class="punctuation">,</span> <span class="string">&quot;Taobao&quot;</span> <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><h5 id="嵌套-JSON-对象中的数组"><a href="#嵌套-JSON-对象中的数组" class="headerlink" title="嵌套 JSON 对象中的数组"></a>嵌套 JSON 对象中的数组</h5><p>JSON 对象中数组可以包含另外一个数组，或者另外一个 JSON 对象：</p><p>例：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">myObj = <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;网站&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;num&quot;</span><span class="punctuation">:</span><span class="number">3</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;sites&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span> <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;Google&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;info&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span> <span class="string">&quot;Android&quot;</span><span class="punctuation">,</span> <span class="string">&quot;Google 搜索&quot;</span><span class="punctuation">,</span> <span class="string">&quot;Google 翻译&quot;</span> <span class="punctuation">]</span> <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="punctuation">&#123;</span> <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;Runoob&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;info&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span> <span class="string">&quot;菜鸟教程&quot;</span><span class="punctuation">,</span> <span class="string">&quot;菜鸟工具&quot;</span><span class="punctuation">,</span> <span class="string">&quot;菜鸟微信&quot;</span> <span class="punctuation">]</span> <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="punctuation">&#123;</span> <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;Taobao&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;info&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span> <span class="string">&quot;淘宝&quot;</span><span class="punctuation">,</span> <span class="string">&quot;网购&quot;</span> <span class="punctuation">]</span> <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p><strong>————JSON数组和对象都可以使用for-in循环来访问</strong></p><h3 id="Python-json"><a href="#Python-json" class="headerlink" title="Python json"></a>Python json</h3><h4 id="json-dumps"><a href="#json-dumps" class="headerlink" title="json.dumps"></a>json.dumps</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">json.dumps(obj, skipkeys=<span class="literal">False</span>, ensure_ascii=<span class="literal">True</span>, check_circular=<span class="literal">True</span>, allow_nan=<span class="literal">True</span>, cls=<span class="literal">None</span>, indent=<span class="literal">None</span>, separators=<span class="literal">None</span>, encoding=<span class="string">&quot;utf-8&quot;</span>, default=<span class="literal">None</span>, sort_keys=<span class="literal">False</span>, **kw)</span><br></pre></td></tr></table></figure><p>——将python对象编码成JSON字符串</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">data = [ &#123; <span class="string">&#x27;a&#x27;</span> : <span class="number">1</span>, <span class="string">&#x27;b&#x27;</span> : <span class="number">2</span>, <span class="string">&#x27;c&#x27;</span> : <span class="number">3</span>, <span class="string">&#x27;d&#x27;</span> : <span class="number">4</span>, <span class="string">&#x27;e&#x27;</span> : <span class="number">5</span> &#125; ]</span><br><span class="line"></span><br><span class="line">data2 = json.dumps(&#123;<span class="string">&#x27;a&#x27;</span>: <span class="string">&#x27;Runoob&#x27;</span>, <span class="string">&#x27;b&#x27;</span>: <span class="number">7</span>&#125;, sort_keys=<span class="literal">True</span>, indent=<span class="number">4</span>, separators=(<span class="string">&#x27;,&#x27;</span>, <span class="string">&#x27;: &#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(data2)</span><br></pre></td></tr></table></figure><p><img src="https://user-images.githubusercontent.com/93063038/161693786-a97c5355-01c0-404d-a141-c77e6e17bec7.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/93063038/161694246-a1c8cc40-8b14-4b9f-b713-af9490964fa2.png" alt="image"></p><h4 id="json-loads"><a href="#json-loads" class="headerlink" title="json.loads"></a>json.loads</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">json.loads(s[, encoding[, cls[, object_hook[, parse_float[, parse_int[, parse_constant[, object_pairs_hook[, **kw]]]]]]]])</span><br></pre></td></tr></table></figure><p>——json.loads 用于解码 JSON 数据。该函数返回 Python 字段的数据类型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">jsonData = <span class="string">&#x27;&#123;&quot;a&quot;:1,&quot;b&quot;:2,&quot;c&quot;:3,&quot;d&quot;:4,&quot;e&quot;:5&#125;&#x27;</span>;</span><br><span class="line"></span><br><span class="line">text = json.loads(jsonData)</span><br><span class="line"><span class="built_in">print</span>(text)</span><br></pre></td></tr></table></figure><p><img src="https://user-images.githubusercontent.com/93063038/161694484-b860f557-4849-4255-809b-eaa5ee033d41.png" alt="image"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#json&quot;&gt;JSON&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#json-语法规则&quot;&gt;JSON 语法规则&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#json-名称值对&quot;&gt;JSON 名称/值对&lt;/a&gt;&lt;/li&gt;
</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Git学习笔记</title>
    <link href="http://lazy.github.io/2022/04/10/Git%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://lazy.github.io/2022/04/10/Git%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</id>
    <published>2022-04-10T13:14:26.000Z</published>
    <updated>2022-04-30T03:36:54.315Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/93063038/161943887-0d855334-36d8-43e0-a11c-1af252d2f1a5.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/93063038/161944097-2f6073fb-e205-47e5-a548-e2400cb085b3.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/93063038/161944157-eba89533-9328-4993-842e-926ec57bb7d0.png" alt="image"></p><h4 id="git-init-——-初始化一个Git仓库"><a href="#git-init-——-初始化一个Git仓库" class="headerlink" title="git init —— 初始化一个Git仓库"></a>git init —— 初始化一个Git仓库</h4><p> 执行后会生成一个.git目录， 该目录包含了资源的所有元数据</p><p><strong>使用指定目录作为git仓库</strong>  ——git init newrepo</p><p>执行后会在newrepo目录下生成.git目录</p><p><code>将文件纳入版本控制</code></p><h4 id="git-add-——-添至暂存区"><a href="#git-add-——-添至暂存区" class="headerlink" title="git add —— 添至暂存区"></a>git add —— 添至暂存区</h4><p>git add . —— 将当前目录下所有未纳入的文件添加到暂存区</p><p>git add {文件名} —— 将指定文件添加到暂存区</p><h4 id="git-commit-——-提交"><a href="#git-commit-——-提交" class="headerlink" title="git commit —— 提交"></a>git commit —— 提交</h4><p>git commit -m ‘提交说明’ —— 对暂存区中的文件进行提交（添加到仓库中）</p><h4 id="git-push-——-上传远程代码并合并"><a href="#git-push-——-上传远程代码并合并" class="headerlink" title="git push —— 上传远程代码并合并"></a>git push —— 上传远程代码并合并</h4><p><strong>git push</strong> 命用于从将本地的分支版本上传到远程并合并。</p><p>命令格式如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git push &lt;远程主机名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt;</span><br></pre></td></tr></table></figure><p>若远程分支名与本地分支名相同则可以省略：及之后部分</p><p>若版本有差异，想要强制推送</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git push --force &lt;远程主机名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt;</span><br></pre></td></tr></table></figure><p>若要删除主机的分支</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git push origin --delete master # 表示删除origin主机的master分支</span><br></pre></td></tr></table></figure><h4 id="git-pull-——-下载远程代码并合并"><a href="#git-pull-——-下载远程代码并合并" class="headerlink" title="git pull —— 下载远程代码并合并"></a>git pull —— 下载远程代码并合并</h4><p><strong>git pull</strong> 命令用于从远程获取代码并合并本地的版本。</p><p><strong>git pull</strong> 其实就是 <strong>git fetch</strong> 和 <strong>git merge FETCH_HEAD</strong> 的简写。 命令格式如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt;</span><br></pre></td></tr></table></figure><h4 id="git-clone-——-从现有Git仓库中拷贝项目"><a href="#git-clone-——-从现有Git仓库中拷贝项目" class="headerlink" title="git clone —— 从现有Git仓库中拷贝项目"></a>git clone —— 从现有Git仓库中拷贝项目</h4><p><strong>git clone <repo></repo></strong></p><p>or</p><p><strong>git clone <repo> <directory></directory></repo></strong> ——克隆到指定目录</p><p>如果要自己定义要新建的项目目录名称，可以在上面的命令末尾指定新的名字</p><p>git commit -a 跳过git add，直接添加至暂存区后提交</p><h4 id="git-config-——-配置信息"><a href="#git-config-——-配置信息" class="headerlink" title="git config —— 配置信息"></a>git config —— 配置信息</h4><p><strong>git config —list</strong> —— 显示当前的git配置信息</p><p><strong>git config -e</strong>  —— 针对当前仓库编辑git配置文件</p><p><strong>git config -e —global</strong> —— 针对系统上所有仓库</p><p>设置提交代码时的用户信息：</p><p><strong>git config —global user.name {YOURGITHUBNAME}</strong><br><strong>git config —global user.email {YOUREMAIL}</strong></p><h4 id="git-status-——-查看仓库当前的状态-显示有变更的文件"><a href="#git-status-——-查看仓库当前的状态-显示有变更的文件" class="headerlink" title="git status —— 查看仓库当前的状态    显示有变更的文件"></a>git status —— 查看仓库当前的状态    显示有变更的文件</h4><p>git status -s 获得更简短的输出结果</p><h4 id="git-diff-——-比较文件的不同，即暂存区和工作区的差异"><a href="#git-diff-——-比较文件的不同，即暂存区和工作区的差异" class="headerlink" title="git diff  —— 比较文件的不同，即暂存区和工作区的差异"></a>git diff  —— 比较文件的不同，即暂存区和工作区的差异</h4><ul><li>尚未缓存的改动：<strong>git diff</strong></li><li>查看已缓存的改动： <strong>git diff —cached</strong></li><li>查看已缓存的与未缓存的所有改动：<strong>git diff HEAD</strong></li><li>显示摘要而非整个 diff：<strong>git diff —stat</strong></li></ul><h4 id="git-reset-——-用于回退版本，-可以制定退回某一次提交的版本"><a href="#git-reset-——-用于回退版本，-可以制定退回某一次提交的版本" class="headerlink" title="git reset —— 用于回退版本， 可以制定退回某一次提交的版本"></a>git reset —— 用于回退版本， 可以制定退回某一次提交的版本</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git reset [--soft | --mixed | --hard] [HEAD]</span><br></pre></td></tr></table></figure><p><strong>git reset HEAD^</strong> - 回退所有内容到上一个版本</p><p><strong>git reset HEAD^ {filename}</strong> - 回退指定文件到上一个版本</p><p><strong>git reset {版本号}</strong> - 回退到指定版本</p><p><strong>git reset —soft HEAD</strong> — soft参数用于回退到某个版本</p><p>例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git reset --soft HEAD~3 # 回退上上上一个版本</span><br></pre></td></tr></table></figure><p><strong>git reset —hard HEAD</strong></p><p><strong>—hard</strong> 参数撤销工作区中所有未提交的修改内容，将暂存区与工作区都回到上一次版本，并删除之前的所有信息提交（慎重使用）</p><p><strong>HEAD 说明：</strong></p><ul><li><p>HEAD 表示当前版本</p></li><li><p>HEAD^ 上一个版本</p></li><li><p>HEAD^^ 上上一个版本</p></li><li><p>HEAD^^^ 上上上一个版本</p></li></ul><ul><li>以此类推…</li></ul><p>可以使用 ～数字表示</p><ul><li>HEAD~0 表示当前版本</li><li>HEAD~1 上一个版本</li><li>HEAD^2 上上一个版本</li><li>HEAD^3 上上上一个版本</li><li>以此类推…</li></ul><p><strong>git reset HEAD</strong> 命令用于取消已缓存的内容。</p><h4 id="git-rm-——-将文件从暂存区和工作区中删除"><a href="#git-rm-——-将文件从暂存区和工作区中删除" class="headerlink" title="git rm  —— 将文件从暂存区和工作区中删除"></a>git rm <file> —— 将文件从暂存区和工作区中删除</file></h4><p>如果删除之前修改过并且已经放到暂存区域的话，则必须要用强制删除选项 <strong>-f</strong></p><p>git rm -f <file></file></p><p>如果想把文件从暂存区域移除，但仍然希望保留在当前工作目录中，换句话说，仅是从跟踪清单中删除，使用 <strong>—cached</strong> 选项即可：</p><p>git rm —cached <file></file></p><h4 id="git-mv-——-用于移动或重命名一个文件-目录或软连接。"><a href="#git-mv-——-用于移动或重命名一个文件-目录或软连接。" class="headerlink" title="git mv  —— 用于移动或重命名一个文件,目录或软连接。"></a>git mv  —— 用于移动或重命名一个文件,目录或软连接。</h4><p>git mv [file] [newfile]</p><h4 id="git-log-——-查看历史提交记录"><a href="#git-log-——-查看历史提交记录" class="headerlink" title="git log —— 查看历史提交记录"></a>git log —— 查看历史提交记录</h4><p>用 —online 选项来查看历史记录的简洁版本。</p><p><strong>git log —online</strong></p><p><strong>git blame <file></file></strong> - 以列表形式查看指定文件的历史修改记录</p><h4 id="git-remote-——-远程仓库操作"><a href="#git-remote-——-远程仓库操作" class="headerlink" title="git remote —— 远程仓库操作"></a>git remote —— 远程仓库操作</h4><p><strong>git remote -v</strong> —— 显示所有远程仓库</p><p><strong>git remote show [remote]</strong> —— 显示某个远程仓库的信息</p><p><code>remote为远程仓库地址</code></p><p>git remote set-url [shortname] [url]</p><p>shortname 为本地的版本库</p><p>添加远程版本库：</p><p><strong>git remote add [shortname] [url]</strong></p><p>shortname 为本地的版本库</p><p><strong>git remote rm name  # 删除远程仓库</strong><br><strong>git remote rename old_name new_name  # 修改仓库名</strong></p><h4 id="git-branch-branchname-——-创建新分支"><a href="#git-branch-branchname-——-创建新分支" class="headerlink" title="git branch (branchname) —— 创建新分支"></a>git branch (branchname) —— 创建新分支</h4><p><strong>git branch</strong> —— 列出本地的分支</p><h4 id="git-checkout-branchname-——-切换分支命令"><a href="#git-checkout-branchname-——-切换分支命令" class="headerlink" title="git checkout (branchname) —— 切换分支命令"></a>git checkout (branchname) —— 切换分支命令</h4><p>当切换分支的时候，Git 会用该分支的最后提交的快照替换你的工作目录的内容， 所以多个分支不需要多个目录。</p><p>也可以使用 <strong>git checkout -b (branchname)</strong> —— <strong>创建新分支并立即切换到该分支下</strong>，从而在该分支中操作。</p><h4 id="git-merge-——-合并分支命令"><a href="#git-merge-——-合并分支命令" class="headerlink" title="git merge —— 合并分支命令"></a>git merge —— 合并分支命令</h4><p><strong>git merge [branchname]</strong> —— 将指定分支与当前所在分支合并 </p><h4 id="git-fetch-——-从远程获取代码库"><a href="#git-fetch-——-从远程获取代码库" class="headerlink" title="git fetch —— 从远程获取代码库"></a>git fetch —— 从远程获取代码库</h4><p>执行完后执行<strong>git merge</strong>合并远程分支到你所在的分支</p><p><img src="https://user-images.githubusercontent.com/93063038/161936610-0ae3d485-71f2-45bb-ad8a-7120f28d8b55.png" alt="image"></p><h4 id="git-tag-tagname-——-为提交快照打上标签"><a href="#git-tag-tagname-——-为提交快照打上标签" class="headerlink" title="git tag [tagname]—— 为提交快照打上标签"></a>git tag [tagname]—— 为提交快照打上标签</h4><p>例：</p><p>我们可以用 <strong>git tag -a v1.0</strong> 命令给最新一次提交打上（HEAD）”v1.0”的标签</p><p><strong>git tag</strong> <strong>—— 查看所有标签</strong></p><p>-a 选项意为”创建一个带注解的标签”。 不用 -a 选项也可以执行的，但它不会记录这标签是啥时候打的，谁打的，也不会让你添加个标签的注解。</p><p><strong>git log —decorate —— 查看标签</strong></p><p><img src="https://user-images.githubusercontent.com/93063038/161943622-a1ef7d03-42da-448f-95be-6999dc6b773c.png" alt="image"></p><h4 id="生成ssh密钥"><a href="#生成ssh密钥" class="headerlink" title="生成ssh密钥"></a>生成ssh密钥</h4><p>执行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -C &lt;your email&gt;</span><br></pre></td></tr></table></figure><p>会生成一个.ssh文件</p><p>找到其中的id_rsa.pub将其中内容复制</p><p>进入github settings 点击SSH and GPG keys</p><p>创建新密钥并将密钥内容粘贴入其中</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/93063038/161943887-0d855334-36d8-43e0-a11c-1af252d2f1a5.png&quot; alt=&quot;image&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img</summary>
      
    
    
    
    
  </entry>
  
</feed>
