[{"title":"DCGAN","url":"/2022/05/11/DCGAN/","content":"模型结构\nCNN的改进方案\n\n判别器中所有的pooling层使用stride卷积进行替换（使用全卷积网络）这种替代只需要将卷积的步长stride设置为大于1的数值。改进的意义是下采样过程不再是固定的抛弃某些位置的像素值，而是可以让网络自己去学习下采样方式。\n生成器中所有的pooling层使用fractional-strided卷积进行替换\n除了生成器模型的输出层和判别器模型的输入层，在网络其它层上都使用了Batch Normalization，使用BN层可以稳定学习，有助于处理初始化不良导致的训练问题。\n移除全连接的隐藏层，让网络可以更深\n在生成器上，除了输出层使用Tanh外（ReLU函数的输出可能会很大，而tanh函数的输出是在-1～1之间的，只要将tanh函数的输出加1再乘以127.5可以得到0～255 的像素值），其他所有层的激活函数都使用了ReLU\n判别器所有层的激活函数都使用LeakyReLU\n优化器使用Adam\n\nDCGAN的一些成功之处有效减轻了GAN的overfitting问题\n作者在LSUN上训练了一个3072-128-3072的去噪自编码器，用它从图像中提取128维特征，在经过ReLU层激活后作为图像的语义hash值，并对生成图像和训练集使用此编码器提取128维的语义hash值，进行重复性检测\n在大小约300万的LSUN数据集中检测到了27.5万左右的重复数据，召回率较高。\n无监督表征学习\n通过DCGAN得到的image feature maps具有良好的通用性和泛化能力。\n在Imagenet-1k上训练DCGAN\n使用判别器所有层的卷积特征，分别经过最大池化层，在每一层上得到一个空间尺寸为4*4的特征，再把这些特征做flattened和concatenated，最终得到28672维的向量表示。\n使用一个L2正则化的svm分类器进行分类，基于这些特征向量和类别label进行有监督训练\n将图像的各种高维度信息进行表征\n代码实现生成器实现：\nclass Generator(nn.Module):    def __init__(self):        super(Generator, self).__init__()        self.init_size = opt.img_size // 4        self.l1 = nn.Sequential(nn.Linear(opt.latent_dim, 128 * self.init_size ** 2))        self.conv_blocks = nn.Sequential(            nn.BatchNorm2d(128),            nn.Upsample(scale_factor=2),            nn.Conv2d(128, 128, 3, stride=1, padding=1),            nn.BatchNorm2d(128, 0.8),            nn.LeakyReLU(0.2, inplace=True),            nn.Upsample(scale_factor=2),            nn.Conv2d(128, 64, 3, stride=1, padding=1),            nn.BatchNorm2d(64, 0.8),            nn.LeakyReLU(0.2, inplace=True),            nn.Conv2d(64, opt.channels, 3, stride=1, padding=1),            nn.Tanh(),        )    def forward(self, z):        out = self.l1(z)        out = out.view(out.shape[0], 128, self.init_size, self.init_size)        img = self.conv_blocks(out)        return img\n判别器实现：\nclass Discriminator(nn.Module):    def __init__(self):        super(Discriminator, self).__init__()        def discriminator_block(in_filters, out_filters, bn=True):            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]            if bn:                block.append(nn.BatchNorm2d(out_filters, 0.8))            return block        self.model = nn.Sequential(            *discriminator_block(opt.channels, 16, bn=False),            *discriminator_block(16, 32),            *discriminator_block(32, 64),            *discriminator_block(64, 128),        )        # The height and width of downsampled image        ds_size = opt.img_size // 2 ** 4        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())    def forward(self, img):        out = self.model(img)        out = out.view(out.shape[0], -1)        validity = self.adv_layer(out)        return validity\n"},{"title":"Generative Adversarial Networks","url":"/2022/04/30/Generative%20Adversarial%20Networks/","content":"浅学一些数学知识信息量在信息论当中，我们用一件事情发生的概率的负对数表示信息量。\n\nH=-\\log{p}如公式所示，也就是事情发生的概率越大，其包含的信息量就越小，反之亦然。\n信息熵信息熵，也是平均自信息量，如公式所示，表示的是自信息量(也就是上面提到的信息量)的数学期望，表示为概率与其自信息量的乘积然后再求和。\n\nH(X)=-\\sum_{x\\in{X} }p(x)\\log{p(x)}交叉熵\n交叉熵刻画的是实际输出（概率）与期望输出（概率）的距离，也就是交叉熵的值越小，两个概率分布就越接近，即拟合的更好。\n\n交叉熵其实就是对于一个分布p来说，我们用分布q来对分布p中的信息进行编码，所需要的信息量。\n如果交叉熵越小，说明用分布q来表示分布p所需要的信息量越小，这也就说明q分布越接近p分布。\n\nH(p,q)=-\\sum_xp(x)\\log{q(x)}KL散度（相对熵）\n描述两个概率分布之间差异的非对称量\n其定义就是用理论分布去拟合真实分布时产生的信息损耗\n\n若有两个随机变量p, q，且其概率分布分别为p(x)、q(x)，则p相对q的相对熵为：\n\nD_{KL}(p||q)=\\sum_{x}p(x)\\log\\frac{p(x)}{q(x)}又由定义可知：KL散度 = 交叉熵 - 信息熵\n因此，KL散度可通过下式得出：\n\n\\begin{aligned}D_{KL}(p||q)&=H(p,q)-H(p)\\\\\n&=-\\sum_xp(x)(\\log{q(x)}-\\log{p(x)})\\\\\n&=-\\sum_x{p(x)\\log{\\frac{q(x)}{p(x)}}}\\\\\\\\\n&\\iff{E_{x\\backsim{p}}(\\log{p(x)}-\\log{q(x)}})\\end{aligned}正定性\n相对熵的值是非负值，即D(P||Q)&gt;0。\n不对称性\n尽管KL散度从直观上是个度量或距离函数，但它并不是一个真正的度量或者距离，因为它不具有对称性，即D(P||Q)!=D(Q||P)。\nJS散度\n由于KL散度的不对称性，所以这里引入了一个JS散度，也就是Jensen-Shannon散度，JS散度度量了两个概率分布的相似度，基于KL散度的变体，解决了KL散度非对称的问题，一般地，JS散度是对称的\n\n公式如下\n\nJS(p||q)=\\frac{1}{2}KL(p(x)||\\frac{p(x)+q(x)}{2}+\\frac{1}{2}KL(q(x)||\\frac{p(x)+q(x)}{2})\n条件概率\n条件概率是指事件A在另外一个事件B已经发生条件下的发生概率。 条件概率表示为：P（A|B），读作”在B的条件下A的概率”。 条件概率可以用决策树进行计算。\n\n\nP(B|A)=\\frac{P(AB)}{P(A)}全概率公式对于一个较为复杂的事件A，找到其完备事件组B1、B2、B3……则可得：\n\nP(A)=P(AB_1)+P(AB_2)+...+P(AB_n)又根据条件概率公式：\n\nP(A)=P(A|B_1)P(B_1)+P(A|B_2)P(B_2)+...+P(A|B_n)P(B_n)则可证得全概率公式如下：\n\nP(A)=\\sum^n_{i=1}P(B_i)P(A|B_i)贝叶斯公式\n通常，事件 A 在事件 B 发生的条件下与事件 B 在事件 A 发生的条件下，它们两者的概率并不相同，但是它们两者之间存在一定的相关性，并具有以下公式（称之为“贝叶斯公式”）\n\n后验概率就是事件A在另一个事件B已经发生的条件下发生概率，根据观察到的样本修正之后的概率值，公式表示为P(A|B)。\n联合概率表示两件事情共同发生的概率。A与B的联合概率表示为p(AB)。\n先验概率（边缘概率）这个概率是通过统计得到的，或者依据自身依据经验给出的一个概率值，这里P(A)就是先验概率\n\nP (AB) = P (A)*P (B|A)=P (B)*P (A|B)\nP(A|B)=\\frac{P(B|A)P(A)}{P(B)}\n似然函数\n概率描述的是在一定条件下某个事件发生的可能性，概率越大说明这件事情越可能会发生；而似然描述的是结果已知的情况下，该事件在不同条件下发生的可能性，似然函数的值越大说明该事件在对应的条件下发生的可能性越大。\n\n若x已知，为变量，则该函数为似然函数     描述对于不同的模型参数，x样本点出现的概率\n若x为变量，未知，则该函数为概率函数     描述对于参数模型,  不同的样本点x出现的概率为多少\n其中：x表示某一个具体的数据，θ 表示模型的参数。\n似然函数对数化\n实际问题往往要比抛一次硬币复杂得多，会涉及到多个独立事件，在似然函数的表达式中通常都会出现连乘\n对多项乘积的求导往往非常复杂，但是对于多项求和的求导却要简单的多，对数函数不改变原函数的单调性和极值位置，而且根据对数函数的性质可以将乘积转换为加减式，这可以大大简化求导的过程\n最大似然估计\n利用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值\n\n当已知样本服从某一分布时，我们根据这一分布求使似然函数最大的概率分布，则求得概率分布就是最大似然估计得结果\nGenerative Adversarial Networks论文阅读\n        →真实数据（）        →真实数据的分布        →噪音（输入数据）        →原始噪音的分布        →经过生成器后的数据分布        →生成映射函数        →判别映射函数\n\n对GAN训练过程的理解将符合正态分布的随机噪声z输入生成器生成G(z)，经处理后与真实数据x一起交予判别器处理，判别器将G(z)是否为真实数据并给出一个概率值D(G(z))。我们的训练目标是：训练判别器D使D(x)最大，而D(G(z))最小，训练生成器G使D(G(z))最大。我们的训练策略是先训练k次判别器D使之具备一定的判别能力（在论文中k取1），之后训练一次生成器G，如此迭代训练以接近全局最优。\n在刚开始训练的时候，生成器G生成的数据显然与真实数据相差很大，此时判别器D将以高置信度拒绝生成器G生成的样本，这将导致饱和（很大），所以选择先对判别器进行训练。\n\n由于训练开始时，G性能较差，这将使得D(G(z))趋近于0，这将导致的梯度较小，而的梯度较大，因此，将G的训练目标改为最大化在训练初期提供了更大的梯度    \n可以说生成对抗网络训练的过程就是生成器G与判别器D进行一个零和博弈的过程，G欲使目标函数最大化，D欲使目标函数最小化\n\n\\underset{G}{min}\\underset{D}{max}V(D,G)=E_{x\\backsim{p_{data}}}[\\log{D(x)}]+E_{z\\backsim{p_z(z)}}[\\log{1-D(G(z)))}] A less formal, more pedagogical explanation of the approach.\n\n\n蓝线 判别分布 \n红线 生成分布 \n黑线 真实数据分布 \n\n\nThe generator nets used a mixture of rectififier linear activations and sigmoid activations, while the discriminator net used maxout activations. Dropout was applied in training the discriminator net. While our theoretical framework permits the use of dropout and other noise at intermediate layers of the generator, we used noise as the input to only the bottommost layer of the generator network.\n\n为什么这样设计目标函数？我们知道KL散度可以描述两个分布之间的差异程度，即用理论分布去拟合真实分布时产生的信息损耗。我们可以将生成器G的训练过程看作是令生成数据的分布不断接近、拟合真实数据分布的过程，因此，我们可以将它看作一个将二者KL散度最小化的过程。再结合GAN的训练过程是生成器G与判别器D进行零和博弈的过程，我们可以得到：                                                                                                                                                             \n\n\\begin{aligned}D_{KL}(p_{data}||p_{g})&=H(p_{data},p_g)-H(p_{data})\\\\\\\\\n&=-\\sum_xp_{data}(x)(\\log{p_g(x)}-\\log{p_{data}(x)})\\\\\n&=-\\sum_x{p_{data}(x)\\log{\\frac{p_g(x)}{p_{data}(x)}}}\\\\\\\\\n&\\iff{E_{x\\backsim{p_{data}}}(\\log{p_{data}(x)}-\\log{p_g(x)}})\\\\\\\\\n&=E_{x\\backsim{p_{data}}}(\\log{p_{data}(x)})-E_{x\\backsim{p_{data}}}(\\log{p_g}(x))\\\\\\\\\n&\\iff{E_{x\\backsim{p_{data}}}(\\log{D(x)})-E_{x\\backsim{p_{data}}}(\\log{D(G(x))})}\\\\\\\\\n&={E_{x\\backsim{p_{data}}}(\\log{D(x)})-E_{x\\backsim{p_{g}}}(\\log{D(x)})}\\\\\\\\\n&={E_{x\\backsim{p_{data}}}(\\log{D(x)})+E_{x\\backsim{p_{g}}}(\\log{\\frac{1}{D(x)}})}\\\\\\\\\n&\\iff{E_{x\\backsim{p_{data}}}(\\log{D(x)})+E_{x\\backsim{p_{g}}}(\\log({1-D(x))})}\\end{aligned}可知，生成器G想要达到最优，与前一项无关，只需最小化后一项。判别器D想要达到最优，只需最大化判别真实数据为真的概率，最小化判别生成数据为真的概率，即最大化整个函数。因此我们可以得到目标函数：\n\n\\underset{G}{min}\\underset{D}{max}V(D,G)=E_{x\\backsim{p_{data}}}[\\log{D(x)}]+E_{z\\backsim{p_z(z)}}[\\log{1-D(G(z)))}]从最大似然估计的角度来看。\n由于我们已知的数据是生成数据的分布与真实数据的分布，想要得到的是使生成器最优的模型概率参数，因此我们可以设计一个似然函数：\n\np_g(X_{i}|\\theta)我们使用最大似然估计方法：\n\n\\theta_{bst}=arg\\underset{\\theta}max\\prod_{i=1}^{n}p_g(x_i|\\theta)取对数可得\n\n\\begin{aligned}\\theta_{bst}&=arg\\underset{\\theta}max\\sum_{i=1}^{n}\\log{p_g(x_i|\\theta)}\n\\\\&\\iff{arg\\underset{\\theta}maxE_{x\\backsim{p_{g}}}\\log{p_g(x_i|\\theta)}}\n\\end{aligned}再考虑判别器，我们想要令判别器对于真实数据输出的值趋于1，对生成数据输出的值趋于0\n何时达到全局最优？\n\\begin{aligned}V(G,D)&=\\int_xp_{data}(x)\\log{(D(x))}dx+\\int_zp_z(z)\\log{(1-D(g(z)))}dz\\\\\\\\&=\\int_xp_{data(x)}\\log{(D(x))}+p_g(x)\\log{(1-D(x))dx}\\end{aligned}要证上式，只需证\n\nE_{z\\backsim{p_z(z)}}\\log{(1-D(G(z)))}=E_{x\\backsim{p_g(x)}}\\log{(1-D(x))}根据测度论中的Radon-Nikodym定理可证。\n寻找最优的判别器D我们假定生成器G固定，来考虑最优判别器, 可将和看作常数a, b。\n由上式得：\n\nV = a\\log(D)+b\\log(1-D)求导求其极值：\n\n\\frac{dV}{dD}=a×\\frac{1}{D}-b×\\frac{1}{1-D}令，则易得最优判别器D为：\n\nD^*_G(x)=\\frac{p_{data}(x)}{p_{data}(x)+p_g(x)}\nNote that the training objective for D can be interpreted as maximizing the log-likelihood for estimating the conditional probability P(Y = y|x), where Y indicates whether x comes from (with y = 1) or from (with y = 0). \n\n寻找最优的生成器G于是，我们将代入求\n联系KL散度与JS散度的定义，我们可以得到：\n\n\\begin{aligned}\\underset{D}{max}V(G,D^*)\n&=E_{x\\backsim{p_{data}}}(\\log{D^*(x)})+E_{x\\backsim{p_{g}}}(\\log({1-D^*(x))})\\\\\n&=E_{x\\backsim{p_{data}}}(\\log{\\frac{p_{data}(x)}{p_{data}(x)+p_g(x)}})+E_{x\\backsim{p_{g}}}(\\log(\\frac{p_{g}(x)}{p_{data}(x)+p_g(x)})\\\\\n&=\\int_xp_{data}(x)\\log{\\frac{p_{data}(x)}{p_{data}(x)+p_g(x)}dx+\\int_xp_g(x)\\log{\\frac{p_{g}(x)}{p_{data}(x)+p_g(x)}dx}}\\\\\n&=\\int_xp_{data}(x)\\log{\\frac{\\frac{1}{2}p_{data}(x)}{\\frac{p_{data}(x)+p_g(x)}{2}}dx+\\int_xp_g(x)\\log{\\frac{\\frac{1}{2}p_{g}(x)}{\\frac{p_{data}(x)+p_g(x)}{2}}dx}}\\\\\n&=\\int_xp_{data}(x)\\log{\\frac{1}{2}}dx+\\int_xp_{g}(x)\\log{\\frac{1}{2}}dx\\\\&+\\int_xp_{data}(x)\\log{\\frac{p_{data}(x)}{\\frac{p_{data}(x)+p_g(x)}{2}}dx+\\int_xp_g(x)\\log{\\frac{p_{g}(x)}{\\frac{p_{data}(x)+p_g(x)}{2}}dx}}\\\\\n&=2\\log{\\frac{1}{2}}+2×[\\frac{1}{2}KL(p_{data}||\\frac{p_g+p_{data}}{2})+\\frac{1}{2}KL(p_g||\\frac{p_g+p_{data}}{2})]\\\\\\\\\n&=-\\log{4}+2JSD(p_{data}||p_g)\\end{aligned}有JS散度的定义域可知，当且仅当的时候JS散度取得最小值0。\n所以我们可以知道仅当时取得全局最小值。\n即取得最优生成器G需要满足的条件是\n\n在实际训练中，想要达到全局最优是不可能的，我们的训练目的是使GAN进入一个纳什平衡的状态。\n在纳什均衡点，两者的参数到达一种“制衡”状态。在给定G的参数情况下，D当前的参数便对应了D损失函数的最小值，同样在给定D的参数情况下，G当前的参数便对应了G损失函数的最小值，也就是说在交替更新过程中，D和G均不可能单独做出任何改变。\n\n为什么不先将判别器训练得很好再训练生成器？梯度消失\n我们已经知道，当假设判别器为最优的极端情况下，目标函数为：\n\n-\\log{4}+2JSD(p_{data}||p_g)此时生成器效果还很差，因此与两个分布的重叠区域几乎为0，此时易证，因此，目标函数为一常数0。此时，对于梯度下降方法，梯度为0，因此训练无法进行。\n证明收敛\n\n"},{"title":"Git学习笔记","url":"/2022/04/10/Git%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","content":"\n\n\ngit init —— 初始化一个Git仓库 执行后会生成一个.git目录， 该目录包含了资源的所有元数据\n使用指定目录作为git仓库  ——git init newrepo\n执行后会在newrepo目录下生成.git目录\n将文件纳入版本控制\ngit add —— 添至暂存区git add . —— 将当前目录下所有未纳入的文件添加到暂存区\ngit add {文件名} —— 将指定文件添加到暂存区\ngit commit —— 提交git commit -m ‘提交说明’ —— 对暂存区中的文件进行提交（添加到仓库中）\ngit push —— 上传远程代码并合并git push 命用于从将本地的分支版本上传到远程并合并。\n命令格式如下：\ngit push &lt;远程主机名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt;\n若远程分支名与本地分支名相同则可以省略：及之后部分\n若版本有差异，想要强制推送\ngit push --force &lt;远程主机名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt;\n若要删除主机的分支\ngit push origin --delete master # 表示删除origin主机的master分支\ngit pull —— 下载远程代码并合并git pull 命令用于从远程获取代码并合并本地的版本。\ngit pull 其实就是 git fetch 和 git merge FETCH_HEAD 的简写。 命令格式如下：\ngit pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt;\ngit clone —— 从现有Git仓库中拷贝项目git clone \nor\ngit clone   ——克隆到指定目录\n如果要自己定义要新建的项目目录名称，可以在上面的命令末尾指定新的名字\ngit commit -a 跳过git add，直接添加至暂存区后提交\ngit config —— 配置信息git config —list —— 显示当前的git配置信息\ngit config -e  —— 针对当前仓库编辑git配置文件\ngit config -e —global —— 针对系统上所有仓库\n设置提交代码时的用户信息：\ngit config —global user.name {YOURGITHUBNAME}git config —global user.email {YOUREMAIL}\ngit status —— 查看仓库当前的状态    显示有变更的文件git status -s 获得更简短的输出结果\ngit diff  —— 比较文件的不同，即暂存区和工作区的差异\n尚未缓存的改动：git diff\n查看已缓存的改动： git diff —cached\n查看已缓存的与未缓存的所有改动：git diff HEAD\n显示摘要而非整个 diff：git diff —stat\n\ngit reset —— 用于回退版本， 可以制定退回某一次提交的版本git reset [--soft | --mixed | --hard] [HEAD]\ngit reset HEAD^ - 回退所有内容到上一个版本\ngit reset HEAD^ {filename} - 回退指定文件到上一个版本\ngit reset {版本号} - 回退到指定版本\ngit reset —soft HEAD — soft参数用于回退到某个版本\n例：\n$ git reset --soft HEAD~3 # 回退上上上一个版本\ngit reset —hard HEAD\n—hard 参数撤销工作区中所有未提交的修改内容，将暂存区与工作区都回到上一次版本，并删除之前的所有信息提交（慎重使用）\nHEAD 说明：\n\nHEAD 表示当前版本\n\nHEAD^ 上一个版本\n\nHEAD^^ 上上一个版本\n\nHEAD^^^ 上上上一个版本\n\n\n\n以此类推…\n\n可以使用 ～数字表示\n\nHEAD~0 表示当前版本\nHEAD~1 上一个版本\nHEAD^2 上上一个版本\nHEAD^3 上上上一个版本\n以此类推…\n\ngit reset HEAD 命令用于取消已缓存的内容。\ngit rm  —— 将文件从暂存区和工作区中删除如果删除之前修改过并且已经放到暂存区域的话，则必须要用强制删除选项 -f\ngit rm -f \n如果想把文件从暂存区域移除，但仍然希望保留在当前工作目录中，换句话说，仅是从跟踪清单中删除，使用 —cached 选项即可：\ngit rm —cached \ngit mv  —— 用于移动或重命名一个文件,目录或软连接。git mv [file] [newfile]\ngit log —— 查看历史提交记录用 —online 选项来查看历史记录的简洁版本。\ngit log —online\ngit blame  - 以列表形式查看指定文件的历史修改记录\ngit remote —— 远程仓库操作git remote -v —— 显示所有远程仓库\ngit remote show [remote] —— 显示某个远程仓库的信息\nremote为远程仓库地址\ngit remote set-url [shortname] [url]\nshortname 为本地的版本库\n添加远程版本库：\ngit remote add [shortname] [url]\nshortname 为本地的版本库\ngit remote rm name  # 删除远程仓库git remote rename old_name new_name  # 修改仓库名\ngit branch (branchname) —— 创建新分支git branch —— 列出本地的分支\ngit checkout (branchname) —— 切换分支命令当切换分支的时候，Git 会用该分支的最后提交的快照替换你的工作目录的内容， 所以多个分支不需要多个目录。\n也可以使用 git checkout -b (branchname) —— 创建新分支并立即切换到该分支下，从而在该分支中操作。\ngit merge —— 合并分支命令git merge [branchname] —— 将指定分支与当前所在分支合并 \ngit fetch —— 从远程获取代码库执行完后执行git merge合并远程分支到你所在的分支\n\ngit tag [tagname]—— 为提交快照打上标签例：\n我们可以用 git tag -a v1.0 命令给最新一次提交打上（HEAD）”v1.0”的标签\ngit tag —— 查看所有标签\n-a 选项意为”创建一个带注解的标签”。 不用 -a 选项也可以执行的，但它不会记录这标签是啥时候打的，谁打的，也不会让你添加个标签的注解。\ngit log —decorate —— 查看标签\n\n生成ssh密钥执行：\nssh-keygen -t rsa -C &lt;your email&gt;\n会生成一个.ssh文件\n找到其中的id_rsa.pub将其中内容复制\n进入github settings 点击SSH and GPG keys\n创建新密钥并将密钥内容粘贴入其中\n"},{"title":"Json学习笔记","url":"/2022/04/10/Json%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","content":"\n\nJSON\nJSON 语法规则\nJSON 名称/值对\nJSON 值\nJSON 文件\nJSON对象\n使用点号访问对象值\n使用点号. 或者中括号 [] 来访问嵌套的JSON对象。\n修改JSON值\n修改对象属性\n\n\nJSON数组\n数组可以作为JSON对象\nJSON对象中的数组\n嵌套 JSON 对象中的数组\n\n\n\n\nPython json\njson.dumps\njson.loads\n\n\n\n\nJSONJSON: JavaScript Object Notation(JavaScript 对象表示法)\nJSON 语法规则JSON 语法是 JavaScript 对象表示语法的子集。\n\n数据在名称/值对中\n数据由逗号分隔\n大括号 {} 保存对象\n中括号 [] 保存数组，数组可以包含多个对象\n\nJSON 名称/值对JSON 数据的书写格式是：\nkey : value\n名称/值对包括字段名称（在双引号中），后面写一个冒号，然后是值：\n“name” : “菜鸟教程”\nJSON 值JSON 值可以是：\n\n数字（整数或浮点数）\n字符串（在双引号中）\n逻辑值（true 或 false）\n数组（在中括号中）\n对象（在大括号中）\nnull\n\nJSON 文件\nJSON 文件的文件类型是 .json\nJSON 文本的 MIME 类型是 application/json\n\nMINE类型：媒体类型（通常称为 Multipurpose Internet Mail Extensions 或 MIME 类型 ）是一种标准，用来表示文档、文件或字节流的性质和格式。 它在IETF RFC 6838中进行了定义和标准化。\nJSON对象必须在大括号{}中书写，\nkey必须是字符串，value可以是合法的JSON数据类型（见JSON值）\n使用点号访问对象值例：\nvar myobj, x;myobj = &#123;&quot;name&quot;:&quot;runoob&quot;, &quot;alexa&quot;:10000, &quot;site&quot;:null&#125;;x = myobj[&quot;name&quot;];\n使用点号. 或者中括号 [] 来访问嵌套的JSON对象。x = myobj.sites.site1;x = myobj.sites[&quot;site1&quot;];\n修改JSON值使用点号访问并修改\nmyobj.sites.site1 = &quot;sxasxaxa&quot;\n使用中括号访问并修改\nmyobj.sites.[&quot;site1&quot;] = &quot;sadadsad&quot;\n修改对象属性使用delete关键字来删除JSON对象的属性：\ndelete myobj.sites.site1\nJSON数组数组可以作为JSON对象例：\n[ &quot;Google&quot;, &quot;Runoob&quot;, &quot;Taobao&quot; ]\nJSON对象中的数组例：\n&#123;&quot;name&quot;:&quot;网站&quot;,&quot;num&quot;:3,&quot;sites&quot;:[ &quot;Google&quot;, &quot;Runoob&quot;, &quot;Taobao&quot; ]&#125;\n嵌套 JSON 对象中的数组JSON 对象中数组可以包含另外一个数组，或者另外一个 JSON 对象：\n例：\nmyObj = &#123;    &quot;name&quot;:&quot;网站&quot;,    &quot;num&quot;:3,    &quot;sites&quot;: [        &#123; &quot;name&quot;:&quot;Google&quot;, &quot;info&quot;:[ &quot;Android&quot;, &quot;Google 搜索&quot;, &quot;Google 翻译&quot; ] &#125;,        &#123; &quot;name&quot;:&quot;Runoob&quot;, &quot;info&quot;:[ &quot;菜鸟教程&quot;, &quot;菜鸟工具&quot;, &quot;菜鸟微信&quot; ] &#125;,        &#123; &quot;name&quot;:&quot;Taobao&quot;, &quot;info&quot;:[ &quot;淘宝&quot;, &quot;网购&quot; ] &#125;    ]&#125;\n————JSON数组和对象都可以使用for-in循环来访问\nPython jsonjson.dumpsjson.dumps(obj, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, encoding=&quot;utf-8&quot;, default=None, sort_keys=False, **kw)\n——将python对象编码成JSON字符串\nimport jsondata = [ &#123; &#x27;a&#x27; : 1, &#x27;b&#x27; : 2, &#x27;c&#x27; : 3, &#x27;d&#x27; : 4, &#x27;e&#x27; : 5 &#125; ]data2 = json.dumps(&#123;&#x27;a&#x27;: &#x27;Runoob&#x27;, &#x27;b&#x27;: 7&#125;, sort_keys=True, indent=4, separators=(&#x27;,&#x27;, &#x27;: &#x27;))print(data2)\n\n\njson.loadsjson.loads(s[, encoding[, cls[, object_hook[, parse_float[, parse_int[, parse_constant[, object_pairs_hook[, **kw]]]]]]]])\n——json.loads 用于解码 JSON 数据。该函数返回 Python 字段的数据类型。\nimport jsonjsonData = &#x27;&#123;&quot;a&quot;:1,&quot;b&quot;:2,&quot;c&quot;:3,&quot;d&quot;:4,&quot;e&quot;:5&#125;&#x27;;text = json.loads(jsonData)print(text)\n\n"},{"title":"OpenMV实现靶点检测","url":"/2022/04/27/OpenMV%E5%AE%9E%E7%8E%B0%E9%9D%B6%E7%82%B9%E6%A3%80%E6%B5%8B/","content":"—— 未完\nidea:\n\n初步想法是利用颜色信息对靶子进行检测\n再对靶点进行定位。若效果不佳考虑部署TensorFlow Lite yolo进行目标检测\n边缘检测\n图像对比\n先颜色识别后模块匹配\n决定先色块识别定位靶子。舵机追踪靶子方位同时横向运动小车，令小车舵机与车身角度为90度时舵机对准靶子。转动小车使车身与舵机夹角为0度。使小车直行，并进行边缘检测，传回矩形靶子的长宽大小比例，分析数据并不断进行微调。戳中靶心后转动舵机寻找第二个靶子重复以上操做。\n\n1.设置窗口roi\nsensor.set_windowing(roi)\n\nroi （回报率） （感兴趣的区域）（进行检测的区域）\n\nroi的格式是(x, y, w, h)的tupple\n2.水平翻转图像，使小车视野与实际相同\n水平方向翻转：\nsensor.set_hmirror(True)\n3.获取区域内的平均颜色或者占面积最大的颜色信息\n使用 Statistics\nimage.get_statistics(roi=Auto)\n4.寻找色块\nimage.find_blobs(thresholds, roi=Auto, x_stride=2, y_stride=1, invert=False, area_threshold=10, pixels_threshold=10, merge=False, margin=0, threshold_cb=None, merge_cb=None)\n\nthresholds是颜色的阈值，注意：这个参数是一个列表，可以包含多个颜色。如果你只需要一个颜色，那么在这个列表中只需要有一个颜色值，如果你想要多个颜色阈值，那这个列表就需要多个颜色阈值。注意：在返回的色块对象blob可以调用code方法，来判断是什么颜色的色块。\n\n\n阈值参数的结构\ncolour = (minL, maxL, minA, maxA, minB, maxB)\nOpenMV 的IDE里加入了阈值选择工具      用他！\n(50, 75, -60, -14, 12, 62)浅测一个绿色 感觉不是很准。。\n靶点检测场地为200*200   调整x, y_stride    将merge设置为True\nblob.rect() 返回这个色块的外框——矩形元组(x, y, w, h)\n\n边缘检测\nimage.find_edges(edge_type[,threshold])\n将图像变为黑白。边缘保留白色像素\nedge_type 参数：image.EDGE_SIMPLE ——简单的阈值高通滤波算法\n​                               image.EDGE_CANNY ——canny边缘检测\nthreshold —— 包含高低阈值的二元组 默认（100，200） 仅支持灰度图像\n例程：\n# Canny边缘检测:## 这个例子展示了Canny边缘检测。import sensor, image, timesensor.reset() # 初始化sensor.sensor.set_pixformat(sensor.GRAYSCALE) # or sensor.RGB565#设置图像色彩格式，有RGB565色彩图和GRAYSCALE灰度图两种sensor.set_framesize(sensor.QQVGA) # or sensor.QVGA (or others)#设置图像像素大小sensor.skip_frames(30) # 让新的设置生效sensor.set_gainceiling(8)clock = time.clock() # 跟踪FPS帧率while(True):    clock.tick() # 追踪两个snapshots()之间经过的毫秒数.    img = sensor.snapshot() # 拍一张照片并返回图像。    # 使用Canny边缘检测器    img.find_edges(image.EDGE_CANNY, threshold=(50, 80))    #threshold设置阈值    # 更快更简单的边缘检测    #img.find_edges(image.EDGE_SIMPLE, threshold=(100, 255))    print(clock.fps()) # 注意:你的OpenMV摄像头的运行速度只有它的一半\nimport sensor, image, lcd#初始化摄像头sensor.reset() # 初始化摄像头模块.sensor.set_pixformat(sensor.GRAYSCALE) # 或者使用 sensor.RGB565 彩色sensor.set_framesize(sensor.QQVGA) # 或者使用 sensor.QVGA (or others)sensor.skip_frames(time = 2000) #延时让摄像头文稳定.sensor.set_gainceiling(8) #设置增益，这是官方推荐的参数lcd.init()                          # LCD初始化while(True):    img = sensor.snapshot() # 拍摄并返回图像.    #使用 Canny 边缘检测器    img.find_edges(image.EDGE_CANNY, threshold=(50, 80))    lcd.display(img)                # LCD显示img\n舵机控制\n构造函数\n\n\nclasspyb.Servo(id)\n创建一个伺服对象。 id 为1-3，与引脚P7至P9相对应。\n\n\n\n方法\n\nServo.angle([*angle, time=0*])\n若未给定参数，该函数返回当前角度。若给定函数，该函数设置servo的角度：angle 是度数计的移动的角度。time 是达到指定角度所用的毫秒数。若省略，则servo会尽快移动到新的位置。\n\nServo.speed([*speed, time=0*])\n若未给定参数，该函数会返回当前速度。若给定参数，该函数设置servo的速度：speed 是改变的速度，取值100-100。time 是达到指定角度所用的毫秒数。若省略，则servo会尽快加速。\n\nServo.pulse_width([*value*])\n若未给定参数，该函数会返回当前的原始脉宽值。若给定参数，该函数设置原始脉宽值。\n\nServo.calibration([*pulse_min, pulse_max, pulse_centre*[, pulse_angle_90, pulse_speed_100**]**])\n若未给定参数，这个函数返回当前的5元组校准数据。若给定参数，该函数设定计时校准：pulse_min 是允许的最小脉宽。pulse_max 是允许的最大脉冲。pulse_centre 是中心/零位置对应的脉宽。pulse_angle_90 是90度对应的脉宽。pulse_speed_100 是速度100对应的脉宽。\n\n\n串口通信\nimport timefrom pyb import UARTuart = UART(3, 19200)while(True):    uart.write(&quot;Hello World!\\r&quot;)    time.sleep_ms(1000)\nUART类\n实例化一个串口， 波特率为19200的串口3\n\n注意：必须是串口3，因为OpenMV2只引出了这个串口，pyb的串口有好多个的。OpenMV3又增加了串口1。\n\n调用write方法传输数据   可传输Json数据\n"},{"title":"Total Variation distance","url":"/2022/05/30/Total%20Variation%20distance/","content":"定义在E上的两个分布$\\mu$和$v$的总变差距离为：\n\n\\lVert \\mu-v \\rVert_{TV}=\\underset{A\\subset{E}}{\\sup}{\\lvert \\mu(A)-v(A) \\rvert}"},{"title":"Yolo","url":"/2022/04/30/Yolo/","content":"我asdasdas\nIoU（Intersection over union）\n交并比，衡量两个区域的重叠程度，是二者重叠部分面积占二者总面积的比例\n\n\n在目标检测任务中，如果我们模型输出的矩形框与我们人工标注的矩形框的IoU值大于某个阈值时（通常为0.5）即认为我们的模型输出了正确的\nPrecision &amp; Recall假设我们有一组图片，里面有若干待检测的目标，\nPrecision就代表我们模型检测出来的目标有多大比例是真正的目标物体，\nRecall就代表所有真实的目标有多大比例被我们的模型检测出来了。\n\nTP ：模型预测为某类物品（检测出的矩形框大于置信度阈值）且与数据集标注中某个目标框IOU大于0.5\nTN ：模型预测不为某类物品（检测出的矩形框小于置信度阈值）但与数据集标注中某个目标框IOU大于0.5\nFP ：模型预测为某类物品，但与数据集标注中所有目标框IOU均大于0.5（重复检测）\nFN ：模型预测不为某类物品，且与数据集中所有目标框IOU均大于0.5\n\n准确率： 模型检测出的物品中正确的比例\n\n召回率： 所有正确的目标中被模型检测出来的比例\n\nPR曲线\n我们当然希望检测的结果P越高越好，R也越高越好，但事实上这两者在某些情况下是矛盾的。比如极端情况下，我们只检测出了一个结果，且是准确的，那么Precision就是100%，但是Recall就很低；而如果我们把所有结果都返回，那么必然Recall必然很大，但是Precision很低。\n因此在不同的场合中需要自己判断希望P比较高还是R比较高。如果是做实验研究，可以绘制Precision-Recall曲线来帮助分析。\n\n\nAP (Average Precision)AP = \n在实际应用中，我们并不直接对该PR曲线进行计算，而是对PR曲线进行平滑处理。即对PR曲线上的每个点，Precision的值取该点右侧最大的Precision的值。\n？\nYolov1\n将目标检测问题转化为一个回归问题进行求解，也就是说将图像作为输入（像素数据），直接输出物体的位置和所属于的类别的置信度（是以一个向量的形式表示的，后续会介绍），属于端到端的模型形式。\n\n基本思想：将图片划分为S*S个区域（gridcell），假设都存在一个 true answer 也就是针对这个目标的最好的检测框 ， 则每一个目标的检测框的中心点一定是落在某一个小区域内的；如果此时的中心点落在 x 框内，则 x 小区域就负责搞定这个目标；注意此时可能多个目标落在同一个区域内。\n每一个小区域设定 B （bounding box的数量）个可能的候选框，并计算每一个可能的候选框的得分 = 置信度，是一个（该候选框和真实的目标检测框的重合程度）和（这个框里确实框住了某一个物体）的综合度量指标，计算方式如下：\n（）\n其中，若bounding box包含物体，则P(object) = 1；否则P(object) = 0\n每一个预测是一个长度为 5 的向量，记作 （x, y, w, h, conf）\n\n(x, y) 表示当前预测的检测框的中心相对于我的小区域的位置（共  个小区域)，这里的 x 和 y 都是 0-1 之间的，也就是说是相对于当前小区域的左上角的偏移值\n(w,h) 表示检测框的宽度和高度，一般是处理到 0-1 之间，标记当前的预测框和整个图片的宽度/高度的比例 - conf 为上述的置信度，可以看作是当前的框的可信度的综合指标，由（是否框准了 = 是否和真实的预测框有较好的重合）和（是否框里确实框住了物体）两个部分影响\n\n网络结构\nOur detection network has 24 convolutional layers followed by 2 fully connected layers. Alternating 1 × 1 convolutional layers reduce the features space from preceding layers. We pretrain the convolutional layers on the ImageNet classifification task at half the resolution (224 × 224 input image) and then double the resolution for detection.\n\nYOLO网络借鉴了GoogLeNet分类网络结构。 网络有24个卷积层，其后是2个完全连接的层，不同的是，YOLO未使用inception module，而是使用1x1卷积层（此处1x1卷积层的存在是为了跨通道信息整合）+3x3卷积层简单替代。最终输出的是7x7x30的张量的预测值\n\n损失函数使用均方和误差作为loss函数来优化模型参数，即网络输出的SxSx(Bx5 + C)维向量与真实图像的对应SxSx(Bx5 + C)维向量的均方和误差。\n\nNMS 方法（Non-Maximal Suppression / 非极大值抑制）\n将同一目标内的bboxes按照cls score + IoU阈值做筛选，剔除冗余地、低置信度的bbox\n\n具体实现思路如下：\n\n选取此类物品box中置信度最高的box\n计算与其余此类box的IOU\nIOU&gt;nms_threshold则去除置信度小的那个box\n从剩余box中再选取置信度最高的box，如此循环\n\n"},{"title":"Total Variation distance","url":"/2022/05/30/distance/","content":"\n\\lVert u-v \\rVert_{TV}=\\sup{\\lvert \\mu(A)-v(A) \\rvert}"},{"title":"jetson配置日志","url":"/2022/04/16/jetson%E9%85%8D%E7%BD%AE%E6%97%A5%E5%BF%97/","content":"jetson nano apt更换国内源备份source.list文件\nsudo cp /etc/apt/sources.list /etc/apt/sources.list.bak  \n修改source.list文件\nsudo vim /etc/apt/sources.list\n删除所有内容，并复制：\ndeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic main multiverse restricted universedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-security main multiverse restricted universedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-updates main multiverse restricted universedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-backports main multiverse restricted universedeb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic main multiverse restricted universedeb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-security main multiverse restricted universedeb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-updates main multiverse restricted universedeb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-backports main multiverse restricted universe\n注意arm架构下的apt源与普通的ubuntu不相同\nthen\nsudo apt-get updatesudo apt-get upgrade\njtop安装先安装pip\nsudo apt-get install python3-pip\nthen\nsudo pip3 install jetson-stats -i https://pypi.tuna.tsinghua.edu.cn/simple\nsudo jtop # 打开jtop\nzerotier安装使用（内网穿透）安装命令\ncurl -s  https://install.zerotier.com  | sudo bash\n加入网络\nsudo zerotier-cli join xxxxxxxxxxxxxxxx\n离开网络\nsudo zerotier-cli leave xxxxxxxxxxxxxxxx\n启动\nsudo systemctl start zerotier-one.service\n设置开机自启\nsudo systemctl enable zerotier-one.service\nminifoege 安装https://github.com/conda-forge/miniforge\n在jetson nano中选择Mambaforge时 出现了pip 无法使用 illegal instruction(core dumped) 的问题\n安装miniforge后在虚拟环境中出现同样问题， 但能在base环境下正常使用pip\n所以选择使用它\n\n在Miniforge-Linux-aarch64.sh所在文件夹打开终端\n执行\nbash Miniforge-Linux-aarch64.sh\n全yes即可\nconda更换国内镜像源配置清华源：\nconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/#设置搜索时显示通道地址conda config --set show_channel_urls yes\n可执行conda config —show channels显示已添加的源\npip更换国内镜像源编辑pip配置文件：\nmkdir ~/.pipvim ~/.pip/pip.conf\n添加内容为：\n[global]index-url = https://pypi.tuna.tsinghua.edu.cn/simple[install]trusted-host = https://pypi.tuna.tsinghua.edu.cn\nconda更改base环境下python版本conda install python=&lt;版本号&gt;\n（看网上都是这么干的， 但由于我们想换版本时已经无意中在base环境下下载了很多包， 所以由于依赖问题这样会报错）\nconda clean -a # 删除所有包\njetson nano 和 jetson nx 配置 cudajetson nano 与 nx 已经内置好了cuda， 但需要配置环境变量才能使用\nvim ~/.bashrc\n在.bashrc文件中添加：\nexport PATH=/usr/local/cuda-10.2/bin:$PATHexport LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATHexport CUDA_HOME=/usr/local/cuda-10.2export OPENBLAS_CORETYPE=ARMV8\t\t\t# 据说不加的话，运行相关的项目会内核崩掉（but在我配置nano环境时即使加上也无济于事）\n再次执行：\nsource ~/.bashrc\n最后输入nvcc -V 测试环境变量是否设置正确\ncv2, torch等由于numpy问题报错illegal instruction(core dumped)我们下载的numpy版本是1.19.5\n在base环境中测试了几个版本发现都没有问题\n于是换了个numpy版本就解决了（大概是1.19.5版本的numpy在arm架构下出了点问题）\n在linux下使用opencv无法打开摄像头问题[ WARN:0] global /io/opencv/modules/videoio/src/cap_v4l.cpp (893) open VIDEOIO(V4L2:/dev/video0): can’t open camera by index发现是重复调用摄像头导致的：\n两次使用了cv2.VideoCapture(0)\n删去一个就可以了\n除此之外还遇到了另一个报错令代码无法运行（忘记记录了），原因是opencv版本太高， 降了几个版本就解决了\n报错This plugin does not support propagateSizeHints()， 图形界面控件消失网上的解决方案都奇奇怪怪的（我看不明白）\n在使用管理员权限运行代码后神奇的成功了\nsudo python main.py\npyside2的安装在网上没有找到支持arm架构的pyside2 whl安装包\n所以我们自己编译了pyside2\ndlib安装torch和torchvision的安装"},{"title":"pytorch笔记","url":"/2022/04/24/pytorch%E7%AC%94%E8%AE%B0/","content":"一.张量1.张量的数据类型\n\n默认数据类型为32位浮点型\n\ntorch.set_default_tensor_type()函数可设置默认的张量数据类型\n\na.long()  a.int()  a.float()方法\n\n2.张量的生成(1)列表或序列可通过torch.tensor()函数构造张量\n\n\n.shape .size .numel()方法\na  = torch.randn((2,3,5),dtype = torch.float32)print(a.shape)#打印“torch.Size([2,3,5])”不需要加括号，直接访问成员属性，返回的是torch.Size类对象，print(a.shape[1])#可以使用[]索引访问,所以size属性是一个迭代器print(a.size())#打印“torch.Size([2,3,5])”,与shape属性一致print(a.size(1))#可传入参数，返回3，即第i维的个数print(a.numel)#返回30，计算张量中包含元素数量\n通过torch.tensor()函数构造张量可使用dtype参数指定数据类型，使用requires_grad来指定是否需要计算梯度\n(2)torch.Tensor()——————一个类\n\n可以生成指定形状的张量\n\n(3)torch.from_numpy(ndarray)  torch.as_tensor()\n\n\n(4)依据数值创建\n\n\n\n\n\n\n\n\n\ntorch.empty()————返回填充有未初始化数据的张量，张量的形状由可变的参数大小定义\n&gt;&gt;&gt; torch.empty(2, 3)tensor(1.00000e-08 *       [[ 6.3984,  0.0000,  0.0000],        [ 0.0000,  0.0000,  0.0000]])\n(5)依据概率分布创建张量\ntorch.manual_seed()——————指定生成随机数种子\n\n \n\n\n3.张量的操作（1）张量的拼接与切分\ntorch.stack()会拓展张量维度\n\n\n（2）张量索引\n==注意index参数的数据类型必须是torch.long==\n例\n\n(对第0维度进行索引（相当于索引第一维度）)\n\n（3）张量变换\n\n\n\n==注意reshape共享数据内存==\n\n\n如图：\n\n\n\n沿着指定的维度重复tensor。不同与expand()，本函数复制的是tensor中的数据。扩展（expand）张量不会分配新的内存，只是在存在的张量上创建一个新的视图（view），一个大小（size）等于1的维度扩展到更大的尺寸。repeat沿着特定的维度重复这个张量，和expand()不同的是，这个函数拷贝张量的数据。\n\n\n（4）张量数学运算\n\n\n\n\n真多啊。。。用到再查叭。\n二.pytorch中的自动求导将张量的requires_grad参数设为Ture可自动求导得到其梯度\n\nTensor()类的重要属性：\n\n在Pytorch中，默认情况下，非叶节点的梯度值在反向传播过程中使用完后就会被清除，不会被保留。只有叶子节点的梯度值能够被保留下来\n\nretain_grad()可保存非叶子节点梯度\n\ngrad_fn：记录创建该张量时所用的方法（函数）\nprint(&quot;grad_fn:&quot;, w.grad_fn, x.grad_fn, a.grad_fn, b.grad_fn, y.grad_fn)# Out：grad_fn: None None &lt;AddBackward0 object at 0x000001C04BB24788&gt; &lt;AddBackward0 object at 0x000001C04605D188&gt; &lt;MulBackward0 object at 0x000001C04605D1C8&gt;\nautogradtorch.autograd.backward张量中的backward()方法直接调用了torch.autograd.backward()\n\nretain_graph参数设置为True，得以进行两次反向传播\n\ngrad_tensors参数用于多梯度权重的设置\nw = torch.tensor([1.], requires_grad=True)    x = torch.tensor([2.], requires_grad=True)    a = torch.add(w, x)     # retain_grad()    b = torch.add(w, 1)    y0 = torch.mul(a, b)    # y0 = (x+w) * (w+1)    y1 = torch.add(a, b)    # y1 = (x+w) + (w+1)    dy1/dw = 2    loss = torch.cat([y0, y1], dim=0)       # [y0, y1]    grad_tensors = torch.tensor([1., 1.])    # grad_tensors = torch.tensor([1., 2.])    loss.backward(gradient=grad_tensors)    # gradient 传入 torch.autograd.backward()中的grad_tensors    print(w.grad)        out：7 # 9\ntorch.autograd.grad\ncreate_graph   创建导数计算图，用于高阶求导\n\nautograd小贴士：1.梯度不自动清零\n\n使用grad.zero_()  对梯度清零\n\n2.依赖于叶子节点的节点， requires_grad默认为True\n\n3.叶子节点不可执行in-place操作\n\n可知+=操作时不改变内存地址，为in-place操作，不可对叶子节点执行\n\n三.torch.nn模块容器\n\n\n卷积层\n# 以torch.nn.Conv2d()为例， 介绍卷积再图像上的使用方法，其调用方式为：torch.nn.Conv2d(in_channels,               out_channels,               kernel_size,               stride=1,               padding=0,               dilation=1,               groups=1,               bias=True)\n\nimport numpy as npimport torchimport torch.nn as nnimport matplotlib.pyplot as pltfrom PIL import Imagemyim = Image.open(&quot;lenna.jpg&quot;)myimgray = np.array(myim.convert(&quot;L&quot;), dtype=np.float32)imh, imw = myimgray.shapemyimgray_t = torch.from_numpy(myimgray.reshape((1, 1, imh, imw)))kersize = 5ker = torch.ones(kersize, kersize, dtype=torch.float32)*-1ker[2, 2] = 24ker = ker.reshape((1, 1, kersize, kersize))conv2d = nn.Conv2d(1, 2, (kersize, kersize), bias = False)conv2d.weight.data[0] = kerimconv2dout = conv2d(myimgray_t)imconv2dout_im = imconv2dout.data.squeeze()plt.figure(figsize=(12, 6))plt.imshow(imconv2dout_im[0], cmap=plt.cm.gray)plt.axis(&quot;off&quot;)plt.show()\n\n可见使用边缘特征提取卷积核很好的提取出了图像的边缘信息\n池化层\n\n\n激活函数\n全连接层\n四.pytorch中的数据操作与预处理\nDataloader\nDataset\ntransforms\ncrop\n\n\n\n\nflip\nrotation\n\n\n\n\n\n\ntransforms的操作\n自定义transforms\n正态分布与平方损失接下来，我们通过对噪声分布的假设来解读平方损失目标函数。\n正态分布和线性回归之间的关系很密切。 正态分布（normal distribution），也称为高斯分布（Gaussian distribution）， 最早由德国数学家高斯（Gauss）应用于天文学研究。 简单的说，若随机变量xx具有均值μμ和方差σ2σ2（标准差σσ），其正态分布概率密度函数如下：\n(3.1.11)\np(x)=12πσ2−−−−√exp(−12σ2(x−μ)2).p(x)=12πσ2exp⁡(−12σ2(x−μ)2).\n下面我们定义一个Python函数来计算正态分布。\ndef normal(x, mu, sigma):    p = 1 / math.sqrt(2 * math.pi * sigma**2)    return p * np.exp(-0.5 / sigma**2 * (x - mu)**2)\n我们现在可视化正态分布。\n# 再次使用numpy进行可视化x = np.arange(-7, 7, 0.01)# 均值和标准差对params = [(0, 1), (0, 2), (3, 1)]d2l.plot(x, [normal(x, mu, sigma) for mu, sigma in params], xlabel=&#x27;x&#x27;,         ylabel=&#x27;p(x)&#x27;, figsize=(4.5, 2.5),         legend=[f&#x27;mean &#123;mu&#125;, std &#123;sigma&#125;&#x27; for mu, sigma in params])\n\n就像我们所看到的，改变均值会产生沿xx轴的偏移，增加方差将会分散分布、降低其峰值。\n均方误差损失函数（简称均方损失）可以用于线性回归的一个原因是： 我们假设了观测中包含噪声，其中噪声服从正态分布。 噪声正态分布如下式:\n(3.1.12)\ny=w⊤x+b+ϵ,y=w⊤x+b+ϵ,\n其中，ϵ∼N(0,σ2)ϵ∼N(0,σ2)。\n因此，我们现在可以写出通过给定的xx观测到特定yy的似然（likelihood）：\n(3.1.13)\nP(y∣x)=12πσ2−−−−√exp(−12σ2(y−w⊤x−b)2).P(y∣x)=12πσ2exp⁡(−12σ2(y−w⊤x−b)2).\n现在，根据极大似然估计法，参数ww和bb的最优值是使整个数据集的似然最大的值：\n(3.1.14)\nP(y∣X)=∏i=1np(y(i)|x(i)).P(y∣X)=∏i=1np(y(i)|x(i)).\n根据极大似然估计法选择的估计量称为极大似然估计量。 虽然使许多指数函数的乘积最大化看起来很困难， 但是我们可以在不改变目标的前提下，通过最大化似然对数来简化。 由于历史原因，优化通常是说最小化而不是最大化。 我们可以改为最小化负对数似然−logP(y∣X)−log⁡P(y∣X)。 由此可以得到的数学公式是：\n(3.1.15)\n−logP(y∣X)=∑i=1n12log(2πσ2)+12σ2(y(i)−w⊤x(i)−b)2.−log⁡P(y∣X)=∑i=1n12log⁡(2πσ2)+12σ2(y(i)−w⊤x(i)−b)2.\n现在我们只需要假设σσ是某个固定常数就可以忽略第一项， 因为第一项不依赖于ww和bb。 现在第二项除了常数1σ21σ2外，其余部分和前面介绍的均方误差是一样的。 幸运的是，上面式子的解并不依赖于σσ。 因此，在高斯噪声的假设下，最小化均方误差等价于对线性模型的极大似然估计。\n"},{"title":"web crawler","url":"/2022/04/30/webcrawler/","content":""},{"title":"余弦相似度","url":"/2022/05/28/%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6/","content":"余弦相似度\n余弦距离，也称为余弦相似度，是用向量空间中两个向量夹角的余弦值作为衡量两个个体间差异的大小的度量。\n余弦值越接近1，就表明夹角越接近0度，也就是两个向量越相似，这就叫”余弦相似性”。\n\n\n二维\n\n拓展至n维\n\n"},{"title":"反卷积","url":"/2022/05/07/%E5%8F%8D%E5%8D%B7%E7%A7%AF/","content":""},{"title":"闵可夫斯基距离（Minkowski距离）","url":"/2022/05/28/%E9%97%B5%E5%8F%AF%E5%A4%AB%E6%96%AF%E5%9F%BA%E8%B7%9D%E7%A6%BB/","content":"\n一般而言，定义一个距离函数 d(x,y), 需要满足下面几个准则：\n   1 .d(x,x) = 0 // 到自己的距离为0 \n   2 .d(x,y) &gt;= 0 // 距离非负 \n\nd(x,y) = d(y,x) // 对称性: 如果 A 到 B 距离是 a，那么 B 到 A 的距离也应该是 a \nd(x,k) d(k,y) &gt;= d(x,y) // 三角形法则: (两边之和大于第三边)\n\n\n闵可夫斯基距离可以定义为：\n\n当p为1时为曼哈顿距离， 即一阶范式，p为2时为欧几里得距离， 即二阶范式。\n当 p 趋近于无穷大时， 转化为切比雪夫距离（Chebyshev distance）(L∞度量) 。\n\n\n"}]