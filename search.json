[{"title":"Generative Adversarial Nets","url":"/2022/04/30/Generative%20Adversarial%20Nets/","content":"\n    $data$→真实数据$（groundtruth）$    $p_{data}$→真实数据的分布    $z$→噪音（输入数据）    $p_{z}$→原始噪音的分布    $p_g$→经过生成器后的数据分布    $G()$→生成映射函数    $D()$→判别映射函数\n\n信息量在信息论当中，我们用一件事情发生的概率的负对数表示信息量。$$H=-\\log{p}$$如公式所示，也就是事情发生的概率越大，其包含的信息量就越小，反之亦然。\n信息熵信息熵，也是平均自信息量，如公式所示，表示的是自信息量(也就是上面提到的信息量)的数学期望，表示为概率与其自信息量的乘积然后再求和。$$H(X)=-\\sum_{x\\in{X}}p(x)\\log{p(x)}$$\n交叉熵\n交叉熵刻画的是实际输出（概率）与期望输出（概率）的距离，也就是交叉熵的值越小，两个概率分布就越接近，即拟合的更好。\n\n交叉熵其实就是对于一个分布p来说，我们用分布q来对分布p中的信息进行编码，所需要的信息量。\n如果交叉熵越小，说明用分布q来表示分布p所需要的信息量越小，这也就说明q分布越接近p分布。$$H(p,q)=-\\sum_xp(x)\\log{q(x)}$$\nKL散度（相对熵）\n描述两个概率分布之间差异的非对称量\n其定义就是用理论分布去拟合真实分布时产生的信息损耗\n\n若有两个随机变量p, q，且其概率分布分别为p(x)、q(x)，则p相对q的相对熵为：$$D_{KL}(p||q)=\\sum^n_{i=1}p(x)\\log\\frac{p(x)}{q(x)}$$\n又由定义可知：==KL散度 = 交叉熵 - 信息熵==\n因此，KL散度可通过下式得出：$$\\begin{aligned}D_{KL}(p||q)&amp;=H(p,q)-H(p)\\&amp;=-\\sum_xp(x)(\\log{q(x)}-\\log{p(x)})\\&amp;=-\\sum{p(x)\\log{\\frac{q(x)}{p(x)}}}\\end{aligned}$$正定性\n相对熵的值是非负值，即D(P||Q)&gt;0。\n不对称性\n尽管KL散度从直观上是个度量或距离函数，但它并不是一个真正的度量或者距离，因为它不具有对称性，即D(P||Q)!=D(Q||P)。\nJS散度\n由于KL散度的不对称性，所以这里引入了一个JS散度，也就是Jensen-Shannon散度，JS散度度量了两个概率分布的相似度，基于KL散度的变体，解决了KL散度非对称的问题，一般地，JS散度是对称的\n\n公式如下$$JS(p||q)=\\frac{1}{2}KL(p(x)||\\frac{p(x)+q(x)}{2}+\\frac{1}{2}KL(q(x)||\\frac{p(x)+q(x)}{2})$$\n全概率公式贝叶斯公式条件概率（后验概率）就是事件A在另一个事件B已经发生的条件下发生概率，公式表示为P(A|B)。\n联合概率表示两件事情共同发生的概率。A与B的联合概率表示为p(A,B)。\n边缘概率（先验概率）是某个事件发生的概率。边缘概率是这样得到的：在联合概率中，把最终结果中那些不需要的事件通过合并成它们的全概率，而消去它们（对离散随机变量用求和得全概率，对连续随机变量用积分得全概率），这称为边缘化（marginalization），比如A的边缘概率表示为P(A)，B的边缘概率表示为P(B)。$$P(A\\cap{B})=P(A)P(B|A)=P(B)P(A|B)$$\n$$P (A|B)=P (B|A)*P (A)/P (B)$$\n似然函数$$p(x|\\theta)$$\n其中：x表示某一个具体的数据，θ 表示模型的参数。\n若x已知，$\\theta$为变量，则该函数为似然函数     描述对于不同的模型参数，x样本点出现的概率\n若x为变量，$\\theta$未知，则该函数为概率函数     描述对于参数模型$\\theta$,  不同的样本点x出现的概率为多少\n最大似然估计\n利用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值\n\n最大后验概率估计Generative Adversarial Networks对GAN训练过程的理解：\n将符合正态分布的随机噪声z输入生成器生成G(z)，经处理后与真实数据x一起交予判别器处理，判别器将G(z)是否为真实数据并给出一个概率值D(G(z))。我们的训练目标是：训练判别器D使D(x)最大，而D(G(z))最小（ We train D to maximize the probability of assigning the correct label to both training examples and samples from G），训练生成器G使D(G(z))最大（train G to minimize log(1 − D(G(z)))）。我们的训练策略是先训练k次判别器D使之具备一定的判别能力（在2014年论文中k取1），之后训练一次生成器G，如此迭代训练以接近全局最优。\n\n\n\n\n目标函数：$$\\underset{G}{min}\\underset{D}{max}V(D,G)=E_{x\\backsim{p_{data}}}[\\log{D(x)}]+E_{z\\backsim{p_z(z)}}[\\log{1-D(G(z)))}]$$\n A less formal, more pedagogical explanation of the approach.\n\n\n\n蓝线 判别分布 $D$\n红线 生成分布 $p_{g}$\n黑线 真实数据分布 $p_{x}$\n\n$$\\begin{aligned}V(G,D)&amp;=\\int_xp_{data}(x)\\log{(D(x))}dx+\\int_xp(z)\\log{(1-D(g(z)))}dz\\&amp;=\\int_xp_{data(x)}\\log{(D(x))}+p_g(x)\\log{(1-D(x))dx}\\end{aligned}$$\n为什么选择训练判别器？\n在刚开始训练的时候，生成器G生成的数据显然与真实数据相差很大，此时判别器D将以高置信度拒绝生成器G生成的样本，这将导致$\\log{1-D(G(z))}$饱和（很大）。\n为什么不先将判别器训练得很好再训练生成器？\n为什么这样设计目标函数？\n何时达到全局最优？\n"},{"title":"Git学习笔记","url":"/2022/04/10/Git%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","content":"\n\n\ngit init —— 初始化一个Git仓库 执行后会生成一个.git目录， 该目录包含了资源的所有元数据\n使用指定目录作为git仓库  ——git init newrepo\n执行后会在newrepo目录下生成.git目录\n将文件纳入版本控制\ngit add —— 添至暂存区git add . —— 将当前目录下所有未纳入的文件添加到暂存区\ngit add {文件名} —— 将指定文件添加到暂存区\ngit commit —— 提交git commit -m ‘提交说明’ —— 对暂存区中的文件进行提交（添加到仓库中）\ngit push —— 上传远程代码并合并git push 命用于从将本地的分支版本上传到远程并合并。\n命令格式如下：\ngit push &lt;远程主机名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt;\n\n若远程分支名与本地分支名相同则可以省略：及之后部分\n若版本有差异，想要强制推送\ngit push --force &lt;远程主机名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt;\n\n若要删除主机的分支\ngit push origin --delete master # 表示删除origin主机的master分支\n\n\n\ngit pull —— 下载远程代码并合并git pull 命令用于从远程获取代码并合并本地的版本。\ngit pull 其实就是 git fetch 和 git merge FETCH_HEAD 的简写。 命令格式如下：\ngit pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt;\n\n\n\n\n\ngit clone —— 从现有Git仓库中拷贝项目git clone \nor\ngit clone   ——克隆到指定目录\n如果要自己定义要新建的项目目录名称，可以在上面的命令末尾指定新的名字\ngit commit -a 跳过git add，直接添加至暂存区后提交\ngit config —— 配置信息git config –list —— 显示当前的git配置信息\ngit config -e  —— 针对当前仓库编辑git配置文件\ngit config -e –global —— 针对系统上所有仓库\n设置提交代码时的用户信息：\ngit config –global user.name {YOURGITHUBNAME}git config –global user.email {YOUREMAIL}\ngit status —— 查看仓库当前的状态    显示有变更的文件git status -s 获得更简短的输出结果\ngit diff  —— 比较文件的不同，即暂存区和工作区的差异\n尚未缓存的改动：git diff\n查看已缓存的改动： git diff –cached\n查看已缓存的与未缓存的所有改动：git diff HEAD\n显示摘要而非整个 diff：git diff –stat\n\ngit reset —— 用于回退版本， 可以制定退回某一次提交的版本git reset [--soft | --mixed | --hard] [HEAD]\n\ngit reset HEAD^ - 回退所有内容到上一个版本\ngit reset HEAD^ {filename} - 回退指定文件到上一个版本\ngit reset {版本号} - 回退到指定版本\ngit reset –soft HEAD – soft参数用于回退到某个版本\n例：\n$ git reset --soft HEAD~3 # 回退上上上一个版本\n\ngit reset –hard HEAD\n–hard 参数撤销工作区中所有未提交的修改内容，将暂存区与工作区都回到上一次版本，并删除之前的所有信息提交（慎重使用）\nHEAD 说明：\n\nHEAD 表示当前版本\n\nHEAD^ 上一个版本\n\nHEAD^^ 上上一个版本\n\nHEAD^^^ 上上上一个版本\n\n\n\n以此类推…\n\n可以使用 ～数字表示\n\nHEAD~0 表示当前版本\nHEAD~1 上一个版本\nHEAD^2 上上一个版本\nHEAD^3 上上上一个版本\n以此类推…\n\ngit reset HEAD 命令用于取消已缓存的内容。\ngit rm  —— 将文件从暂存区和工作区中删除如果删除之前修改过并且已经放到暂存区域的话，则必须要用强制删除选项 -f\ngit rm -f \n如果想把文件从暂存区域移除，但仍然希望保留在当前工作目录中，换句话说，仅是从跟踪清单中删除，使用 –cached 选项即可：\ngit rm –cached \ngit mv  —— 用于移动或重命名一个文件,目录或软连接。git mv [file] [newfile]\ngit log —— 查看历史提交记录用 –online 选项来查看历史记录的简洁版本。\ngit log –online\ngit blame  - 以列表形式查看指定文件的历史修改记录\ngit remote —— 远程仓库操作git remote -v —— 显示所有远程仓库\ngit remote show [remote] —— 显示某个远程仓库的信息\nremote为远程仓库地址\ngit remote set-url [shortname] [url]\nshortname 为本地的版本库\n添加远程版本库：\ngit remote add [shortname] [url]\nshortname 为本地的版本库\ngit remote rm name  # 删除远程仓库git remote rename old_name new_name  # 修改仓库名\ngit branch (branchname) —— 创建新分支git branch —— 列出本地的分支\ngit checkout (branchname) —— 切换分支命令当切换分支的时候，Git 会用该分支的最后提交的快照替换你的工作目录的内容， 所以多个分支不需要多个目录。\n也可以使用 git checkout -b (branchname) —— 创建新分支并立即切换到该分支下，从而在该分支中操作。\ngit merge —— 合并分支命令git merge [branchname] —— 将指定分支与当前所在分支合并 \ngit fetch —— 从远程获取代码库执行完后执行git merge合并远程分支到你所在的分支\n\ngit tag [tagname]—— 为提交快照打上标签例：\n我们可以用 git tag -a v1.0 命令给最新一次提交打上（HEAD）”v1.0”的标签\ngit tag —— 查看所有标签\n-a 选项意为”创建一个带注解的标签”。 不用 -a 选项也可以执行的，但它不会记录这标签是啥时候打的，谁打的，也不会让你添加个标签的注解。\ngit log –decorate —— 查看标签\n\n生成ssh密钥执行：\nssh-keygen -t rsa -C &lt;your email&gt;\n\n会生成一个.ssh文件\n找到其中的id_rsa.pub将其中内容复制\n进入github settings 点击SSH and GPG keys\n创建新密钥并将密钥内容粘贴入其中\n"},{"title":"Json学习笔记","url":"/2022/04/10/Json%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","content":"\n\n\nJSON\nJSON 语法规则\nJSON 名称/值对\nJSON 值\nJSON 文件\nJSON对象\n使用点号访问对象值\n使用点号. 或者中括号 [] 来访问嵌套的JSON对象。\n修改JSON值\n修改对象属性\n\n\nJSON数组\n数组可以作为JSON对象\nJSON对象中的数组\n嵌套 JSON 对象中的数组\n\n\n\n\nPython json\njson.dumps\njson.loads\n\n\n\n\n\nJSONJSON: JavaScript Object Notation(JavaScript 对象表示法)\nJSON 语法规则JSON 语法是 JavaScript 对象表示语法的子集。\n\n数据在名称/值对中\n数据由逗号分隔\n大括号 {} 保存对象\n中括号 [] 保存数组，数组可以包含多个对象\n\nJSON 名称/值对JSON 数据的书写格式是：\nkey : value\n\n名称/值对包括字段名称（在双引号中），后面写一个冒号，然后是值：\n“name” : “菜鸟教程”\nJSON 值JSON 值可以是：\n\n数字（整数或浮点数）\n字符串（在双引号中）\n逻辑值（true 或 false）\n数组（在中括号中）\n对象（在大括号中）\nnull\n\nJSON 文件\nJSON 文件的文件类型是 .json\nJSON 文本的 MIME 类型是 application/json\n\nMINE类型：媒体类型（通常称为 Multipurpose Internet Mail Extensions 或 MIME 类型 ）是一种标准，用来表示文档、文件或字节流的性质和格式。 它在IETF RFC 6838中进行了定义和标准化。\nJSON对象必须在大括号{}中书写，\nkey必须是字符串，value可以是合法的JSON数据类型（见JSON值）\n使用点号访问对象值例：\nvar myobj, x;myobj = &#123;&quot;name&quot;:&quot;runoob&quot;, &quot;alexa&quot;:10000, &quot;site&quot;:null&#125;;x = myobj[&quot;name&quot;];\n\n使用点号. 或者中括号 [] 来访问嵌套的JSON对象。x = myobj.sites.site1;x = myobj.sites[&quot;site1&quot;];\n\n\n\n修改JSON值使用点号访问并修改\nmyobj.sites.site1 = &quot;sxasxaxa&quot;\n\n使用中括号访问并修改\nmyobj.sites.[&quot;site1&quot;] = &quot;sadadsad&quot;\n\n\n\n修改对象属性使用delete关键字来删除JSON对象的属性：\ndelete myobj.sites.site1\n\n\n\nJSON数组数组可以作为JSON对象例：\n[ &quot;Google&quot;, &quot;Runoob&quot;, &quot;Taobao&quot; ]\n\n\n\nJSON对象中的数组例：\n&#123;&quot;name&quot;:&quot;网站&quot;,&quot;num&quot;:3,&quot;sites&quot;:[ &quot;Google&quot;, &quot;Runoob&quot;, &quot;Taobao&quot; ]&#125;\n\n嵌套 JSON 对象中的数组JSON 对象中数组可以包含另外一个数组，或者另外一个 JSON 对象：\n例：\nmyObj = &#123;    &quot;name&quot;:&quot;网站&quot;,    &quot;num&quot;:3,    &quot;sites&quot;: [        &#123; &quot;name&quot;:&quot;Google&quot;, &quot;info&quot;:[ &quot;Android&quot;, &quot;Google 搜索&quot;, &quot;Google 翻译&quot; ] &#125;,        &#123; &quot;name&quot;:&quot;Runoob&quot;, &quot;info&quot;:[ &quot;菜鸟教程&quot;, &quot;菜鸟工具&quot;, &quot;菜鸟微信&quot; ] &#125;,        &#123; &quot;name&quot;:&quot;Taobao&quot;, &quot;info&quot;:[ &quot;淘宝&quot;, &quot;网购&quot; ] &#125;    ]&#125;\n\n————JSON数组和对象都可以使用for-in循环来访问\nPython jsonjson.dumpsjson.dumps(obj, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, encoding=&quot;utf-8&quot;, default=None, sort_keys=False, **kw)\n\n——将python对象编码成JSON字符串\nimport jsondata = [ &#123; &#x27;a&#x27; : 1, &#x27;b&#x27; : 2, &#x27;c&#x27; : 3, &#x27;d&#x27; : 4, &#x27;e&#x27; : 5 &#125; ]data2 = json.dumps(&#123;&#x27;a&#x27;: &#x27;Runoob&#x27;, &#x27;b&#x27;: 7&#125;, sort_keys=True, indent=4, separators=(&#x27;,&#x27;, &#x27;: &#x27;))print(data2)\n\n\n\njson.loadsjson.loads(s[, encoding[, cls[, object_hook[, parse_float[, parse_int[, parse_constant[, object_pairs_hook[, **kw]]]]]]]])\n\n\n\n——json.loads 用于解码 JSON 数据。该函数返回 Python 字段的数据类型。\nimport jsonjsonData = &#x27;&#123;&quot;a&quot;:1,&quot;b&quot;:2,&quot;c&quot;:3,&quot;d&quot;:4,&quot;e&quot;:5&#125;&#x27;;text = json.loads(jsonData)print(text)\n\n\n\n\n"},{"title":"baseline","url":"/2022/04/27/baseline/","content":"VGGVGG 网络结构\n\n\n\n\n因为只使用了3x3卷积核， 尽管深度很大，网络中的权重数量相较具有更大卷积层宽度和感受野的网络并不大。\n\n\n\n\n\n\n\n\n\n3×3卷积的使用\n\n图为两个3×3卷积核的堆叠\n1.可见两个3×3卷积核堆叠在原feature map中的感受野与一个5×5卷积核相同， 三个3x3的堆叠卷基层的感受野是7x7\n2.可以把三个3x3的filter看成是一个7x7filter的分解中间层有非线性的分解, 并且起到隐式正则化的作用。\n3.使用小卷积核减少了参数数量：\n假设该卷积层的卷积核为3×3，为了清晰明了假设卷积层的输入和输出的特征图（featuremap）大小（其实是channel通道数）分别为C1，C2。说明：卷积核的应该是一个多维的矩阵K×K×channels，其中channels是由输入的featuremap的通道数决定的，而卷积层中卷积核的个数是由输出的featuremap的通道数决定的。所以该卷积层的参数量是：（3×3×C1）× C2说明:（3×3×C1） —— 是每一个卷积核的参数量（输入）          × C2 —— 是总共C2个卷积核（输出的通道数）\n"},{"title":"jetson配置日志","url":"/2022/04/16/jetson%E9%85%8D%E7%BD%AE%E6%97%A5%E5%BF%97/","content":"jetson nano apt更换国内源备份source.list文件\nsudo cp /etc/apt/sources.list /etc/apt/sources.list.bak  \n\n修改source.list文件\nsudo vim /etc/apt/sources.list\n\n删除所有内容，并复制：\ndeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic main multiverse restricted universedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-security main multiverse restricted universedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-updates main multiverse restricted universedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-backports main multiverse restricted universedeb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic main multiverse restricted universedeb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-security main multiverse restricted universedeb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-updates main multiverse restricted universedeb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-backports main multiverse restricted universe\n\n注意arm架构下的apt源与普通的ubuntu不相同\nthen\nsudo apt-get updatesudo apt-get upgrade\n\n\n\n\n\njtop安装先安装pip\nsudo apt-get install python3-pip\n\nthen\nsudo pip3 install jetson-stats -i https://pypi.tuna.tsinghua.edu.cn/simple\n\nsudo jtop # 打开jtop\n\n\n\nzerotier安装使用（内网穿透）安装命令\ncurl -s  https://install.zerotier.com  | sudo bash\n\n加入网络\nsudo zerotier-cli join xxxxxxxxxxxxxxxx\n\n离开网络\nsudo zerotier-cli leave xxxxxxxxxxxxxxxx\n\n启动\nsudo systemctl start zerotier-one.service\n\n设置开机自启\nsudo systemctl enable zerotier-one.service\n\n\n\n\n\n\n\nminifoege 安装https://github.com/conda-forge/miniforge\n在jetson nano中选择Mambaforge时 出现了pip 无法使用 illegal instruction(core dumped) 的问题\n安装miniforge后在虚拟环境中出现同样问题， 但能在base环境下正常使用pip\n所以选择使用它\n\n在Miniforge-Linux-aarch64.sh所在文件夹打开终端\n执行\nbash Miniforge-Linux-aarch64.sh\n\n全yes即可\nconda更换国内镜像源配置清华源：\nconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/#设置搜索时显示通道地址conda config --set show_channel_urls yes\n\n可执行conda config –show channels显示已添加的源\npip更换国内镜像源编辑pip配置文件：\nmkdir ~/.pipvim ~/.pip/pip.conf\n\n添加内容为：\n[global]index-url = https://pypi.tuna.tsinghua.edu.cn/simple[install]trusted-host = https://pypi.tuna.tsinghua.edu.cn\n\n\n\n\n\n\n\n\n\nconda更改base环境下python版本conda install python=&lt;版本号&gt;\n\n（看网上都是这么干的， 但由于我们想换版本时已经无意中在base环境下下载了很多包， 所以由于依赖问题这样会报错）\nconda clean -a # 删除所有包\n\n\n\n\n\n\n\njetson nano 和 jetson nx 配置 cudajetson nano 与 nx 已经内置好了cuda， 但需要配置环境变量才能使用\nvim ~/.bashrc\n\n在.bashrc文件中添加：\nexport PATH=/usr/local/cuda-10.2/bin:$PATHexport LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATHexport CUDA_HOME=/usr/local/cuda-10.2export OPENBLAS_CORETYPE=ARMV8\t\t\t# 据说不加的话，运行相关的项目会内核崩掉（but在我配置nano环境时即使加上也无济于事）\n\n再次执行：\nsource ~/.bashrc\n\n最后输入nvcc -V 测试环境变量是否设置正确\ncv2, torch等由于numpy问题报错illegal instruction(core dumped)我们下载的numpy版本是1.19.5\n在base环境中测试了几个版本发现都没有问题\n于是换了个numpy版本就解决了（大概是1.19.5版本的numpy在arm架构下出了点问题）\n在linux下使用opencv无法打开摄像头问题[ WARN:0] global /io/opencv/modules/videoio/src/cap_v4l.cpp (893) open VIDEOIO(V4L2:/dev/video0): can’t open camera by index发现是重复调用摄像头导致的：\n两次使用了cv2.VideoCapture(0)\n删去一个就可以了\n除此之外还遇到了另一个报错令代码无法运行（忘记记录了），原因是opencv版本太高， 降了几个版本就解决了\n报错This plugin does not support propagateSizeHints()， 图形界面控件消失网上的解决方案都奇奇怪怪的（我看不明白）\n在使用管理员权限运行代码后神奇的成功了\nsudo python main.py\npyside2的安装在网上没有找到支持arm架构的pyside2 whl安装包\n所以我们自己编译了pyside2\ndlib安装torch和torchvision的安装"},{"title":"Yolo","url":"/2022/04/30/Yolo/","content":"IoU（Intersection over union）\n交并比，衡量两个区域的重叠程度，是二者重叠部分面积占二者总面积的比例\n\n\n在目标检测任务中，如果我们模型输出的矩形框与我们人工标注的矩形框的IoU值大于某个阈值时（通常为0.5）即认为我们的模型输出了正确的\nPrecision &amp; Recall假设我们有一组图片，里面有若干待检测的目标，\nPrecision就代表我们模型检测出来的目标有多大比例是真正的目标物体，\nRecall就代表所有真实的目标有多大比例被我们的模型检测出来了。\n\nTP ：模型预测为某类物品（检测出的矩形框大于置信度阈值）且与数据集标注中某个目标框IOU大于0.5\nTN ：模型预测不为某类物品（检测出的矩形框小于置信度阈值）但与数据集标注中某个目标框IOU大于0.5\nFP ：模型预测为某类物品，但与数据集标注中所有目标框IOU均大于0.5（重复检测）\nFN ：模型预测不为某类物品，且与数据集中所有目标框IOU均大于0.5\n\n\n\n\n准确率： 模型检测出的物品中正确的比例\n\n召回率： 所有正确的目标中被模型检测出来的比例\n\nPR曲线\n我们当然希望检测的结果P越高越好，R也越高越好，但事实上这两者在某些情况下是矛盾的。比如极端情况下，我们只检测出了一个结果，且是准确的，那么Precision就是100%，但是Recall就很低；而如果我们把所有结果都返回，那么必然Recall必然很大，但是Precision很低。\n因此在不同的场合中需要自己判断希望P比较高还是R比较高。如果是做实验研究，可以绘制Precision-Recall曲线来帮助分析。\n\n\nAP (Average Precision)AP = $\\int^1_0p(r)dr$\n在实际应用中，我们并不直接对该PR曲线进行计算，而是对PR曲线进行平滑处理。即对PR曲线上的每个点，Precision的值取该点右侧最大的Precision的值。\n？\nYolov1\n将目标检测问题转化为一个回归问题进行求解，也就是说将图像作为输入（像素数据），直接输出物体的位置和所属于的类别的置信度（是以一个向量的形式表示的，后续会介绍），属于端到端的模型形式。\n\n基本思想：将图片划分为S*S个区域（gridcell），假设都存在一个 true answer 也就是针对这个目标的最好的检测框 ， 则每一个目标的检测框的中心点一定是落在某一个小区域内的；如果此时的中心点落在 x 框内，则 x 小区域就负责搞定这个目标；注意此时可能多个目标落在同一个区域内。\n每一个小区域设定 B （bounding box的数量）个可能的候选框，并计算每一个可能的候选框的得分 = 置信度，是一个（该候选框和真实的目标检测框的重合程度）和（这个框里确实框住了某一个物体）的综合度量指标，计算方式如下：\n$confidence = Pr（Object）* IOU^{truth}_{pred}$\n其中，若bounding box包含物体，则P(object) = 1；否则P(object) = 0\n每一个预测是一个长度为 5 的向量，记作 （x, y, w, h, conf）\n\n(x, y) 表示当前预测的检测框的中心相对于我的小区域的位置（共 $S^2$ 个小区域)，这里的 x 和 y 都是 0-1 之间的，也就是说是相对于当前小区域的左上角的偏移值\n(w,h) 表示检测框的宽度和高度，一般是处理到 0-1 之间，标记当前的预测框和整个图片的宽度/高度的比例 - conf 为上述的置信度，可以看作是当前的框的可信度的综合指标，由（是否框准了 = 是否和真实的预测框有较好的重合）和（是否框里确实框住了物体）两个部分影响\n\n网络结构\n\nOur detection network has 24 convolutional layers followed by 2 fully connected layers. Alternating 1 × 1 convolutional layers reduce the features space from preceding layers. We pretrain the convolutional layers on the ImageNet classifification task at half the resolution (224 × 224 input image) and then double the resolution for detection.\n\nYOLO网络借鉴了GoogLeNet分类网络结构。 网络有24个卷积层，其后是2个完全连接的层，不同的是，YOLO未使用inception module，而是使用1x1卷积层（此处1x1卷积层的存在是为了跨通道信息整合）+3x3卷积层简单替代。最终输出的是7x7x30的张量的预测值\n\n\n\n\n\n\n\n\n损失函数\n使用均方和误差作为loss函数来优化模型参数，即网络输出的SxSx(Bx5 + C)维向量与真实图像的对应SxSx(Bx5 + C)维向量的均方和误差。\n\n\n\n\nNMS 方法（Non-Maximal Suppression / 非极大值抑制）\n\n将同一目标内的bboxes按照cls score + IoU阈值做筛选，剔除冗余地、低置信度的bbox\n\n"},{"title":"OpenMV实现靶点检测","url":"/2022/04/27/OpenMV%E5%AE%9E%E7%8E%B0%E9%9D%B6%E7%82%B9%E6%A3%80%E6%B5%8B/","content":"—— 未完\nidea:\n\n初步想法是利用颜色信息对靶子进行检测\n再对靶点进行定位。若效果不佳考虑部署TensorFlow Lite yolo进行目标检测\n边缘检测\n图像对比\n先颜色识别后模块匹配\n\n\n决定先色块识别定位靶子。舵机追踪靶子方位同时横向运动小车，令小车舵机与车身角度为90度时舵机对准靶子。转动小车使车身与舵机夹角为0度。使小车直行，并进行边缘检测，传回矩形靶子的长宽大小比例，分析数据并不断进行微调。戳中靶心后转动舵机寻找第二个靶子重复以上操做。\n\n1.设置窗口roi\nsensor.set_windowing(roi)\n\n\n\n\nroi （回报率） （感兴趣的区域）（进行检测的区域）\n\nroi的格式是(x, y, w, h)的tupple\n2.水平翻转图像，使小车视野与实际相同\n水平方向翻转：\nsensor.set_hmirror(True)\n\n\n\n3.获取区域内的平均颜色或者占面积最大的颜色信息\n使用 Statistics\nimage.get_statistics(roi=Auto)\n\n\n\n4.寻找色块\nimage.find_blobs(thresholds, roi=Auto, x_stride=2, y_stride=1, invert=False, area_threshold=10, pixels_threshold=10, merge=False, margin=0, threshold_cb=None, merge_cb=None)\n\n\n\n\nthresholds是颜色的阈值，注意：这个参数是一个列表，可以包含多个颜色。如果你只需要一个颜色，那么在这个列表中只需要有一个颜色值，如果你想要多个颜色阈值，那这个列表就需要多个颜色阈值。注意：在返回的色块对象blob可以调用code方法，来判断是什么颜色的色块。\n\n\n\n\n\n阈值参数的结构\ncolour = (minL, maxL, minA, maxA, minB, maxB)\n\n\n\n\n\nOpenMV 的IDE里加入了阈值选择工具      用他！\n(50, 75, -60, -14, 12, 62)浅测一个绿色 感觉不是很准。。\n靶点检测场地为200*200   调整x, y_stride    将merge设置为True\nblob.rect() 返回这个色块的外框——矩形元组(x, y, w, h)\n\n\n\n\n\n\n\n\n\n\n边缘检测\nimage.find_edges(edge_type[,threshold])\n将图像变为黑白。边缘保留白色像素\nedge_type 参数：image.EDGE_SIMPLE ——简单的阈值高通滤波算法\n​                               image.EDGE_CANNY ——canny边缘检测\nthreshold —— 包含高低阈值的二元组 默认（100，200） 仅支持灰度图像\n例程：\n# Canny边缘检测:## 这个例子展示了Canny边缘检测。import sensor, image, timesensor.reset() # 初始化sensor.sensor.set_pixformat(sensor.GRAYSCALE) # or sensor.RGB565#设置图像色彩格式，有RGB565色彩图和GRAYSCALE灰度图两种sensor.set_framesize(sensor.QQVGA) # or sensor.QVGA (or others)#设置图像像素大小sensor.skip_frames(30) # 让新的设置生效sensor.set_gainceiling(8)clock = time.clock() # 跟踪FPS帧率while(True):    clock.tick() # 追踪两个snapshots()之间经过的毫秒数.    img = sensor.snapshot() # 拍一张照片并返回图像。    # 使用Canny边缘检测器    img.find_edges(image.EDGE_CANNY, threshold=(50, 80))    #threshold设置阈值    # 更快更简单的边缘检测    #img.find_edges(image.EDGE_SIMPLE, threshold=(100, 255))    print(clock.fps()) # 注意:你的OpenMV摄像头的运行速度只有它的一半\n\n\n\n\n\nimport sensor, image, lcd#初始化摄像头sensor.reset() # 初始化摄像头模块.sensor.set_pixformat(sensor.GRAYSCALE) # 或者使用 sensor.RGB565 彩色sensor.set_framesize(sensor.QQVGA) # 或者使用 sensor.QVGA (or others)sensor.skip_frames(time = 2000) #延时让摄像头文稳定.sensor.set_gainceiling(8) #设置增益，这是官方推荐的参数lcd.init()                          # LCD初始化while(True):    img = sensor.snapshot() # 拍摄并返回图像.    #使用 Canny 边缘检测器    img.find_edges(image.EDGE_CANNY, threshold=(50, 80))    lcd.display(img)                # LCD显示img\n\n\n\n\n\n\n\n舵机控制\n构造函数\n\n\nclasspyb.Servo(id)\n创建一个伺服对象。 id 为1-3，与引脚P7至P9相对应。\n\n\n\n方法\n\nServo.angle([*angle, time=0*]**)\n若未给定参数，该函数返回当前角度。若给定函数，该函数设置servo的角度：angle 是度数计的移动的角度。time 是达到指定角度所用的毫秒数。若省略，则servo会尽快移动到新的位置。\n\nServo.speed([*speed, time=0*]**)\n若未给定参数，该函数会返回当前速度。若给定参数，该函数设置servo的速度：speed 是改变的速度，取值100-100。time 是达到指定角度所用的毫秒数。若省略，则servo会尽快加速。\n\nServo.pulse_width([*value*])\n若未给定参数，该函数会返回当前的原始脉宽值。若给定参数，该函数设置原始脉宽值。\n\nServo.calibration([*pulse_min, *pulse_max, pulse_centre**[, pulse_angle_90, pulse_speed_100]**])\n若未给定参数，这个函数返回当前的5元组校准数据。若给定参数，该函数设定计时校准：pulse_min 是允许的最小脉宽。pulse_max 是允许的最大脉冲。pulse_centre 是中心/零位置对应的脉宽。pulse_angle_90 是90度对应的脉宽。pulse_speed_100 是速度100对应的脉宽。\n\n\n串口通信\nimport timefrom pyb import UARTuart = UART(3, 19200)while(True):    uart.write(&quot;Hello World!\\r&quot;)    time.sleep_ms(1000)\n\nUART类\n实例化一个串口， 波特率为19200的串口3\n\n注意：必须是串口3，因为OpenMV2只引出了这个串口，pyb的串口有好多个的。OpenMV3又增加了串口1。\n\n调用write方法传输数据   可传输Json数据\n"},{"title":"web crawler","url":"/2022/04/30/webcrawler/","content":""},{"title":"pytorch笔记","url":"/2022/04/24/pytorch%E7%AC%94%E8%AE%B0/","content":"一.张量1.张量的数据类型\n\n默认数据类型为32位浮点型\n\ntorch.set_default_tensor_type()函数可设置默认的张量数据类型\n\na.long()  a.int()  a.float()方法\n\n2.张量的生成(1)列表或序列可通过torch.tensor()函数构造张量\n\n\n.shape .size .numel()方法\na  = torch.randn((2,3,5),dtype = torch.float32)print(a.shape)#打印“torch.Size([2,3,5])”不需要加括号，直接访问成员属性，返回的是torch.Size类对象，print(a.shape[1])#可以使用[]索引访问,所以size属性是一个迭代器print(a.size())#打印“torch.Size([2,3,5])”,与shape属性一致print(a.size(1))#可传入参数，返回3，即第i维的个数print(a.numel)#返回30，计算张量中包含元素数量\n\n通过torch.tensor()函数构造张量可使用dtype参数指定数据类型，使用requires_grad来指定是否需要计算梯度\n(2)torch.Tensor()——————一个类\n\n可以生成指定形状的张量\n\n(3)torch.from_numpy(ndarray)  torch.as_tensor()\n\n\n(4)依据数值创建\n\n\n\n\n\n\n\n\n\ntorch.empty()————返回填充有未初始化数据的张量，张量的形状由可变的参数大小定义\n&gt;&gt;&gt; torch.empty(2, 3)tensor(1.00000e-08 *       [[ 6.3984,  0.0000,  0.0000],        [ 0.0000,  0.0000,  0.0000]])\n\n(5)依据概率分布创建张量\ntorch.manual_seed()——————指定生成随机数种子\n\n \n\n\n3.张量的操作（1）张量的拼接与切分\ntorch.stack()会拓展张量维度\n\n\n（2）张量索引\n==注意index参数的数据类型必须是torch.long==\n例\n\n(对第0维度进行索引（相当于索引第一维度）)\n\n（3）张量变换\n\n\n\n==注意reshape共享数据内存==\n\n\n如图：\n\n\n\n沿着指定的维度重复tensor。不同与expand()，本函数复制的是tensor中的数据。扩展（expand）张量不会分配新的内存，只是在存在的张量上创建一个新的视图（view），一个大小（size）等于1的维度扩展到更大的尺寸。repeat沿着特定的维度重复这个张量，和expand()不同的是，这个函数拷贝张量的数据。\n\n\n（4）张量数学运算\n\n\n\n\n真多啊。。。用到再查叭。\n二.pytorch中的自动求导将张量的requires_grad参数设为Ture可自动求导得到其梯度\n\nTensor()类的重要属性：\n\n在Pytorch中，默认情况下，非叶节点的梯度值在反向传播过程中使用完后就会被清除，不会被保留。只有叶子节点的梯度值能够被保留下来\n\nretain_grad()可保存非叶子节点梯度\n\ngrad_fn：记录创建该张量时所用的方法（函数）\nprint(&quot;grad_fn:&quot;, w.grad_fn, x.grad_fn, a.grad_fn, b.grad_fn, y.grad_fn)# Out：grad_fn: None None &lt;AddBackward0 object at 0x000001C04BB24788&gt; &lt;AddBackward0 object at 0x000001C04605D188&gt; &lt;MulBackward0 object at 0x000001C04605D1C8&gt;\n\nautogradtorch.autograd.backward张量中的backward()方法直接调用了torch.autograd.backward()\n\nretain_graph参数设置为True，得以进行两次反向传播\n\ngrad_tensors参数用于多梯度权重的设置\nw = torch.tensor([1.], requires_grad=True)    x = torch.tensor([2.], requires_grad=True)    a = torch.add(w, x)     # retain_grad()    b = torch.add(w, 1)    y0 = torch.mul(a, b)    # y0 = (x+w) * (w+1)    y1 = torch.add(a, b)    # y1 = (x+w) + (w+1)    dy1/dw = 2    loss = torch.cat([y0, y1], dim=0)       # [y0, y1]    grad_tensors = torch.tensor([1., 1.])    # grad_tensors = torch.tensor([1., 2.])    loss.backward(gradient=grad_tensors)    # gradient 传入 torch.autograd.backward()中的grad_tensors    print(w.grad)        out：7 # 9\n\ntorch.autograd.grad\ncreate_graph   创建导数计算图，用于高阶求导\n\nautograd小贴士：1.梯度不自动清零\n\n使用grad.zero_()  对梯度清零\n\n2.依赖于叶子节点的节点， requires_grad默认为True\n\n3.叶子节点不可执行in-place操作\n\n可知+=操作时不改变内存地址，为in-place操作，不可对叶子节点执行\n\n三.torch.nn模块容器\n\n\n卷积层\n# 以torch.nn.Conv2d()为例， 介绍卷积再图像上的使用方法，其调用方式为：torch.nn.Conv2d(in_channels,               out_channels,               kernel_size,               stride=1,               padding=0,               dilation=1,               groups=1,               bias=True)\n\n\nimport numpy as npimport torchimport torch.nn as nnimport matplotlib.pyplot as pltfrom PIL import Imagemyim = Image.open(&quot;lenna.jpg&quot;)myimgray = np.array(myim.convert(&quot;L&quot;), dtype=np.float32)imh, imw = myimgray.shapemyimgray_t = torch.from_numpy(myimgray.reshape((1, 1, imh, imw)))kersize = 5ker = torch.ones(kersize, kersize, dtype=torch.float32)*-1ker[2, 2] = 24ker = ker.reshape((1, 1, kersize, kersize))conv2d = nn.Conv2d(1, 2, (kersize, kersize), bias = False)conv2d.weight.data[0] = kerimconv2dout = conv2d(myimgray_t)imconv2dout_im = imconv2dout.data.squeeze()plt.figure(figsize=(12, 6))plt.imshow(imconv2dout_im[0], cmap=plt.cm.gray)plt.axis(&quot;off&quot;)plt.show()\n\n\n可见使用边缘特征提取卷积核很好的提取出了图像的边缘信息\n池化层\n\n\n激活函数\n全连接层\n四.pytorch中的数据操作与预处理\nDataloader\nDataset\ntransforms\ncrop\n\n\n\n\nflip\nrotation\n\n\n\n\n\n\ntransforms的操作\n自定义transforms\n正态分布与平方损失接下来，我们通过对噪声分布的假设来解读平方损失目标函数。\n正态分布和线性回归之间的关系很密切。 正态分布（normal distribution），也称为高斯分布（Gaussian distribution）， 最早由德国数学家高斯（Gauss）应用于天文学研究。 简单的说，若随机变量xx具有均值μμ和方差σ2σ2（标准差σσ），其正态分布概率密度函数如下：\n(3.1.11)\np(x)=12πσ2−−−−√exp(−12σ2(x−μ)2).p(x)=12πσ2exp⁡(−12σ2(x−μ)2).\n下面我们定义一个Python函数来计算正态分布。\ndef normal(x, mu, sigma):    p = 1 / math.sqrt(2 * math.pi * sigma**2)    return p * np.exp(-0.5 / sigma**2 * (x - mu)**2)\n\n我们现在可视化正态分布。\n# 再次使用numpy进行可视化x = np.arange(-7, 7, 0.01)# 均值和标准差对params = [(0, 1), (0, 2), (3, 1)]d2l.plot(x, [normal(x, mu, sigma) for mu, sigma in params], xlabel=&#x27;x&#x27;,         ylabel=&#x27;p(x)&#x27;, figsize=(4.5, 2.5),         legend=[f&#x27;mean &#123;mu&#125;, std &#123;sigma&#125;&#x27; for mu, sigma in params])\n\n\n就像我们所看到的，改变均值会产生沿xx轴的偏移，增加方差将会分散分布、降低其峰值。\n均方误差损失函数（简称均方损失）可以用于线性回归的一个原因是： 我们假设了观测中包含噪声，其中噪声服从正态分布。 噪声正态分布如下式:\n(3.1.12)\ny=w⊤x+b+ϵ,y=w⊤x+b+ϵ,\n其中，ϵ∼N(0,σ2)ϵ∼N(0,σ2)。\n因此，我们现在可以写出通过给定的xx观测到特定yy的似然（likelihood）：\n(3.1.13)\nP(y∣x)=12πσ2−−−−√exp(−12σ2(y−w⊤x−b)2).P(y∣x)=12πσ2exp⁡(−12σ2(y−w⊤x−b)2).\n现在，根据极大似然估计法，参数ww和bb的最优值是使整个数据集的似然最大的值：\n(3.1.14)\nP(y∣X)=∏i=1np(y(i)|x(i)).P(y∣X)=∏i=1np(y(i)|x(i)).\n根据极大似然估计法选择的估计量称为极大似然估计量。 虽然使许多指数函数的乘积最大化看起来很困难， 但是我们可以在不改变目标的前提下，通过最大化似然对数来简化。 由于历史原因，优化通常是说最小化而不是最大化。 我们可以改为最小化负对数似然−logP(y∣X)−log⁡P(y∣X)。 由此可以得到的数学公式是：\n(3.1.15)\n−logP(y∣X)=∑i=1n12log(2πσ2)+12σ2(y(i)−w⊤x(i)−b)2.−log⁡P(y∣X)=∑i=1n12log⁡(2πσ2)+12σ2(y(i)−w⊤x(i)−b)2.\n现在我们只需要假设σσ是某个固定常数就可以忽略第一项， 因为第一项不依赖于ww和bb。 现在第二项除了常数1σ21σ2外，其余部分和前面介绍的均方误差是一样的。 幸运的是，上面式子的解并不依赖于σσ。 因此，在高斯噪声的假设下，最小化均方误差等价于对线性模型的极大似然估计。\n"}]